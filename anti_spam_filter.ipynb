{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0f9725",
   "metadata": {},
   "source": [
    "# Project Overview — Email SPAM Analysis & Classification\n",
    "\n",
    "## Goal\n",
    "\n",
    "Build an end-to-end pipeline to **detect SPAM emails** and produce **content insights**:\n",
    "\n",
    "* Train a robust SPAM classifier.\n",
    "* Discover **topics** within predicted SPAM to understand campaigns/trends.\n",
    "* Measure **semantic distances** between topics (heterogeneity).\n",
    "* From **HAM** emails, extract **Organizations** (NER) for downstream BI.\n",
    "\n",
    "---\n",
    "\n",
    "## Data & Setup\n",
    "\n",
    "* Dataset: 5,171 emails with `label`/`label_num` and raw `text` containing `Subject:` and body.\n",
    "* Splits: **Stratified 80/20** hold-out test; **5-fold CV** on the training set.\n",
    "* Reproducibility: fixed `random_state=42`; artifacts saved to disk (model + JSON).\n",
    "\n",
    "---\n",
    "\n",
    "## What we did in this notebook\n",
    "\n",
    "### 1) Data Intake & Basic EDA\n",
    "\n",
    "* Loaded the dataset, validated schema, checked nulls/lengths.\n",
    "* Verified **label ↔ label\\_num** consistency (SPAM=1).\n",
    "* Confirmed presence of `Subject:` in all rows.\n",
    "\n",
    "### 2) In-depth EDA & Data Readiness\n",
    "\n",
    "* **Duplicates**: identified exact duplicate texts; decided to **drop** duplicates in training.\n",
    "* **Subject/Body parsing**: extracted `subject`, `body`; computed per-class stats (lengths, token counts, subject/body ratio).\n",
    "* **Simple signals (meta-features)**: counts of digits, phones, exclamation marks, spammy words; subject flags (`Re:`, `Fwd:`, currency).\n",
    "* **Formatting & leakage**: removed HTML (none detected), trimmed signatures/threads, and **sanitized PII** (URLs, emails, phones, long numbers) to avoid leakage and improve generalization.\n",
    "* **Distinctive lexicon**: inspected top n-grams for SPAM vs HAM to guide feature choices.\n",
    "* **Preprocessing decisions** “frozen” for modeling.\n",
    "\n",
    "### 3) Feature Representation & Baseline Modeling\n",
    "\n",
    "* **Text**: TF-IDF on **word 1–2 grams** (optionally + char 3–5 grams).\n",
    "* **Meta-features**: standardized numerics (kept sparse end-to-end).\n",
    "* **Pipelines**:\n",
    "\n",
    "  * **A**: word n-grams + meta-features → LogisticRegression (`class_weight=\"balanced\"`).\n",
    "  * **B**: word + char n-grams + meta-features → LogisticRegression.\n",
    "* Chose **Pipeline A** as the default baseline for simplicity/efficiency.\n",
    "\n",
    "### 4) Topic Modeling on predicted SPAM\n",
    "\n",
    "* Predicted SPAM with the baseline model; built a TF-IDF matrix (after custom stopwords).\n",
    "* Evaluated **K** (e.g., {5,8,11,14,17,20}) via topic **stability** and reconstruction error.\n",
    "* Selected **K ≈ 5** as a good trade-off.\n",
    "* Computed **semantic distance** between topics (cosine on normalized H) and visualized a **topic map** (clusters/heatmap).\n",
    "\n",
    "### 5) NER on HAM (Organizations)\n",
    "\n",
    "* NER pipeline: spaCy model if available; otherwise a **rule-based** `EntityRuler` fallback (robust to missing models).\n",
    "* Extracted **Organizations** from HAM; produced per-org counts and sample mentions (CSV).\n",
    "\n",
    "### 6) Calibration, Thresholding, Final Fit & Artifacts\n",
    "\n",
    "* **Calibration** with `CalibratedClassifierCV(method=\"sigmoid\")` using 5-fold OOF predictions.\n",
    "* **Robust OOF building**: always selected the positive class column by **class label** (not position), avoiding class order mix-ups.\n",
    "* Threshold selection on calibrated OOF:\n",
    "\n",
    "  * **F1-optimal (`f1_global`)**\n",
    "  * **High-recall** (target recall≈0.95) → `high_recall_global`\n",
    "  * **High-precision** (target precision≈0.98)\n",
    "  * **Min-cost** (custom FP/FN costs)\n",
    "* **Final training** on full training set; **evaluation** on hold-out test.\n",
    "* **Results (calibrated)**: Hold-out **PR-AUC ≈ 0.987**, **ROC-AUC ≈ 0.995** (representative run).\n",
    "* **Artifacts saved**:\n",
    "\n",
    "  * `spam_model_v1.joblib` — full sklearn pipeline (features + classifier).\n",
    "  * `spam_model_v1_artifacts.json` — thresholds (e.g., `high_recall_global ≈ 0.65`), meta-features, CV settings, test metrics.\n",
    "  * Error slices: `test_false_positives.csv`, `test_false_negatives.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "## Design Choices (Why)\n",
    "\n",
    "* **PII masking & HTML strip**: prevents memorizing identifiers and improves generalization/ethics.\n",
    "* **Duplicates dropped** only in training to avoid bias.\n",
    "* **Subject weighting**: `subject + body` combined (subject repeated by a tunable weight) to capture signal without overfitting.\n",
    "* **Meta-features** augment sparse text to capture formatting/behavioral signals (digits, phones, `Re:`/`Fwd:`, etc.).\n",
    "* **Calibration & thresholds**: we expose multiple operating points (F1-max, high-recall, high-precision, min-cost) for different risk profiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2561be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os, json, joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, pandas as pd, time\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from scipy import sparse\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.pipeline import EntityRuler\n",
    "from typing import List, Dict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, f1_score, precision_recall_fscore_support, confusion_matrix, precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer as FT\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929fbf5e",
   "metadata": {},
   "source": [
    "## Step 1 — Data Intake & Basic EDA \n",
    "This cell performs a **quick but rigorous intake check** of the email dataset to confirm schema, label consistency, and basic text quality before deeper EDA/modeling.\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Visualization style\n",
    "\n",
    "* `plt.style.use('ggplot')`, `sns.set(font_scale=1.2)`\n",
    "  Sets a readable, consistent style for any plots produced later.\n",
    "\n",
    "### 2) Load dataset\n",
    "\n",
    "* `pd.read_csv('spam_dataset.csv')`\n",
    "  Loads the CSV and prints its **shape** to confirm row/column counts.\n",
    "\n",
    "### 3) Snapshot & Data Dictionary\n",
    "\n",
    "* `df.info()`, `df.head()`\n",
    "  Gives a structural snapshot: column names, types, and a few sample rows.\n",
    "* Builds a **data dictionary** with:\n",
    "\n",
    "  * `Type`: pandas dtype per column\n",
    "  * `Non-Null Count` & `Null Count`: data completeness\n",
    "  * `Null %`: quick missingness rate\n",
    "  * `Unique Values`: cardinality to spot ID-like columns or low-variance fields\n",
    "    **Why:** ensures the dataset matches expectations and flags potential issues early.\n",
    "\n",
    "### 4) Technical index cleanup\n",
    "\n",
    "* If an `Unnamed: 0` column exists, it’s dropped.\n",
    "  **Why:** These are often CSV-exported index columns and add no signal.\n",
    "\n",
    "### 5) Label verification\n",
    "\n",
    "* Prints distribution for `label` and `label_num`.\n",
    "* Cross-tab (`pd.crosstab`) checks **alignment** between `label` (string) and `label_num` (numeric).\n",
    "* Verifies `spam` corresponds to `1` (`spam_is_one`).\n",
    "  **Why:** Prevents silent data leakage/label inversion that would invalidate training and metrics.\n",
    "\n",
    "### 6) Text content verification\n",
    "\n",
    "* Creates `text_length = df['text'].str.len()` and prints `.describe()`\n",
    "  to understand typical email sizes.\n",
    "* Flags **very short** texts (`< 10 chars`) and **whitespace-only** rows.\n",
    "  **Why:** Extremely short/empty rows are often noise and can break tokenizers.\n",
    "\n",
    "### 7) Subject presence check\n",
    "\n",
    "* Checks how many texts contain `'Subject:'` (case-insensitive).\n",
    "* Prints a short example with and (if present) without `Subject:`.\n",
    "  **Why:** Confirms the expected **Subject + Body** structure; this informs later parsing (e.g., weighting subject vs. body).\n",
    "\n",
    "### 8) Preliminary findings summary\n",
    "\n",
    "* Prints a compact recap: total rows, missing values, counts of very short/empty texts, class distribution, and whether `spam == 1`.\n",
    "  **Why:** Creates a “Definition of Ready” for the dataset: if anything is off, we fix it **before** modeling.\n",
    "\n",
    "---\n",
    "\n",
    "### Takeaway\n",
    "\n",
    "This cell validates that the dataset is **well-formed**, **labels are consistent**, and the raw text field is suitable for downstream steps (subject/body parsing, preprocessing, feature extraction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96ab263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the spam dataset...\n",
      "Dataset loaded successfully with 5171 rows and 4 columns.\n",
      "\n",
      "=== DATASET SNAPSHOT ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5171 entries, 0 to 5170\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  5171 non-null   int64 \n",
      " 1   label       5171 non-null   object\n",
      " 2   text        5171 non-null   object\n",
      " 3   label_num   5171 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 161.7+ KB\n",
      "None\n",
      "   Unnamed: 0 label                                               text  \\\n",
      "0         605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
      "1        2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
      "2        3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
      "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "4        2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
      "\n",
      "   label_num  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          0  \n",
      "\n",
      "=== DATA DICTIONARY ===\n",
      "              Type  Non-Null Count  Null Count  Null %  Unique Values\n",
      "Unnamed: 0   int64            5171           0     0.0           5171\n",
      "label       object            5171           0     0.0              2\n",
      "text        object            5171           0     0.0           4993\n",
      "label_num    int64            5171           0     0.0              2\n",
      "\n",
      "Detected technical index column 'Unnamed: 0' - will be dropped\n",
      "Column dropped successfully\n",
      "\n",
      "=== LABEL VERIFICATION ===\n",
      "'label' column values:\n",
      "label\n",
      "ham     3672\n",
      "spam    1499\n",
      "Name: count, dtype: int64\n",
      "\n",
      "'label_num' column values:\n",
      "label_num\n",
      "0    3672\n",
      "1    1499\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Consistency check (label vs label_num):\n",
      "label_num     0     1\n",
      "label                \n",
      "ham        3672     0\n",
      "spam          0  1499\n",
      "Spam corresponds to label_num=1: True\n",
      "\n",
      "=== TEXT CONTENT VERIFICATION ===\n",
      "Text length statistics:\n",
      "count     5171.00000\n",
      "mean      1029.74531\n",
      "std       1505.10317\n",
      "min         10.00000\n",
      "25%        238.00000\n",
      "50%        529.00000\n",
      "75%       1214.00000\n",
      "max      31860.00000\n",
      "Name: text_length, dtype: float64\n",
      "\n",
      "Found 0 very short texts (less than 10 characters):\n",
      "\n",
      "Found 0 whitespace-only texts:\n",
      "\n",
      "Texts containing 'Subject:': 5171 out of 5171 (100.00%)\n",
      "\n",
      "Example with 'Subject:':\n",
      "Subject: enron methanol ; meter # : 988291\n",
      "this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary\n",
      "flow data provided by daren } .\n",
      "please override pop ' s daily volume { presen...\n",
      "\n",
      "=== PRELIMINARY FINDINGS ===\n",
      "- Total records: 5171\n",
      "- Missing values: None\n",
      "- Very short texts: 0\n",
      "- Whitespace-only texts: 0\n",
      "- Class distribution: {'ham': 3672, 'spam': 1499}\n",
      "- Spam corresponds to label_num=1: True\n"
     ]
    }
   ],
   "source": [
    "# Set style for visualizations\n",
    "plt.style.use('ggplot')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading the spam dataset...\")\n",
    "df = pd.read_csv('spam_dataset.csv')\n",
    "print(f\"Dataset loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "# Snapshot & Data Dictionary\n",
    "print(\"\\n=== DATASET SNAPSHOT ===\")\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# Display data types and null counts\n",
    "print(\"\\n=== DATA DICTIONARY ===\")\n",
    "data_dict = pd.DataFrame({\n",
    "    'Type': df.dtypes,\n",
    "    'Non-Null Count': df.count(),\n",
    "    'Null Count': df.isnull().sum(),\n",
    "    'Null %': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'Unique Values': [df[col].nunique() for col in df.columns]\n",
    "})\n",
    "print(data_dict)\n",
    "\n",
    "# Check for 'Unnamed: 0' column (index to drop)\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    print(\"\\nDetected technical index column 'Unnamed: 0' - will be dropped\")\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    print(\"Column dropped successfully\")\n",
    "\n",
    "# Verify label values\n",
    "print(\"\\n=== LABEL VERIFICATION ===\")\n",
    "print(\"'label' column values:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Verify label_num values and consistency with label\n",
    "print(\"\\n'label_num' column values:\")\n",
    "print(df['label_num'].value_counts())\n",
    "\n",
    "# Check consistency between label and label_num\n",
    "if 'label' in df.columns and 'label_num' in df.columns:\n",
    "    # Create a crosstab to verify alignment\n",
    "    label_consistency = pd.crosstab(df['label'], df['label_num'], \n",
    "                                    rownames=['label'], \n",
    "                                    colnames=['label_num'])\n",
    "    print(\"\\nConsistency check (label vs label_num):\")\n",
    "    print(label_consistency)\n",
    "    \n",
    "    # Verify if spam == 1\n",
    "    spam_is_one = (df[df['label'] == 'spam']['label_num'] == 1).all()\n",
    "    print(f\"Spam corresponds to label_num=1: {spam_is_one}\")\n",
    "    \n",
    "    if not spam_is_one:\n",
    "        print(\"WARNING: Inconsistency between 'label' and 'label_num'!\")\n",
    "\n",
    "# Check for empty or very short texts\n",
    "print(\"\\n=== TEXT CONTENT VERIFICATION ===\")\n",
    "df['text_length'] = df['text'].str.len()\n",
    "print(\"Text length statistics:\")\n",
    "print(df['text_length'].describe())\n",
    "\n",
    "# Identify very short texts (potential empty content)\n",
    "short_threshold = 10\n",
    "short_texts = df[df['text_length'] < short_threshold]\n",
    "print(f\"\\nFound {len(short_texts)} very short texts (less than {short_threshold} characters):\")\n",
    "if not short_texts.empty:\n",
    "    print(short_texts[['label', 'text']])\n",
    "\n",
    "# Check for whitespace-only texts\n",
    "whitespace_texts = df[df['text'].str.strip() == '']\n",
    "print(f\"\\nFound {len(whitespace_texts)} whitespace-only texts:\")\n",
    "if not whitespace_texts.empty:\n",
    "    print(whitespace_texts[['label', 'text']])\n",
    "\n",
    "# Verify if texts contain \"Subject:\" pattern\n",
    "has_subject = df['text'].str.contains('Subject:', case=False, regex=True)\n",
    "print(f\"\\nTexts containing 'Subject:': {has_subject.sum()} out of {len(df)} ({has_subject.mean()*100:.2f}%)\")\n",
    "\n",
    "# Display a few examples of texts with and without \"Subject:\"\n",
    "if has_subject.any():\n",
    "    print(\"\\nExample with 'Subject:':\")\n",
    "    print(df[has_subject].iloc[0]['text'][:200] + \"...\")\n",
    "    \n",
    "if (~has_subject).any():\n",
    "    print(\"\\nExample without 'Subject:':\")\n",
    "    print(df[~has_subject].iloc[0]['text'][:200] + \"...\")\n",
    "\n",
    "print(\"\\n=== PRELIMINARY FINDINGS ===\")\n",
    "print(f\"- Total records: {len(df)}\")\n",
    "print(f\"- Missing values: {'None' if df.isnull().sum().sum() == 0 else df.isnull().sum().sum()}\")\n",
    "print(f\"- Very short texts: {len(short_texts)}\")\n",
    "print(f\"- Whitespace-only texts: {len(whitespace_texts)}\")\n",
    "print(f\"- Class distribution: {df['label'].value_counts().to_dict()}\")\n",
    "print(f\"- Spam corresponds to label_num=1: {spam_is_one if 'label' in df.columns and 'label_num' in df.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc2151d",
   "metadata": {},
   "source": [
    "# Step 2 — In-depth EDA: duplicates\n",
    "\n",
    "* **Flag exact duplicates:** `df['is_exact_duplicate'] = df.duplicated('text', keep=False)` marks rows with identical `text`.\n",
    "* **Dataset-level metrics:** counts how many rows are duplicated and how many **duplicate groups** exist.\n",
    "* **By-class breakdown:** number and % of duplicated rows within each `label` (`ham`/`spam`).\n",
    "* **Readable summary:** prints totals and per-class stats.\n",
    "* **Top duplicate groups:** shows the 3 most frequent texts, displaying the **Subject** (if found) or the first 80 chars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faf36198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DUPLICATES ANALYSIS ===\n",
      "Total rows marked as duplicates: 321 (6.21% of dataset)\n",
      "Number of duplicate groups: 143\n",
      "\n",
      "Duplicates by class:\n",
      "- ham: 264 rows (7.19% of ham class)\n",
      "- spam: 57 rows (3.80% of spam class)\n",
      "\n",
      "Top 3 duplicate groups:\n",
      "- 'calpine daily gas nomination...' (20 occurrences)\n",
      "- '...' (16 occurrences)\n",
      "- 'you can be smart !...' (3 occurrences)\n"
     ]
    }
   ],
   "source": [
    "# Flag exact duplicates\n",
    "df['is_exact_duplicate'] = df.duplicated('text', keep=False)\n",
    "\n",
    "# Calculate metrics\n",
    "n_rows_dup_marked = df['is_exact_duplicate'].sum()\n",
    "n_groups_dup = df['text'].value_counts().gt(1).sum()\n",
    "\n",
    "# Count duplicates by class\n",
    "dup_by_class = df[df['is_exact_duplicate']].groupby('label').size()\n",
    "dup_pct_by_class = df[df['is_exact_duplicate']].groupby('label').size() / df.groupby('label').size() * 100\n",
    "\n",
    "# Print summary\n",
    "print(\"=== DUPLICATES ANALYSIS ===\")\n",
    "print(f\"Total rows marked as duplicates: {n_rows_dup_marked} ({n_rows_dup_marked/len(df)*100:.2f}% of dataset)\")\n",
    "print(f\"Number of duplicate groups: {n_groups_dup}\")\n",
    "print(\"\\nDuplicates by class:\")\n",
    "for label, count in dup_by_class.items():\n",
    "    print(f\"- {label}: {count} rows ({dup_pct_by_class[label]:.2f}% of {label} class)\")\n",
    "\n",
    "# Show top 3 duplicate groups\n",
    "print(\"\\nTop 3 duplicate groups:\")\n",
    "top_dups = df['text'].value_counts().nlargest(3)\n",
    "for text, count in top_dups.items():\n",
    "    # Extract subject or first 80 chars for display\n",
    "    subject_match = re.search(r'(?im)^\\s*subject\\s*:\\s*(.*)$', text)\n",
    "    display_text = subject_match.group(1) if subject_match else text[:80]\n",
    "    print(f\"- '{display_text}...' ({count} occurrences)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b85437",
   "metadata": {},
   "source": [
    "## Step 2.1 — Subject/Body parsing & quick stats\n",
    "\n",
    "* **Extract `subject` and `body`:**\n",
    "  Uses robust regex on the raw `text` to get the line after `Subject:` as the subject and everything below as the body. Falls back gracefully if `Subject:` is missing.\n",
    "\n",
    "* **Create basic metrics:**\n",
    "\n",
    "  * `subject_length`, `body_length` (char counts)\n",
    "  * `subject_token_count`, `body_token_count` (word counts)\n",
    "  * `subject_body_ratio` = subject\\_length / body\\_length (denominator protected with `max(1, x)`)\n",
    "\n",
    "* **Summarize by class (SPAM vs HAM):**\n",
    "  Prints **median** and **IQR** $[Q1–Q3]$ for each metric, per class, to spot early differences in size and verbosity.\n",
    "\n",
    "* **Why this matters:**\n",
    "  Confirms the dataset structure (subject vs body), surfaces simple distribution shifts between SPAM/HAM, and informs later preprocessing/weighting (e.g., how much to weight the subject).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06910a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting subject and body...\n",
      "\n",
      "=== SUBJECT/BODY STATISTICS BY CLASS ===\n",
      "  Class               Metric                      IQR\n",
      "0  SPAM       subject_length      32.00 [20.00-46.00]\n",
      "1  SPAM          body_length  507.00 [227.50-1171.00]\n",
      "2  SPAM  subject_token_count        7.00 [4.00-10.00]\n",
      "3  SPAM     body_token_count    105.00 [46.00-232.00]\n",
      "4  SPAM   subject_body_ratio         0.06 [0.02-0.15]\n",
      "5   HAM       subject_length      28.00 [19.00-40.00]\n",
      "6   HAM          body_length  473.00 [190.00-1170.25]\n",
      "7   HAM  subject_token_count         6.00 [4.00-9.00]\n",
      "8   HAM     body_token_count    118.00 [44.00-284.00]\n",
      "9   HAM   subject_body_ratio         0.05 [0.02-0.15]\n"
     ]
    }
   ],
   "source": [
    "# Define robust extraction functions\n",
    "def extract_subject(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    match = re.search(r'(?im)^\\s*subject\\s*:\\s*(.*)$', text)\n",
    "    return match.group(1).strip() if match else ''\n",
    "\n",
    "def extract_body(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    match = re.search(r'(?im)^\\s*subject\\s*:\\s*(.*)$', text)\n",
    "    if match:\n",
    "        subject_end = match.end()\n",
    "        next_line = text.find('\\n', subject_end)\n",
    "        if next_line != -1:\n",
    "            return text[next_line+1:].strip()\n",
    "        else:\n",
    "            return ''  # No body after subject\n",
    "    return text  # If no subject found, return full text\n",
    "\n",
    "# Add columns\n",
    "print(\"Extracting subject and body...\")\n",
    "df['subject'] = df['text'].apply(extract_subject)\n",
    "df['body'] = df['text'].apply(extract_body)\n",
    "\n",
    "# Calculate length and token metrics\n",
    "df['subject_length'] = df['subject'].fillna('').str.len()\n",
    "df['body_length'] = df['body'].fillna('').str.len()\n",
    "df['subject_token_count'] = df['subject'].fillna('').str.split().str.len()\n",
    "df['body_token_count'] = df['body'].fillna('').str.split().str.len()\n",
    "df['subject_body_ratio'] = df['subject_length'] / df['body_length'].apply(lambda x: max(1, x))\n",
    "\n",
    "# Print statistics by class\n",
    "print(\"\\n=== SUBJECT/BODY STATISTICS BY CLASS ===\")\n",
    "\n",
    "metrics = ['subject_length', 'body_length', 'subject_token_count', 'body_token_count', 'subject_body_ratio']\n",
    "\n",
    "# Create a results dataframe for better display\n",
    "results = []\n",
    "\n",
    "for label_num in [1, 0]:  # SPAM=1, HAM=0\n",
    "    class_label = 'SPAM' if label_num == 1 else 'HAM'\n",
    "    class_df = df[df['label_num'] == label_num]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        median = class_df[metric].median()\n",
    "        q1 = class_df[metric].quantile(0.25)\n",
    "        q3 = class_df[metric].quantile(0.75)\n",
    "        \n",
    "        results.append({\n",
    "            'Class': class_label,\n",
    "            'Metric': metric,\n",
    "            'Median': median,\n",
    "            'Q1': q1,\n",
    "            'Q3': q3,\n",
    "            'IQR': f\"{median:.2f} [{q1:.2f}-{q3:.2f}]\"\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "stats_df = pd.DataFrame(results)\n",
    "print(stats_df[['Class', 'Metric', 'IQR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe53b2",
   "metadata": {},
   "source": [
    "## Step 2.2 — Subject indicators\n",
    "\n",
    "* **Signals extracted from `subject`:**\n",
    "  `has_re`, `has_fwd`, `exclamation_count`, `digit_count`, `has_currency`, `%_uppercase_letters`.\n",
    "  (Robust regex for `Re:` / `Fwd:`; counts are case-sensitive where appropriate.)\n",
    "\n",
    "* **Adds features to `df`:**\n",
    "  Creates columns for each indicator so they’re reusable later.\n",
    "\n",
    "* **Summaries by class (SPAM vs HAM):**\n",
    "  Prints **median \\[Q1–Q3]** for all indicators.\n",
    "\n",
    "* **Prevalence for binary flags:**\n",
    "  Prints **% True** of `has_re`, `has_fwd`, `has_currency` per class (more informative than medians for 0/1).\n",
    "\n",
    "* **Purpose:**\n",
    "  Quickly surface subject-line behavior differences between SPAM and HAM to guide feature selection/weighting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f5e2f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating subject indicators...\n",
      "\n",
      "=== SUBJECT INDICATORS BY CLASS (mediana [IQR]) ===\n",
      "   Class                          Indicator    Median [Q1-Q3]\n",
      "0   SPAM                     subject_has_re  0.00 [0.00-0.00]\n",
      "1   SPAM                    subject_has_fwd  0.00 [0.00-0.00]\n",
      "2   SPAM          subject_exclamation_count  0.00 [0.00-0.00]\n",
      "3   SPAM                subject_digit_count  0.00 [0.00-0.00]\n",
      "4   SPAM               subject_has_currency  0.00 [0.00-0.00]\n",
      "5   SPAM  subject_percent_uppercase_letters  0.00 [0.00-0.00]\n",
      "6    HAM                     subject_has_re  0.00 [0.00-0.00]\n",
      "7    HAM                    subject_has_fwd  0.00 [0.00-0.00]\n",
      "8    HAM          subject_exclamation_count  0.00 [0.00-0.00]\n",
      "9    HAM                subject_digit_count  1.00 [0.00-5.00]\n",
      "10   HAM               subject_has_currency  0.00 [0.00-0.00]\n",
      "11   HAM  subject_percent_uppercase_letters  0.00 [0.00-0.00]\n",
      "\n",
      "=== SUBJECT FLAGS PREVALENCE (percentuale di True) ===\n",
      "Class                   HAM  SPAM\n",
      "Flag                             \n",
      "subject_has_currency   0.19  3.80\n",
      "subject_has_fwd        4.52  2.67\n",
      "subject_has_re        19.20  5.34\n",
      "   Class                          Indicator    Median [Q1-Q3]\n",
      "0   SPAM                     subject_has_re  0.00 [0.00-0.00]\n",
      "1   SPAM                    subject_has_fwd  0.00 [0.00-0.00]\n",
      "2   SPAM          subject_exclamation_count  0.00 [0.00-0.00]\n",
      "3   SPAM                subject_digit_count  0.00 [0.00-0.00]\n",
      "4   SPAM               subject_has_currency  0.00 [0.00-0.00]\n",
      "5   SPAM  subject_percent_uppercase_letters  0.00 [0.00-0.00]\n",
      "6    HAM                     subject_has_re  0.00 [0.00-0.00]\n",
      "7    HAM                    subject_has_fwd  0.00 [0.00-0.00]\n",
      "8    HAM          subject_exclamation_count  0.00 [0.00-0.00]\n",
      "9    HAM                subject_digit_count  1.00 [0.00-5.00]\n",
      "10   HAM               subject_has_currency  0.00 [0.00-0.00]\n",
      "11   HAM  subject_percent_uppercase_letters  0.00 [0.00-0.00]\n"
     ]
    }
   ],
   "source": [
    "RE_PAT  = r'(?i)\\bre\\s*:'\n",
    "FWD_PAT = r'(?i)\\b(?:fw|fwd)\\s*:'\n",
    "\n",
    "def calculate_subject_indicators(subject: str):\n",
    "    subject = (subject or \"\").strip()\n",
    "    letters = [c for c in subject if c.isalpha()]\n",
    "    n_letters = max(1, len(letters))\n",
    "    uppercase_letters = sum(1 for c in letters if c.isupper())\n",
    "\n",
    "    return {\n",
    "        \"subject_has_re\": 1 if re.search(RE_PAT, subject) else 0,\n",
    "        \"subject_has_fwd\": 1 if re.search(FWD_PAT, subject) else 0,\n",
    "        \"subject_exclamation_count\": subject.count(\"!\"),\n",
    "        \"subject_digit_count\": sum(c.isdigit() for c in subject),\n",
    "        \"subject_has_currency\": 1 if re.search(r\"[$€£¥]\", subject) else 0,\n",
    "        \"subject_percent_uppercase_letters\": (uppercase_letters / n_letters) * 100.0,\n",
    "    }\n",
    "\n",
    "print(\"Calculating subject indicators...\")\n",
    "subject_indicators = df[\"subject\"].apply(calculate_subject_indicators)\n",
    "\n",
    "cols = [\n",
    "    \"subject_has_re\", \"subject_has_fwd\", \"subject_exclamation_count\",\n",
    "    \"subject_digit_count\", \"subject_has_currency\",\n",
    "    \"subject_percent_uppercase_letters\"\n",
    "]\n",
    "for c in cols:\n",
    "    df[c] = subject_indicators.apply(lambda x: x[c])\n",
    "\n",
    "results = []\n",
    "for label_num, class_label in [(1,\"SPAM\"), (0,\"HAM\")]:\n",
    "    class_df = df[df[\"label_num\"] == label_num]\n",
    "    for c in cols:\n",
    "        med = class_df[c].median()\n",
    "        q1 = class_df[c].quantile(0.25)\n",
    "        q3 = class_df[c].quantile(0.75)\n",
    "        results.append({\n",
    "            \"Class\": class_label,\n",
    "            \"Indicator\": c,\n",
    "            \"Median [Q1-Q3]\": f\"{med:.2f} [{q1:.2f}-{q3:.2f}]\"\n",
    "        })\n",
    "indicators_df = pd.DataFrame(results)\n",
    "print(\"\\n=== SUBJECT INDICATORS BY CLASS (mediana [IQR]) ===\")\n",
    "print(indicators_df[[\"Class\",\"Indicator\",\"Median [Q1-Q3]\"]])\n",
    "\n",
    "flag_cols = [\"subject_has_re\",\"subject_has_fwd\",\"subject_has_currency\"]\n",
    "pct_rows = []\n",
    "for label_num, class_label in [(1,\"SPAM\"), (0,\"HAM\")]:\n",
    "    class_df = df[df[\"label_num\"] == label_num]\n",
    "    for c in flag_cols:\n",
    "        pct = class_df[c].mean() * 100.0\n",
    "        pct_rows.append({\"Class\": class_label, \"Flag\": c, \"Prevalence %\": f\"{pct:.2f}\"})\n",
    "pct_df = pd.DataFrame(pct_rows)\n",
    "print(\"\\n=== SUBJECT FLAGS PREVALENCE (percentuale di True) ===\")\n",
    "print(pct_df.pivot(index=\"Flag\", columns=\"Class\", values=\"Prevalence %\"))\n",
    "\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "indicators_df = pd.DataFrame(results)\n",
    "print(indicators_df[['Class', 'Indicator', 'Median [Q1-Q3]']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69abe7",
   "metadata": {},
   "source": [
    "## Step 2.3 — Content indicators on body/text & SPAM–HAM comparison\n",
    "\n",
    "* **Compute rich indicators** with `calculate_content_indicators(text)`:\n",
    "\n",
    "  * `url_count`, `email_count`, `phone_count`, `digit_count`, `exclamation_count`\n",
    "  * `%_uppercase_letters` (letters‐only denominator)\n",
    "  * `spam_word_count` over a small list: `['free','offer','money','click','win','cash','prize','discount']`.\n",
    "\n",
    "* **Apply to both body and full text**:\n",
    "\n",
    "  * Creates columns prefixed **`body_`** and **`text_`** (e.g., `body_digit_count`, `text_url_count`) for reuse later.\n",
    "\n",
    "* **Summarize by class (SPAM vs HAM)** for **body** metrics:\n",
    "\n",
    "  * Prints **median \\[IQR]** per class and the **SPAM/HAM ratio** (quick effect size proxy).\n",
    "  * Ratio > 1 ⇒ higher typical value in SPAM; < 1 ⇒ higher in HAM.\n",
    "\n",
    "* **Why it matters**:\n",
    "\n",
    "  * These **meta-features** capture non-lexical signals (formatting, punctuation, contact info) that often distinguish SPAM from HAM and complement TF-IDF features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a11fd694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating content indicators for body and full text...\n",
      "\n",
      "=== BODY CONTENT INDICATORS: SPAM vs HAM ===\n",
      "                      Metric SPAM (median [IQR])  HAM (median [IQR])  \\\n",
      "0                  url_count    0.00 [0.00-0.00]    0.00 [0.00-0.00]   \n",
      "1                email_count    0.00 [0.00-0.00]    0.00 [0.00-0.00]   \n",
      "2                phone_count    0.00 [0.00-0.00]    0.00 [0.00-2.00]   \n",
      "3                digit_count   5.00 [0.00-20.00]  24.00 [6.00-53.00]   \n",
      "4          exclamation_count    0.00 [0.00-2.00]    0.00 [0.00-0.00]   \n",
      "5  percent_uppercase_letters    0.00 [0.00-0.00]    0.00 [0.00-0.00]   \n",
      "6            spam_word_count    0.00 [0.00-1.00]    0.00 [0.00-0.00]   \n",
      "\n",
      "  SPAM/HAM ratio  \n",
      "0          0.00x  \n",
      "1          0.00x  \n",
      "2          0.00x  \n",
      "3          0.21x  \n",
      "4          0.00x  \n",
      "5          0.00x  \n",
      "6          0.00x  \n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate content indicators\n",
    "def calculate_content_indicators(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    \n",
    "    # Count letters for uppercase percentage calculation\n",
    "    letters = [c for c in text if c.isalpha()]\n",
    "    letter_count = max(1, len(letters))\n",
    "    uppercase_letters = sum(1 for c in letters if c.isupper())\n",
    "    \n",
    "    # Define spam words list\n",
    "    spam_words = ['free', 'offer', 'money', 'click', 'win', 'cash', 'prize', 'discount']\n",
    "    \n",
    "    # Calculate indicators\n",
    "    url_count = len(re.findall(r'https?://\\S+|www\\.\\S+', text))\n",
    "    email_count = len(re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text))\n",
    "    phone_count = len(re.findall(r'\\+?\\d[\\d\\s\\-\\(\\)]{7,}', text))\n",
    "    digit_count = sum(c.isdigit() for c in text)\n",
    "    exclamation_count = text.count('!')\n",
    "    percent_uppercase = (uppercase_letters / letter_count) * 100\n",
    "    \n",
    "    # Count spam words (case insensitive)\n",
    "    spam_word_count = sum(len(re.findall(r'\\b' + word + r'\\b', text, re.IGNORECASE)) for word in spam_words)\n",
    "    \n",
    "    return {\n",
    "        'url_count': url_count,\n",
    "        'email_count': email_count,\n",
    "        'phone_count': phone_count,\n",
    "        'digit_count': digit_count,\n",
    "        'exclamation_count': exclamation_count,\n",
    "        'percent_uppercase_letters': percent_uppercase,\n",
    "        'spam_word_count': spam_word_count\n",
    "    }\n",
    "\n",
    "# Apply to body and text\n",
    "print(\"Calculating content indicators for body and full text...\")\n",
    "\n",
    "# Process body\n",
    "body_indicators = df['body'].apply(calculate_content_indicators)\n",
    "for indicator, values in zip(\n",
    "    ['body_url_count', 'body_email_count', 'body_phone_count', 'body_digit_count',\n",
    "     'body_exclamation_count', 'body_percent_uppercase_letters', 'body_spam_word_count'],\n",
    "    ['url_count', 'email_count', 'phone_count', 'digit_count',\n",
    "     'exclamation_count', 'percent_uppercase_letters', 'spam_word_count']\n",
    "):\n",
    "    df[indicator] = body_indicators.apply(lambda x: x[values])\n",
    "\n",
    "# Process full text\n",
    "text_indicators = df['text'].apply(calculate_content_indicators)\n",
    "for indicator, values in zip(\n",
    "    ['text_url_count', 'text_email_count', 'text_phone_count', 'text_digit_count',\n",
    "     'text_exclamation_count', 'text_percent_uppercase_letters', 'text_spam_word_count'],\n",
    "    ['url_count', 'email_count', 'phone_count', 'digit_count',\n",
    "     'exclamation_count', 'percent_uppercase_letters', 'spam_word_count']\n",
    "):\n",
    "    df[indicator] = text_indicators.apply(lambda x: x[values])\n",
    "\n",
    "# Print comparative table for body metrics\n",
    "print(\"\\n=== BODY CONTENT INDICATORS: SPAM vs HAM ===\")\n",
    "\n",
    "body_metrics = ['body_url_count', 'body_email_count', 'body_phone_count', \n",
    "               'body_digit_count', 'body_exclamation_count', \n",
    "               'body_percent_uppercase_letters', 'body_spam_word_count']\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "\n",
    "for metric in body_metrics:\n",
    "    # SPAM statistics\n",
    "    spam_median = df[df['label_num'] == 1][metric].median()\n",
    "    spam_q1 = df[df['label_num'] == 1][metric].quantile(0.25)\n",
    "    spam_q3 = df[df['label_num'] == 1][metric].quantile(0.75)\n",
    "    spam_iqr = f\"{spam_median:.2f} [{spam_q1:.2f}-{spam_q3:.2f}]\"\n",
    "    \n",
    "    # HAM statistics\n",
    "    ham_median = df[df['label_num'] == 0][metric].median()\n",
    "    ham_q1 = df[df['label_num'] == 0][metric].quantile(0.25)\n",
    "    ham_q3 = df[df['label_num'] == 0][metric].quantile(0.75)\n",
    "    ham_iqr = f\"{ham_median:.2f} [{ham_q1:.2f}-{ham_q3:.2f}]\"\n",
    "    \n",
    "    # Calculate ratio (protect against division by zero)\n",
    "    ratio = spam_median / max(0.001, ham_median)\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Metric': metric.replace('body_', ''),\n",
    "        'SPAM (median [IQR])': spam_iqr,\n",
    "        'HAM (median [IQR])': ham_iqr,\n",
    "        'SPAM/HAM ratio': f\"{ratio:.2f}x\"\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813d6cd",
   "metadata": {},
   "source": [
    "## Step 2.4 — Formatting & noise flags\n",
    "\n",
    "* **Flags computed on raw `text`:**\n",
    "  `has_html`, `has_obfuscated_links` (mismatch between anchor text and `href`), `has_signature` (`--\\n`), `has_disclaimer` (e.g., *disclaimer/legal notice/confidential*), `has_original_message` (reply/forward thread markers).\n",
    "\n",
    "* **Adds boolean columns to `df`:**\n",
    "  One column per flag for later reuse in modeling/EDA.\n",
    "\n",
    "* **Class-wise prevalence:**\n",
    "  Prints % of emails where each flag is `True` for **SPAM** vs **HAM** to spot formatting patterns.\n",
    "\n",
    "* **Decision:**\n",
    "  Extract these meta-features first, then **strip HTML** and **normalize text** in preprocessing to avoid leakage and stabilize the vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5082684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting formatting and noise patterns...\n",
      "\n",
      "=== FORMATTING & NOISE PATTERNS BY CLASS ===\n",
      "                   Flag SPAM %  HAM %\n",
      "0              has_html  0.00%  0.00%\n",
      "1  has_obfuscated_links  0.00%  0.00%\n",
      "2         has_signature  0.00%  0.00%\n",
      "3        has_disclaimer  2.47%  0.95%\n",
      "4  has_original_message  0.00%  0.00%\n",
      "\n",
      "DECISION: Will propose to extract meta-features from HTML/formatting before cleaning, then remove HTML tags and normalize text.\n"
     ]
    }
   ],
   "source": [
    "# Define functions to detect formatting and noise patterns\n",
    "def has_html(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    return bool(re.search(r'<[^>]+>', text))\n",
    "\n",
    "def has_obfuscated_links(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    \n",
    "    # Find all anchor tags\n",
    "    anchor_tags = re.findall(r'<a\\s+[^>]*href\\s*=\\s*[\"\\']([^\"\\']+)[\"\\'][^>]*>(.*?)</a>', text, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    for href, anchor_text in anchor_tags:\n",
    "        # Extract domains\n",
    "        href_domain = re.search(r'https?://([^/]+)', href)\n",
    "        anchor_domain = re.search(r'https?://([^/]+)', anchor_text)\n",
    "        \n",
    "        # Check if anchor text doesn't contain a domain (generic text like \"click here\")\n",
    "        if not anchor_domain:\n",
    "            return True\n",
    "            \n",
    "        # Check if domains don't match\n",
    "        if href_domain and anchor_domain and href_domain.group(1) != anchor_domain.group(1):\n",
    "            return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "def has_signature(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    return bool(re.search(r'--\\s*\\n', text))\n",
    "\n",
    "def has_disclaimer(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    return bool(re.search(r'(?i)\\b(disclaimer|legal notice|confidential)\\b', text))\n",
    "\n",
    "def has_original_message(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    pattern1 = r'(?im)^-{2,}\\s*Original Message\\s*-{2,}'\n",
    "    pattern2 = r'(?ims)^\\s*From: .+\\n\\s*Sent: .+\\n\\s*To: .+\\n\\s*Subject: .+'\n",
    "    return bool(re.search(pattern1, text) or re.search(pattern2, text))\n",
    "\n",
    "# Apply functions to add flags\n",
    "print(\"Detecting formatting and noise patterns...\")\n",
    "df['has_html'] = df['text'].apply(has_html)\n",
    "df['has_obfuscated_links'] = df['text'].apply(has_obfuscated_links)\n",
    "df['has_signature'] = df['text'].apply(has_signature)\n",
    "df['has_disclaimer'] = df['text'].apply(has_disclaimer)\n",
    "df['has_original_message'] = df['text'].apply(has_original_message)\n",
    "\n",
    "# Print percentages by class\n",
    "print(\"\\n=== FORMATTING & NOISE PATTERNS BY CLASS ===\")\n",
    "\n",
    "flags = ['has_html', 'has_obfuscated_links', 'has_signature', 'has_disclaimer', 'has_original_message']\n",
    "results = []\n",
    "\n",
    "for flag in flags:\n",
    "    # Calculate percentages\n",
    "    spam_pct = df[df['label_num'] == 1][flag].mean() * 100\n",
    "    ham_pct = df[df['label_num'] == 0][flag].mean() * 100\n",
    "    \n",
    "    results.append({\n",
    "        'Flag': flag,\n",
    "        'SPAM %': f\"{spam_pct:.2f}%\",\n",
    "        'HAM %': f\"{ham_pct:.2f}%\"\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "flags_df = pd.DataFrame(results)\n",
    "print(flags_df)\n",
    "\n",
    "print(\"\\nDECISION: Will propose to extract meta-features from HTML/formatting before cleaning, then remove HTML tags and normalize text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccb2ac",
   "metadata": {},
   "source": [
    "## Step 2.5 — Leakage check (anti-spam headers)\n",
    "\n",
    "* **What it detects:** presence of header strings that would leak the true label (e.g., `X-Spam-Flag`, `Spam-Score`, `SpamAssassin`, `X-Spam-Status`, `X-Spam-Level`).\n",
    "* **How:** regex scan on raw `text`; creates `df['has_leakage']` boolean.\n",
    "* **Output:** total count and % of emails containing these headers.\n",
    "* **Decision:**\n",
    "\n",
    "  * If any found → **strip these headers during preprocessing** (Step 3) to avoid label leakage.\n",
    "  * If none found → no special handling needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "decf1aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for anti-spam headers (potential leakage)...\n",
      "\n",
      "=== LEAKAGE DETECTION (ANTI-SPAM HEADERS) ===\n",
      "Emails with potential leakage: 0 (0.00% of dataset)\n",
      "\n",
      "No anti-spam headers detected. No special handling required.\n"
     ]
    }
   ],
   "source": [
    "# Define function to check for leakage\n",
    "def check_leakage(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    leakage_patterns = [\n",
    "        r'X-Spam-Flag:',\n",
    "        r'Spam-Score:',\n",
    "        r'SpamAssassin',\n",
    "        r'X-Spam-Status:',\n",
    "        r'X-Spam-Level:'\n",
    "    ]\n",
    "    \n",
    "    for pattern in leakage_patterns:\n",
    "        if re.search(f'(?i){pattern}', text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply function to add flag\n",
    "print(\"Checking for anti-spam headers (potential leakage)...\")\n",
    "df['has_leakage'] = df['text'].apply(check_leakage)\n",
    "\n",
    "# Calculate statistics\n",
    "leakage_count = df['has_leakage'].sum()\n",
    "leakage_percent = leakage_count / len(df) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== LEAKAGE DETECTION (ANTI-SPAM HEADERS) ===\")\n",
    "print(f\"Emails with potential leakage: {leakage_count} ({leakage_percent:.2f}% of dataset)\")\n",
    "\n",
    "if leakage_count > 0:\n",
    "    print(\"\\nWARNING: Found anti-spam headers that could cause data leakage!\")\n",
    "    print(\"DECISION: These headers should be excluded during preprocessing in Step 3.\")\n",
    "else:\n",
    "    print(\"\\nNo anti-spam headers detected. No special handling required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c298563",
   "metadata": {},
   "source": [
    "## Step 2.6 — Distinctive lexicon (top n-grams)\n",
    "\n",
    "* **Preprocess text**: lowercase, remove punctuation/numbers, normalize spaces (no stemming/lemmatization).\n",
    "* **Vectorize with counts**: `CountVectorizer` on unigrams/bigrams with English stopwords; skip empty docs.\n",
    "* **Split corpora**: SPAM vs HAM and `subject` vs `body`.\n",
    "* **Rank terms**: show top-K n-grams (with frequencies) for each corpus.\n",
    "* **Why**: highlights characteristic phrases per class/field to guide feature engineering, topic modeling, and custom stopword lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36d1345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating top 20 n-grams for each corpus...\n",
      "\n",
      "=== TOP UNIGRAMS IN SUBJECT ===\n",
      "SPAM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>software</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>online</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meds</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paliourg</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cheap</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>want</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>free</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>best</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prices</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xp</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>low</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>price</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>buy</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>download</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fwd</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>viagra</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>need</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cialis</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>th</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ngram  frequency\n",
       "0   software         44\n",
       "1     online         42\n",
       "2       meds         41\n",
       "3        new         41\n",
       "4   paliourg         36\n",
       "5      cheap         33\n",
       "6       want         31\n",
       "7       free         31\n",
       "8       best         30\n",
       "9     prices         27\n",
       "10        xp         27\n",
       "11       low         25\n",
       "12     price         25\n",
       "13       buy         25\n",
       "14  download         24\n",
       "15       fwd         23\n",
       "16    viagra         22\n",
       "17      need         22\n",
       "18    cialis         22\n",
       "19        th         21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HAM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meter</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gas</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actuals</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nomination</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fw</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>noms</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deal</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tenaska</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>april</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>change</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>march</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>june</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>july</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eastrans</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>revised</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>new</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>iv</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ngram  frequency\n",
       "0          hpl        582\n",
       "1          nom        338\n",
       "2        meter        333\n",
       "3        enron        276\n",
       "4          gas        232\n",
       "5      actuals        214\n",
       "6   nomination        209\n",
       "7           fw        177\n",
       "8         noms        148\n",
       "9         deal        134\n",
       "10     tenaska        107\n",
       "11       april        101\n",
       "12      change        100\n",
       "13       march        100\n",
       "14        june         95\n",
       "15        july         93\n",
       "16    eastrans         91\n",
       "17     revised         83\n",
       "18         new         83\n",
       "19          iv         80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP BIGRAMS IN SUBJECT ===\n",
      "SPAM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>instant download</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soft tabs</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charset ascii</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>windows xp</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>office xp</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi paliourg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prescription needed</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>penis growth</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fix penis</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cialis soft</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>low prices</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>download date</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>download coupon</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>write review</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>solution penis</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rom download</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ise media</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>average customer</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>june th</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>price save</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ngram  frequency\n",
       "0      instant download         13\n",
       "1             soft tabs         12\n",
       "2         charset ascii         11\n",
       "3            windows xp         10\n",
       "4             office xp         10\n",
       "5           hi paliourg          9\n",
       "6   prescription needed          7\n",
       "7          penis growth          7\n",
       "8             fix penis          7\n",
       "9           cialis soft          7\n",
       "10           low prices          7\n",
       "11        download date          6\n",
       "12      download coupon          6\n",
       "13         write review          6\n",
       "14       solution penis          6\n",
       "15         rom download          6\n",
       "16            ise media          6\n",
       "17     average customer          6\n",
       "18              june th          6\n",
       "19           price save          6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HAM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enron hpl</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpl actuals</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tenaska iv</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gas nomination</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>calpine daily</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eastrans nomination</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>daily gas</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>noms actual</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>actual flow</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hpl meter</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hpl noms</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nomination change</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>enron actuals</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>change effective</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nom march</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>actuals august</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>actuals july</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>natural gas</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nom april</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ngram  frequency\n",
       "0               hpl nom        234\n",
       "1             enron hpl        185\n",
       "2           hpl actuals        168\n",
       "3            tenaska iv         80\n",
       "4        gas nomination         70\n",
       "5         calpine daily         54\n",
       "6   eastrans nomination         53\n",
       "7             daily gas         49\n",
       "8           noms actual         45\n",
       "9           actual flow         44\n",
       "10            hpl meter         43\n",
       "11             hpl noms         40\n",
       "12    nomination change         39\n",
       "13        enron actuals         36\n",
       "14     change effective         35\n",
       "15            nom march         34\n",
       "16       actuals august         28\n",
       "17         actuals july         28\n",
       "18          natural gas         26\n",
       "19            nom april         24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP UNIGRAMS IN BODY ===\n",
      "SPAM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>information</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>font</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>td</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>statements</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>email</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>price</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nbsp</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>new</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>height</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>time</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>width</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pills</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>size</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>message</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>investment</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>free</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ngram  frequency\n",
       "0           com        989\n",
       "1          http        983\n",
       "2       company        723\n",
       "3           www        587\n",
       "4   information        513\n",
       "5          font        511\n",
       "6            td        504\n",
       "7    statements        476\n",
       "8         email        471\n",
       "9         price        446\n",
       "10         nbsp        418\n",
       "11          new        391\n",
       "12       height        362\n",
       "13         time        342\n",
       "14        width        306\n",
       "15        pills        303\n",
       "16         size        301\n",
       "17      message        285\n",
       "18   investment        284\n",
       "19         free        282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HAM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ect</td>\n",
       "      <td>13893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hou</td>\n",
       "      <td>7281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron</td>\n",
       "      <td>6279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject</td>\n",
       "      <td>2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deal</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gas</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cc</td>\n",
       "      <td>2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pm</td>\n",
       "      <td>2325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meter</td>\n",
       "      <td>2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>daren</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hpl</td>\n",
       "      <td>1736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>corp</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>know</td>\n",
       "      <td>1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mmbtu</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>forwarded</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>need</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>farmer</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>let</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ngram  frequency\n",
       "0         ect      13893\n",
       "1         hou       7281\n",
       "2       enron       6279\n",
       "3     subject       2728\n",
       "4         com       2693\n",
       "5        deal       2655\n",
       "6         gas       2629\n",
       "7          cc       2357\n",
       "8          pm       2325\n",
       "9       meter       2126\n",
       "10      daren       1897\n",
       "11     thanks       1810\n",
       "12        hpl       1736\n",
       "13       corp       1701\n",
       "14       know       1436\n",
       "15      mmbtu       1345\n",
       "16  forwarded       1292\n",
       "17       need       1254\n",
       "18     farmer       1137\n",
       "19        let       1083"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP BIGRAMS IN BODY ===\n",
      "SPAM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http www</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nbsp nbsp</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computron com</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>href http</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking statements</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pills pills</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>width height</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>src http</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>www computron</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>forward looking</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http nd</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>td td</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>investment advice</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>font size</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>td tr</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tr td</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>align center</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>size pt</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>duty free</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ali duty</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ngram  frequency\n",
       "0             http www        409\n",
       "1            nbsp nbsp        296\n",
       "2        computron com        195\n",
       "3            href http        175\n",
       "4   looking statements        172\n",
       "5          pills pills        169\n",
       "6         width height        164\n",
       "7             src http        157\n",
       "8        www computron        152\n",
       "9      forward looking        142\n",
       "10             http nd        136\n",
       "11               td td        134\n",
       "12   investment advice        118\n",
       "13           font size        113\n",
       "14               td tr        111\n",
       "15               tr td         94\n",
       "16        align center         91\n",
       "17             size pt         87\n",
       "18           duty free         82\n",
       "19            ali duty         81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HAM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hou ect</td>\n",
       "      <td>7226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ect ect</td>\n",
       "      <td>6339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron enron</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ect cc</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corp enron</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cc subject</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>let know</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>daren farmer</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>enron com</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ect subject</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ect pm</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>farmer hou</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>attached file</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>original message</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pec pec</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>teco tap</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>enron cc</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ami chokshi</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gas daily</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>north america</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ngram  frequency\n",
       "0            hou ect       7226\n",
       "1            ect ect       6339\n",
       "2        enron enron       1440\n",
       "3             ect cc       1391\n",
       "4         corp enron       1210\n",
       "5         cc subject       1099\n",
       "6           let know        980\n",
       "7       daren farmer        933\n",
       "8          enron com        824\n",
       "9        ect subject        730\n",
       "10            ect pm        567\n",
       "11        farmer hou        563\n",
       "12     attached file        501\n",
       "13  original message        437\n",
       "14           pec pec        357\n",
       "15          teco tap        332\n",
       "16          enron cc        314\n",
       "17       ami chokshi        304\n",
       "18         gas daily        303\n",
       "19     north america        301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define preprocessing function for n-grams\n",
    "def preprocess_for_ngrams(text):\n",
    "    text = str(text).strip() if pd.notna(text) else ''\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Function to get top n-grams\n",
    "def get_top_ngrams(corpus, n, top_k=20):\n",
    "    corpus = [preprocess_for_ngrams(text) for text in corpus]\n",
    "    \n",
    "    # Skip empty texts\n",
    "    corpus = [text for text in corpus if text.strip()]\n",
    "    \n",
    "    if not corpus:\n",
    "        return pd.DataFrame({'ngram': [], 'frequency': []})\n",
    "    \n",
    "    # Create vectorizer and fit\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english')\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    # Get feature names and frequencies\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    frequencies = X.sum(axis=0).A1\n",
    "    \n",
    "    # Create DataFrame and sort\n",
    "    ngram_df = pd.DataFrame({'ngram': feature_names, 'frequency': frequencies})\n",
    "    ngram_df = ngram_df.sort_values('frequency', ascending=False).head(top_k).reset_index(drop=True)\n",
    "    \n",
    "    return ngram_df\n",
    "\n",
    "# Set top K parameter\n",
    "TOP_K = 20\n",
    "print(f\"Generating top {TOP_K} n-grams for each corpus...\")\n",
    "\n",
    "# Split data by class\n",
    "spam_subjects = df[df['label_num'] == 1]['subject']\n",
    "ham_subjects = df[df['label_num'] == 0]['subject']\n",
    "spam_bodies = df[df['label_num'] == 1]['body']\n",
    "ham_bodies = df[df['label_num'] == 0]['body']\n",
    "\n",
    "# Generate top n-grams\n",
    "print(\"\\n=== TOP UNIGRAMS IN SUBJECT ===\")\n",
    "print(\"SPAM:\")\n",
    "display(get_top_ngrams(spam_subjects, 1, TOP_K))\n",
    "print(\"\\nHAM:\")\n",
    "display(get_top_ngrams(ham_subjects, 1, TOP_K))\n",
    "\n",
    "print(\"\\n=== TOP BIGRAMS IN SUBJECT ===\")\n",
    "print(\"SPAM:\")\n",
    "display(get_top_ngrams(spam_subjects, 2, TOP_K))\n",
    "print(\"\\nHAM:\")\n",
    "display(get_top_ngrams(ham_subjects, 2, TOP_K))\n",
    "\n",
    "print(\"\\n=== TOP UNIGRAMS IN BODY ===\")\n",
    "print(\"SPAM:\")\n",
    "display(get_top_ngrams(spam_bodies, 1, TOP_K))\n",
    "print(\"\\nHAM:\")\n",
    "display(get_top_ngrams(ham_bodies, 1, TOP_K))\n",
    "\n",
    "print(\"\\n=== TOP BIGRAMS IN BODY ===\")\n",
    "print(\"SPAM:\")\n",
    "display(get_top_ngrams(spam_bodies, 2, TOP_K))\n",
    "print(\"\\nHAM:\")\n",
    "display(get_top_ngrams(ham_bodies, 2, TOP_K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010c101",
   "metadata": {},
   "source": [
    "## Step 2.7 — Definition of Done (EDA & Data Readiness)\n",
    "\n",
    "* **Duplicates:**\n",
    "  Reports how many rows are exact duplicates, number of duplicate groups, and breakdown by class (counts and %).\n",
    "  → Decision preview: keep **one** instance per duplicate group during training.\n",
    "\n",
    "* **Subject/Body stats:**\n",
    "  For `subject_length`, `body_length`, token counts, and `subject_body_ratio`, prints **median \\[Q1–Q3]** by class (SPAM vs HAM).\n",
    "\n",
    "* **Subject flags prevalence:**\n",
    "  `% True` for `subject_has_re`, `subject_has_fwd`, `subject_has_currency` by class to highlight subject-line patterns.\n",
    "\n",
    "* **Body signals comparison:**\n",
    "  For `body_url/email/phone/digit/exclamation/spam_word/%uppercase`, prints **median \\[IQR]** by class plus **SPAM/HAM ratio**.\n",
    "  Also shows detailed stats: **%>0**, **mean | >0**, and **p95** per metric and class.\n",
    "\n",
    "* **Formatting & noise:**\n",
    "  Class-wise % for `has_html`, `has_obfuscated_links`, `has_signature`, `has_disclaimer`, `has_original_message`.\n",
    "\n",
    "* **Leakage check:**\n",
    "  Counts emails containing anti-spam headers (potential label leakage). Notes required handling if any are found.\n",
    "\n",
    "* **Preprocessing decisions (to freeze for Step 3):**\n",
    "\n",
    "  * Remove exact duplicates (keep one).\n",
    "  * Extract meta-features (HTML/URL/email/phone etc.) **before** cleanup.\n",
    "  * Strip HTML and normalize whitespace/case.\n",
    "  * Replace PII with placeholders: `[URL] [EMAIL] [PHONE] [NUMBER]`.\n",
    "  * Use weighted **subject + body** text.\n",
    "  * Truncate after signatures and “Original Message” blocks.\n",
    "  * Use `class_weight=\"balanced\"` and exclude anti-spam headers from model inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebf3a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 2: DEFINITION OF DONE ===\n",
      "\n",
      "1. DUPLICATES:\n",
      "• Rows marked as duplicates: 321 (6.21% of dataset)\n",
      "• Number of duplicate groups: 143\n",
      "• Breakdown by class:\n",
      "  - ham: 264 (7.19% of class)\n",
      "  - spam: 57 (3.80% of class)\n",
      "\n",
      "2. SUBJECT/BODY STATISTICS (median [IQR]):\n",
      "• subject_length:\n",
      "  - SPAM: 32.00 [20.00-46.00]\n",
      "  - HAM: 28.00 [19.00-40.00]\n",
      "• body_length:\n",
      "  - SPAM: 507.00 [227.50-1171.00]\n",
      "  - HAM: 473.00 [190.00-1170.25]\n",
      "• subject_token_count:\n",
      "  - SPAM: 7.00 [4.00-10.00]\n",
      "  - HAM: 6.00 [4.00-9.00]\n",
      "• body_token_count:\n",
      "  - SPAM: 105.00 [46.00-232.00]\n",
      "  - HAM: 118.00 [44.00-284.00]\n",
      "• subject_body_ratio:\n",
      "  - SPAM: 0.06 [0.02-0.15]\n",
      "  - HAM: 0.05 [0.02-0.15]\n",
      "\n",
      "2.1. SUBJECT FLAGS PREVALENCE (%):\n",
      "Class                   HAM  SPAM\n",
      "Flag                             \n",
      "subject_has_currency   0.19  3.80\n",
      "subject_has_fwd        4.52  2.67\n",
      "subject_has_re        19.20  5.34\n",
      "\n",
      "3. BODY SIGNALS COMPARISON (median [IQR]):\n",
      "                   Metric SPAM (median [IQR]) HAM (median [IQR]) SPAM/HAM ratio\n",
      "                url_count    0.00 [0.00-0.00]   0.00 [0.00-0.00]          0.00x\n",
      "              email_count    0.00 [0.00-0.00]   0.00 [0.00-0.00]          0.00x\n",
      "              phone_count    0.00 [0.00-0.00]   0.00 [0.00-2.00]          0.00x\n",
      "              digit_count   5.00 [0.00-20.00] 24.00 [6.00-53.00]          0.21x\n",
      "        exclamation_count    0.00 [0.00-2.00]   0.00 [0.00-0.00]          0.00x\n",
      "percent_uppercase_letters    0.00 [0.00-0.00]   0.00 [0.00-0.00]          0.00x\n",
      "          spam_word_count    0.00 [0.00-1.00]   0.00 [0.00-0.00]          0.00x\n",
      "\n",
      "3.1. BODY SIGNALS: PREVALENCE, CONDITIONAL MEAN, AND P95:\n",
      "  Class % url_count>0 % email_count>0 % phone_count>0 % digit_count>0  \\\n",
      "0  SPAM         0.00%           0.00%          21.21%          70.65%   \n",
      "1   HAM         0.00%           0.00%          49.73%          91.09%   \n",
      "\n",
      "  % exclamation_count>0 % spam_word_count>0 mean url_count|>0  \\\n",
      "0                45.83%              37.16%               nan   \n",
      "1                12.96%               8.80%               nan   \n",
      "\n",
      "  mean email_count|>0 mean phone_count|>0 mean digit_count|>0  \\\n",
      "0                 nan                2.84               36.30   \n",
      "1                 nan                4.01               47.06   \n",
      "\n",
      "  mean exclamation_count|>0 mean spam_word_count|>0 p95 url_count  \\\n",
      "0                      3.21                    2.09             0   \n",
      "1                      2.29                    1.95             0   \n",
      "\n",
      "  p95 email_count p95 phone_count p95 digit_count p95 exclamation_count  \\\n",
      "0               0               3             109                     6   \n",
      "1               0               8             147                     2   \n",
      "\n",
      "  p95 spam_word_count  \n",
      "0                   3  \n",
      "1                   1  \n",
      "\n",
      "4. FORMATTING & NOISE:\n",
      "• has_html:\n",
      "  - SPAM: 0.00%\n",
      "  - HAM: 0.00%\n",
      "• has_obfuscated_links:\n",
      "  - SPAM: 0.00%\n",
      "  - HAM: 0.00%\n",
      "• has_signature:\n",
      "  - SPAM: 0.00%\n",
      "  - HAM: 0.00%\n",
      "• has_disclaimer:\n",
      "  - SPAM: 2.47%\n",
      "  - HAM: 0.95%\n",
      "• has_original_message:\n",
      "  - SPAM: 0.00%\n",
      "  - HAM: 0.00%\n",
      "\n",
      "5. LEAKAGE:\n",
      "• Anti-spam headers: 0 emails (0.00% of dataset)\n",
      "• No leakage detected\n",
      "\n",
      "6. DECISIONS FOR STEP 3:\n",
      "• Remove exact duplicates in training, keeping one instance per group\n",
      "• Extract meta-features from HTML/URL/email/phone before cleanup\n",
      "• Remove HTML tags and normalize whitespace/case\n",
      "• Apply PII placeholders: [URL] [EMAIL] [PHONE] [NUMBER]\n",
      "• Use weighted combination of subject + body\n",
      "• Truncate content after signatures and 'Original Message' blocks\n",
      "• Use class_weight=\"balanced\" in the model (automatically handles class imbalance).\n",
      "• Exclude any anti-spam headers (X-Spam-Flag, Spam-Score, X-Spam-Status, X-Spam-Level, SpamAssassin) from the text used for the model (not detected here).\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 2: DEFINITION OF DONE ===\")\n",
    "\n",
    "# 1. Duplicates summary\n",
    "print(\"\\n1. DUPLICATES:\")\n",
    "print(f\"• Rows marked as duplicates: {n_rows_dup_marked} ({n_rows_dup_marked/len(df)*100:.2f}% of dataset)\")\n",
    "print(f\"• Number of duplicate groups: {n_groups_dup}\")\n",
    "print(\"• Breakdown by class:\")\n",
    "for label, count in dup_by_class.items():\n",
    "    print(f\"  - {label}: {count} ({dup_pct_by_class[label]:.2f}% of class)\")\n",
    "\n",
    "# 2. Subject/Body statistics\n",
    "print(\"\\n2. SUBJECT/BODY STATISTICS (median [IQR]):\")\n",
    "for metric in metrics:\n",
    "    spam_data = df[df['label_num'] == 1][metric]\n",
    "    ham_data = df[df['label_num'] == 0][metric]\n",
    "    \n",
    "    spam_median = spam_data.median()\n",
    "    spam_q1 = spam_data.quantile(0.25)\n",
    "    spam_q3 = spam_data.quantile(0.75)\n",
    "    \n",
    "    ham_median = ham_data.median()\n",
    "    ham_q1 = ham_data.quantile(0.25)\n",
    "    ham_q3 = ham_data.quantile(0.75)\n",
    "    \n",
    "    print(f\"• {metric}:\")\n",
    "    print(f\"  - SPAM: {spam_median:.2f} [{spam_q1:.2f}-{spam_q3:.2f}]\")\n",
    "    print(f\"  - HAM: {ham_median:.2f} [{ham_q1:.2f}-{ham_q3:.2f}]\")\n",
    "\n",
    "# 2.1 Subject flags prevalence\n",
    "print(\"\\n2.1. SUBJECT FLAGS PREVALENCE (%):\")\n",
    "flag_cols = [\"subject_has_re\",\"subject_has_fwd\",\"subject_has_currency\"]\n",
    "rows = []\n",
    "for lbl, name in [(1,\"SPAM\"), (0,\"HAM\")]:\n",
    "    sub = df.loc[df.label_num==lbl, flag_cols]\n",
    "    for c in flag_cols:\n",
    "        rows.append({\"Class\": name, \"Flag\": c, \"Prevalence %\": round(sub[c].mean()*100, 2)})\n",
    "prevalence_df = pd.DataFrame(rows).pivot(index=\"Flag\", columns=\"Class\", values=\"Prevalence %\")\n",
    "print(prevalence_df)\n",
    "\n",
    "# 3. Body signals comparison\n",
    "print(\"\\n3. BODY SIGNALS COMPARISON (median [IQR]):\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# 3.1 Body signals: detailed stats\n",
    "print(\"\\n3.1. BODY SIGNALS: PREVALENCE, CONDITIONAL MEAN, AND P95:\")\n",
    "count_cols = [\"body_url_count\",\"body_email_count\",\"body_phone_count\",\n",
    "              \"body_digit_count\",\"body_exclamation_count\",\"body_spam_word_count\"]\n",
    "out_rows = []\n",
    "for lbl, name in [(1,\"SPAM\"), (0,\"HAM\")]:\n",
    "    sub = df.loc[df.label_num==lbl, count_cols]\n",
    "    gt0 = (sub > 0).mean()*100\n",
    "    cond_mean = sub.where(sub>0).mean()\n",
    "    p95 = sub.quantile(0.95)\n",
    "    out = {\"Class\": name}\n",
    "    out.update({f\"% {c.split('_',1)[1]}>0\": f\"{gt0[c]:.2f}%\" for c in count_cols})\n",
    "    out.update({f\"mean {c.split('_',1)[1]}|>0\": f\"{cond_mean[c]:.2f}\" for c in count_cols})\n",
    "    out.update({f\"p95 {c.split('_',1)[1]}\": f\"{p95[c]:.0f}\" for c in count_cols})\n",
    "    out_rows.append(out)\n",
    "detailed_stats_df = pd.DataFrame(out_rows)\n",
    "print(detailed_stats_df)\n",
    "\n",
    "# 4. Formatting percentages\n",
    "print(\"\\n4. FORMATTING & NOISE:\")\n",
    "for flag in flags:\n",
    "    spam_pct = df[df['label_num'] == 1][flag].mean() * 100\n",
    "    ham_pct = df[df['label_num'] == 0][flag].mean() * 100\n",
    "    \n",
    "    print(f\"• {flag}:\")\n",
    "    print(f\"  - SPAM: {spam_pct:.2f}%\")\n",
    "    print(f\"  - HAM: {ham_pct:.2f}%\")\n",
    "\n",
    "# 5. Leakage\n",
    "print(\"\\n5. LEAKAGE:\")\n",
    "print(f\"• Anti-spam headers: {leakage_count} emails ({leakage_percent:.2f}% of dataset)\")\n",
    "if leakage_count > 0:\n",
    "    print(\"• DECISION: Exclude anti-spam headers during preprocessing in Step 3\")\n",
    "else:\n",
    "    print(\"• No leakage detected\")\n",
    "\n",
    "# 6. Decisions for Step 3\n",
    "print(\"\\n6. DECISIONS FOR STEP 3:\")\n",
    "print(\"• Remove exact duplicates in training, keeping one instance per group\")\n",
    "print(\"• Extract meta-features from HTML/URL/email/phone before cleanup\")\n",
    "print(\"• Remove HTML tags and normalize whitespace/case\")\n",
    "print(\"• Apply PII placeholders: [URL] [EMAIL] [PHONE] [NUMBER]\")\n",
    "print(\"• Use weighted combination of subject + body\")\n",
    "print(\"• Truncate content after signatures and 'Original Message' blocks\")\n",
    "print(\"• Use class_weight=\\\"balanced\\\" in the model (automatically handles class imbalance).\")\n",
    "print(\"• Exclude any anti-spam headers (X-Spam-Flag, Spam-Score, X-Spam-Status, X-Spam-Level, SpamAssassin) from the text used for the model (not detected here).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a620d42",
   "metadata": {},
   "source": [
    "## Step 2.8 — Preprocessing Freeze & Setup\n",
    "\n",
    "* **Fix the knobs** we’ll use downstream:\n",
    "\n",
    "  * `RANDOM_STATE=42` for reproducibility\n",
    "  * `N_FOLDS=5` for stratified CV\n",
    "  * `SUBJECT_WEIGHT=2` so the subject line counts twice in the text mix\n",
    "\n",
    "* **Target definition:** `label_num` (0 = HAM, 1 = SPAM) and a quick print of the current class balance.\n",
    "\n",
    "* **Freeze the meta-feature schema** (from EDA findings) so later cells use a **stable** set:\n",
    "\n",
    "  * Subject: `subject_has_re`, `subject_has_fwd`, `subject_has_currency`, `subject_digit_count`, `subject_exclamation_count`, `subject_length`, `subject_body_ratio`\n",
    "  * Body: `body_phone_count`, `body_digit_count`, `body_exclamation_count`, `body_spam_word_count`, `body_length`\n",
    "\n",
    "* **Preview only:** build `meta_X` (meta features) and `y` to show an example row; **no dedup here** (it will be applied in training).\n",
    "\n",
    "* **Preprocessing decisions to carry forward (frozen):**\n",
    "\n",
    "  * Extract meta-features **before** cleaning.\n",
    "  * Strip HTML, normalize case/whitespace.\n",
    "  * Replace PII with placeholders `[URL] [EMAIL] [PHONE] [NUMBER]`.\n",
    "  * Weight **subject** more than body (2:1).\n",
    "  * Truncate after signatures / “Original Message”.\n",
    "  * Use `class_weight=\"balanced\"`.\n",
    "  * Exclude anti-spam headers to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b2c125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPROCESSING SETUP ===\n",
      "• Random Seed: 42\n",
      "• Cross-validation folds: 5\n",
      "• Subject weight: 2x\n",
      "\n",
      "=== TARGET VARIABLE ===\n",
      "• Using 'label_num' as target (0=HAM, 1=SPAM)\n",
      "• Class distribution: {0: 3672, 1: 1499}\n",
      "\n",
      "=== EXAMPLE META-FEATURES (first sample) ===\n",
      "• subject_has_re: 0.0\n",
      "• subject_has_fwd: 0.0\n",
      "• subject_has_currency: 0.0\n",
      "• subject_digit_count: 6.0\n",
      "• subject_exclamation_count: 0.0\n",
      "• subject_length: 33.0\n",
      "• subject_body_ratio: 0.11827956989247312\n",
      "• body_phone_count: 0.0\n",
      "• body_digit_count: 4.0\n",
      "• body_exclamation_count: 0.0\n",
      "• body_spam_word_count: 0.0\n",
      "• body_length: 279.0\n",
      "\n",
      "=== PREPROCESSING DECISIONS ===\n",
      "• Training data will use deduplication (one instance per group)\n",
      "• Text preprocessing will:\n",
      "  - Extract meta-features (shown above) before cleaning\n",
      "  - Remove HTML tags and normalize whitespace/case\n",
      "  - Apply PII placeholders: [URL] [EMAIL] [PHONE] [NUMBER]\n",
      "  - Weight subject higher than body (ratio 2:1)\n",
      "  - Truncate content after signatures and 'Original Message' blocks\n",
      "  - Use balanced class weights in the model\n",
      "  - Exclude anti-spam headers that could cause leakage\n"
     ]
    }
   ],
   "source": [
    "# Set key parameters\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "SUBJECT_WEIGHT = 2\n",
    "\n",
    "print(\"=== PREPROCESSING SETUP ===\")\n",
    "print(f\"• Random Seed: {RANDOM_STATE}\")\n",
    "print(f\"• Cross-validation folds: {N_FOLDS}\")\n",
    "print(f\"• Subject weight: {SUBJECT_WEIGHT}x\")\n",
    "\n",
    "# Define target variable\n",
    "print(\"\\n=== TARGET VARIABLE ===\")\n",
    "print(\"• Using 'label_num' as target (0=HAM, 1=SPAM)\")\n",
    "print(f\"• Class distribution: {df['label_num'].value_counts().to_dict()}\")\n",
    "\n",
    "# Define meta-features list based on analysis\n",
    "subject_meta_features = [\n",
    "  'subject_has_re', 'subject_has_fwd', 'subject_has_currency',\n",
    "  'subject_digit_count', 'subject_exclamation_count',\n",
    "  'subject_length', 'subject_body_ratio'\n",
    "]\n",
    "body_meta_features = [\n",
    "  'body_phone_count', 'body_digit_count',\n",
    "  'body_exclamation_count', 'body_spam_word_count',\n",
    "  'body_length'\n",
    "]\n",
    "all_meta_features = subject_meta_features + body_meta_features\n",
    "\n",
    "\n",
    "# Create a copy of the dataframe for training with meta-features\n",
    "# Note: Deduplication will be done in the training phase, not here\n",
    "meta_X = df[all_meta_features].copy()\n",
    "y = df['label_num'].copy()\n",
    "\n",
    "# Display example of meta-features for one sample\n",
    "print(\"\\n=== EXAMPLE META-FEATURES (first sample) ===\")\n",
    "example = meta_X.iloc[0].to_dict()\n",
    "for feature, value in example.items():\n",
    "    print(f\"• {feature}: {value}\")\n",
    "\n",
    "print(\"\\n=== PREPROCESSING DECISIONS ===\")\n",
    "print(\"• Training data will use deduplication (one instance per group)\")\n",
    "print(\"• Text preprocessing will:\")\n",
    "print(\"  - Extract meta-features (shown above) before cleaning\")\n",
    "print(\"  - Remove HTML tags and normalize whitespace/case\")\n",
    "print(\"  - Apply PII placeholders: [URL] [EMAIL] [PHONE] [NUMBER]\")\n",
    "print(\"  - Weight subject higher than body (ratio 2:1)\")\n",
    "print(\"  - Truncate content after signatures and 'Original Message' blocks\")\n",
    "print(\"  - Use balanced class weights in the model\")\n",
    "print(\"  - Exclude anti-spam headers that could cause leakage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c14a0e",
   "metadata": {},
   "source": [
    "# Step 3 — Preprocessing functions (text + meta)\n",
    "\n",
    "**Goal:** build a model-ready table by cleaning text and keeping the meta-features defined in Step 2.8.\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "* **Uses precomputed meta-features** (no recalculation here).\n",
    "* **Cleans text** with `clean_text()` (in order):\n",
    "\n",
    "  1. strip HTML tags\n",
    "  2. drop anti-spam headers (`X-Spam-*`, `SpamAssassin`, …)\n",
    "  3. truncate after signatures (`--\\n`) and *Original Message* blocks\n",
    "  4. replace PII with placeholders: `[URL]`, `[EMAIL]`, `[PHONE]`, `[NUMBER]`\n",
    "  5. lowercase + normalize whitespace\n",
    "* **Builds a weighted text field** with `create_weighted_text()`:\n",
    "\n",
    "  * concatenates `subject` and `body`, weighting the subject by `SUBJECT_WEIGHT` (set to 2).\n",
    "* **Creates `df_ready`** via `create_model_ready_df()`:\n",
    "\n",
    "  * adds `text_weighted` → `text_clean`\n",
    "  * (optionally) removes exact duplicates *(currently `deduplicate=False` to keep full data; dedup will happen at training split)*\n",
    "  * keeps only `[meta features] + text_clean + label_num`\n",
    "  * guards against NaN/Inf and empty texts (replaces with safe values / `[EMPTY_TEXT]`)\n",
    "\n",
    "**Outputs printed**\n",
    "\n",
    "* Example *before vs after* cleaning.\n",
    "* Length stats on `text_clean` (overall and by class).\n",
    "* Final shape and feature count of `df_ready`.\n",
    "\n",
    "**Why this order matters**\n",
    "\n",
    "* We extract meta-signals from raw text upstream (already done), then clean aggressively to avoid leakage and noise before vectorization in the modeling step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78e897bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPROCESSING FUNCTIONS ===\n",
      "• Using pre-calculated meta-features from previous steps\n",
      "\n",
      "Total meta-features: 12\n",
      "\n",
      "• Creating model-ready DataFrame...\n",
      "\n",
      "• Creating weighted text (subject×2):\n",
      "• Cleaning text with full pipeline\n",
      "WARNING: Found 16 empty text_clean values\n",
      "  → Replaced empty texts with '[EMPTY_TEXT]' placeholder\n",
      "\n",
      "=== EXAMPLE: BEFORE vs AFTER CLEANING ===\n",
      "ORIGINAL:\n",
      "Subject: enron methanol ; meter # : 988291\n",
      "this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary\n",
      "flow data provided by daren } .\n",
      "please override pop ' s daily volume { presently zero } to reflect daily\n",
      "activity you can obtain from gas control .\n",
      "this change is needed asap for economics purposes ....\n",
      "\n",
      "CLEANED:\n",
      "enron methanol ; meter # : [number] enron methanol ; meter # : [number] this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary flow data provided by daren } . please override pop ' s daily volume { presently zero } to reflect daily activity you can obtain from gas control . this change is needed asap for economics purposes ....\n",
      "\n",
      "=== TEXT_CLEAN STATISTICS ===\n",
      "• Mean length: 1059.93 chars\n",
      "• Median length: 562.00 chars\n",
      "• Min length: 4 chars\n",
      "• Max length: 31964 chars\n",
      "\n",
      "• Length distribution by class:\n",
      "  - SPAM: 589.00 chars [IQR: 301.50-1273.50]\n",
      "  - HAM: 548.50 chars [IQR: 250.00-1235.25]\n",
      "\n",
      "=== PREPROCESSING COMPLETE ===\n",
      "• Final DataFrame shape: (5171, 15)\n",
      "• Features: 12 meta-features + text_clean\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PREPROCESSING FUNCTIONS ===\")\n",
    "\n",
    "# 1. Meta-features first (already calculated in df)\n",
    "print(\"• Using pre-calculated meta-features from previous steps\")\n",
    "\n",
    "# 2. Text cleaning functions\n",
    "def clean_text(text, remove_leakage=True, truncate=True, replace_pii=True, normalize=True):\n",
    "    \"\"\"\n",
    "    Complete text cleaning pipeline:\n",
    "    - Remove HTML\n",
    "    - Remove anti-spam headers (optional)\n",
    "    - Truncate after signatures and 'Original Message' (optional)\n",
    "    - Replace PII with placeholders (optional)\n",
    "    - Normalize whitespace and lowercase (optional)\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove HTML\n",
    "    if '<' in text and '>' in text:  # Quick check before applying expensive regex\n",
    "        text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    \n",
    "    # Remove anti-spam headers (potential data leakage)\n",
    "    if remove_leakage:\n",
    "        leakage_pattern = r'(?im)^(X-Spam-Flag|Spam-Score|X-Spam-Status|X-Spam-Level|SpamAssassin):.*?$\\n?'\n",
    "        text = re.sub(leakage_pattern, '', text)\n",
    "    \n",
    "    # Truncate after signatures and 'Original Message'\n",
    "    if truncate:\n",
    "        # Signatures (common pattern: --\\n)\n",
    "        signature_match = re.search(r'--\\s*\\n', text)\n",
    "        if signature_match:\n",
    "            text = text[:signature_match.start()].strip()\n",
    "        \n",
    "        # 'Original Message' block\n",
    "        orig_msg_patterns = [\n",
    "            r'(?im)^-{2,}\\s*Original Message\\s*-{2,}',\n",
    "            r'(?ims)^\\s*From: .+\\n\\s*Sent: .+\\n\\s*To: .+\\n\\s*Subject: .+'\n",
    "        ]\n",
    "        \n",
    "        for pattern in orig_msg_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                text = text[:match.start()].strip()\n",
    "    \n",
    "    # Replace PII with placeholders\n",
    "    if replace_pii:\n",
    "        # URLs\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '[URL]', text)\n",
    "        \n",
    "        # Email addresses\n",
    "        text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', text)\n",
    "        \n",
    "        # Phone numbers (various formats)\n",
    "        text = re.sub(r'\\+?\\d[\\d\\s\\-\\(\\)]{7,}\\d', '[PHONE]', text)\n",
    "        \n",
    "        # Number sequences (4+ consecutive digits)\n",
    "        text = re.sub(r'\\b\\d{4,}\\b', '[NUMBER]', text)\n",
    "    \n",
    "    # Normalization\n",
    "    if normalize:\n",
    "        # Lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 3. Function for subject weighting\n",
    "def create_weighted_text(row, subject_weight):\n",
    "    \"\"\"\n",
    "    Create text_weighted = (subject + \" \")*SUBJECT_WEIGHT + body\n",
    "    \"\"\"\n",
    "    subject = str(row['subject']) if pd.notna(row['subject']) else ''\n",
    "    body = str(row['body']) if pd.notna(row['body']) else ''\n",
    "    \n",
    "    # If subject is empty but body isn't, use only body\n",
    "    if subject.strip() == '' and body.strip() != '':\n",
    "        return body\n",
    "    \n",
    "    # If body is empty but subject isn't, use only subject\n",
    "    if body.strip() == '' and subject.strip() != '':\n",
    "        return subject\n",
    "    \n",
    "    # Otherwise apply weighting\n",
    "    return (subject + \" \") * subject_weight + body\n",
    "\n",
    "# 4. Function to create model-ready DataFrame\n",
    "def create_model_ready_df(df, subject_weight, meta_features, deduplicate=True):\n",
    "    \"\"\"\n",
    "    Create model-ready dataframe:\n",
    "    - Add text_weighted and text_clean\n",
    "    - Optionally remove duplicates\n",
    "    - Keep only necessary columns (meta-features + text_clean + label)\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_ready = df.copy()\n",
    "    \n",
    "    # Create text_weighted\n",
    "    print(\"\\n• Creating weighted text (subject×{}):\".format(subject_weight))\n",
    "    df_ready['text_weighted'] = df_ready.apply(\n",
    "        lambda row: create_weighted_text(row, subject_weight), axis=1\n",
    "    )\n",
    "    \n",
    "    # Apply clean_text to text_weighted\n",
    "    print(\"• Cleaning text with full pipeline\")\n",
    "    df_ready['text_clean'] = df_ready['text_weighted'].apply(clean_text)\n",
    "    \n",
    "    # Remove duplicates (optional)\n",
    "    if deduplicate:\n",
    "        before_count = len(df_ready)\n",
    "        df_ready = df_ready.drop_duplicates('text')\n",
    "        after_count = len(df_ready)\n",
    "        print(f\"• Removed {before_count - after_count} duplicates ({(before_count - after_count)/before_count*100:.2f}% of data)\")\n",
    "    \n",
    "    # Select columns to keep\n",
    "    keep_cols = meta_features + ['text_clean', 'label_num']\n",
    "    df_ready = df_ready[keep_cols]\n",
    "    \n",
    "    # Check: no NaN/inf in meta-features\n",
    "    nan_meta = df_ready[meta_features].isna().sum().sum()\n",
    "    inf_meta = np.isinf(df_ready[meta_features].values).sum()\n",
    "    \n",
    "    if nan_meta > 0 or inf_meta > 0:\n",
    "        print(f\"WARNING: Found {nan_meta} NaN and {inf_meta} Inf values in meta-features\")\n",
    "        # Fill NaN with 0 and replace Inf with very large but finite values\n",
    "        df_ready[meta_features] = df_ready[meta_features].fillna(0)\n",
    "        df_ready[meta_features] = df_ready[meta_features].replace([np.inf, -np.inf], [1e9, -1e9])\n",
    "        print(\"  → Replaced NaN with 0 and Inf with ±1e9\")\n",
    "    \n",
    "    # Check: text_clean not empty\n",
    "    empty_texts = (df_ready['text_clean'] == '').sum()\n",
    "    if empty_texts > 0:\n",
    "        print(f\"WARNING: Found {empty_texts} empty text_clean values\")\n",
    "        # Insert placeholder for empty texts\n",
    "        df_ready.loc[df_ready['text_clean'] == '', 'text_clean'] = '[EMPTY_TEXT]'\n",
    "        print(\"  → Replaced empty texts with '[EMPTY_TEXT]' placeholder\")\n",
    "    \n",
    "    return df_ready\n",
    "\n",
    "\n",
    "print(f\"\\nTotal meta-features: {len(all_meta_features)}\")\n",
    "\n",
    "# Create model-ready DataFrame (without deduplication yet)\n",
    "print(\"\\n• Creating model-ready DataFrame...\")\n",
    "df_ready = create_model_ready_df(\n",
    "    df, \n",
    "    subject_weight=SUBJECT_WEIGHT,\n",
    "    meta_features=all_meta_features,\n",
    "    deduplicate=False  # Don't deduplicate here, keep both train and test complete\n",
    ")\n",
    "\n",
    "# Show example of text before and after cleaning\n",
    "print(\"\\n=== EXAMPLE: BEFORE vs AFTER CLEANING ===\")\n",
    "sample_idx = 0\n",
    "print(f\"ORIGINAL:\\n{df.iloc[sample_idx]['text'][:500]}...\")\n",
    "print(f\"\\nCLEANED:\\n{df_ready.iloc[sample_idx]['text_clean'][:500]}...\")\n",
    "\n",
    "# Statistics on text_clean\n",
    "print(\"\\n=== TEXT_CLEAN STATISTICS ===\")\n",
    "df_ready['clean_length'] = df_ready['text_clean'].str.len()\n",
    "print(f\"• Mean length: {df_ready['clean_length'].mean():.2f} chars\")\n",
    "print(f\"• Median length: {df_ready['clean_length'].median():.2f} chars\")\n",
    "print(f\"• Min length: {df_ready['clean_length'].min()} chars\")\n",
    "print(f\"• Max length: {df_ready['clean_length'].max()} chars\")\n",
    "\n",
    "# Report length distribution by class\n",
    "print(\"\\n• Length distribution by class:\")\n",
    "for label, name in [(1, \"SPAM\"), (0, \"HAM\")]:\n",
    "    subset = df_ready[df_ready['label_num'] == label]['clean_length']\n",
    "    print(f\"  - {name}: {subset.median():.2f} chars [IQR: {subset.quantile(0.25):.2f}-{subset.quantile(0.75):.2f}]\")\n",
    "\n",
    "print(\"\\n=== PREPROCESSING COMPLETE ===\")\n",
    "print(f\"• Final DataFrame shape: {df_ready.shape}\")\n",
    "print(f\"• Features: {len(all_meta_features)} meta-features + text_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddd5b6",
   "metadata": {},
   "source": [
    "## Step 3.1 — Feature Representation Definition (templates + model-ready table)\n",
    "\n",
    "**What this cell does (quick):**\n",
    "\n",
    "* Defines **reusable TF-IDF templates**\n",
    "\n",
    "  * `TFIDF_WORD_TEMPLATE`: word 1–2 grams, `min_df=2`, sublinear TF, English stopwords, `max_features=150k`, unicode strip.\n",
    "  * `TFIDF_CHAR_TEMPLATE`: char 3–5 grams, `max_features=50k`.\n",
    "* Builds a **numeric branch** that keeps meta-features **sparse end-to-end** (`to_csr` → `StandardScaler(with_mean=False)`).\n",
    "* Provides a safe **text selector** (`text_selector`) that outputs a 1-D Series (`text_clean`).\n",
    "* Exposes a **factory** `build_features_transformer(all_meta_features, mode)` that returns a `ColumnTransformer`:\n",
    "\n",
    "  * `mode='word'`: word TF-IDF on `text_clean` + scaled meta-features.\n",
    "  * `mode='word_char'`: **FeatureUnion** of word + char TF-IDF on `text_clean` + scaled meta-features.\n",
    "  * Always returns a **sparse** feature matrix (`sparse_threshold=1.0`).\n",
    "* Creates **`df_ready_model`** (deduplicated) via `create_model_ready_df(...)`, **saves to CSV**, and prints:\n",
    "\n",
    "  * Shape after dedup, % rows removed,\n",
    "  * Estimated vocabulary size (with the same TF-IDF params),\n",
    "  * Approx total feature dimensionality = vocab size + #meta-features.\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "* Keeps preprocessing **DRY** (one place to change vectorizers).\n",
    "* Guarantees **sparse compatibility** across text + numeric branches.\n",
    "* Freezes a **clean, deduplicated training frame** (`df_ready_model`) so downstream CV/fit steps are reproducible and fast to reload.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "780f5945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE REPRESENTATION SETUP ===\n",
      "\n",
      "• Text Representation:\n",
      "  - Using TF-IDF Vectorizer with 1-2 grams\n",
      "  - Minimum document frequency: 2\n",
      "  - Sublinear TF scaling: Yes\n",
      "  - English stopwords: Yes\n",
      "  - Max features: 150,000\n",
      "\n",
      "=== META-FEATURES INCLUDED ===\n",
      "Subject-related:\n",
      "  - subject_has_re\n",
      "  - subject_has_fwd\n",
      "  - subject_has_currency\n",
      "  - subject_digit_count\n",
      "  - subject_exclamation_count\n",
      "  - subject_length\n",
      "  - subject_body_ratio\n",
      "\n",
      "Body-related:\n",
      "  - body_phone_count\n",
      "  - body_digit_count\n",
      "  - body_exclamation_count\n",
      "  - body_spam_word_count\n",
      "  - body_length\n",
      "\n",
      "• Creating weighted text (subject×2):\n",
      "• Cleaning text with full pipeline\n",
      "• Removed 178 duplicates (3.44% of data)\n",
      "WARNING: Found 1 empty text_clean values\n",
      "  → Replaced empty texts with '[EMPTY_TEXT]' placeholder\n",
      "df_ready_model shape: (4993, 14)\n",
      "\n",
      "Estimated vocabulary size (TF-IDF params): 71,878 n-grams\n",
      "Limited to max_features: 71,878 n-grams\n",
      "Total feature dimensionality (approx): 71,890\n",
      "Deduplicated rows: 178 (3.44%)\n",
      "\n",
      "=== FEATURE REPRESENTATION COMPLETE ===\n",
      "Templates & factory ready. Using df_ready_model for training.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== FEATURE REPRESENTATION SETUP ===\")\n",
    "\n",
    "# 1. TF-IDF for text features\n",
    "print(\"\\n• Text Representation:\")\n",
    "print(\"  - Using TF-IDF Vectorizer with 1-2 grams\")\n",
    "print(\"  - Minimum document frequency: 2\")\n",
    "print(\"  - Sublinear TF scaling: Yes\")\n",
    "print(\"  - English stopwords: Yes\")\n",
    "print(\"  - Max features: 150,000\")\n",
    "\n",
    "# --- Template TF-IDF (word) ---\n",
    "TFIDF_WORD_TEMPLATE = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    sublinear_tf=True,\n",
    "    max_features=150_000,\n",
    "    stop_words='english',\n",
    "    strip_accents='unicode',\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# --- Template TF-IDF (char) ---\n",
    "TFIDF_CHAR_TEMPLATE = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=2,\n",
    "    sublinear_tf=True,\n",
    "    max_features=50_000,\n",
    "    strip_accents='unicode',\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "def select_text_clean(X):\n",
    "    return X['text_clean']\n",
    "\n",
    "def to_csr(X):\n",
    "    return csr_matrix(X)\n",
    "\n",
    "def build_num_pipeline():\n",
    "    return Pipeline([\n",
    "        ('to_sparse', FT(to_csr, validate=False)),\n",
    "        ('scaler', StandardScaler(with_mean=False))\n",
    "    ])\n",
    "\n",
    "text_selector = FT(select_text_clean, validate=False)\n",
    "\n",
    "def build_features_transformer(all_meta_features, mode='word'):\n",
    "    num_pipeline = build_num_pipeline()\n",
    "    if mode == 'word':\n",
    "        text_branch = Pipeline([\n",
    "            ('select_text', text_selector),\n",
    "            ('tfidf', clone(TFIDF_WORD_TEMPLATE))\n",
    "        ])\n",
    "    elif mode == 'word_char':\n",
    "        text_branch = Pipeline([\n",
    "            ('select_text', text_selector),\n",
    "            ('union', FeatureUnion([\n",
    "                ('word', clone(TFIDF_WORD_TEMPLATE)),\n",
    "                ('char', clone(TFIDF_CHAR_TEMPLATE))\n",
    "            ]))\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'word' or 'word_char'\")\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text_features', text_branch, ['text_clean']),\n",
    "            ('meta_features', num_pipeline, all_meta_features)\n",
    "        ],\n",
    "        remainder='drop',\n",
    "        sparse_threshold=1.0\n",
    "    )\n",
    "\n",
    "\n",
    "def estimate_vocab_size(texts):\n",
    "    probe = clone(TFIDF_WORD_TEMPLATE)\n",
    "    probe.fit(texts)\n",
    "    return len(probe.vocabulary_)\n",
    "\n",
    "# Print information about the meta-features\n",
    "print(\"\\n=== META-FEATURES INCLUDED ===\")\n",
    "print(\"Subject-related:\")\n",
    "for feature in [f for f in all_meta_features if f.startswith('subject_')]:\n",
    "    print(f\"  - {feature}\")\n",
    "print(\"\\nBody-related:\")\n",
    "for feature in [f for f in all_meta_features if f.startswith('body_')]:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "# Create model-ready DataFrame without \n",
    "df_ready_model = create_model_ready_df(\n",
    "    df,\n",
    "    subject_weight=SUBJECT_WEIGHT,\n",
    "    meta_features=all_meta_features,\n",
    "    deduplicate=True \n",
    ")\n",
    "\n",
    "df_ready_model.to_csv(\"df_ready_model.csv\", index=False)\n",
    "print(\"df_ready_model shape:\", df_ready_model.shape)\n",
    "\n",
    "# Estimate vocabulary size\n",
    "vocab_size = estimate_vocab_size(df_ready_model['text_clean'])\n",
    "print(f\"\\nEstimated vocabulary size (TF-IDF params): {vocab_size:,} n-grams\")\n",
    "print(f\"Limited to max_features: {min(vocab_size, TFIDF_WORD_TEMPLATE.max_features):,} n-grams\")\n",
    "\n",
    "feature_dim = min(vocab_size, TFIDF_WORD_TEMPLATE.max_features or vocab_size) + len(all_meta_features)\n",
    "print(f\"Total feature dimensionality (approx): {feature_dim:,}\")\n",
    "print(f\"Deduplicated rows: {len(df) - len(df_ready_model)} \"\n",
    "      f\"({(len(df) - len(df_ready_model)) / len(df) * 100:.2f}%)\")\n",
    "\n",
    "print(\"\\n=== FEATURE REPRESENTATION COMPLETE ===\")\n",
    "print(\"Templates & factory ready. Using df_ready_model for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb92943",
   "metadata": {},
   "source": [
    "## Step 3.2 — Baseline Model Setup\n",
    "\n",
    "**What this cell does (quick):**\n",
    "\n",
    "* Defines a **baseline classifier**:\n",
    "\n",
    "  * `LogisticRegression` with `class_weight=\"balanced\"`, `solver=\"liblinear\"`, `max_iter=2000`.\n",
    "  * Robust for sparse, imbalanced text data.\n",
    "* Builds two **pipelines**:\n",
    "\n",
    "  * **Pipeline A** → TF-IDF (word 1–2 grams) + meta-features + LogisticRegression.\n",
    "  * **Pipeline B** → TF-IDF (word 1–2 grams + char 3–5 grams) + meta-features + LogisticRegression.\n",
    "* Runs a **quick check** on a sample (≤1000 rows):\n",
    "\n",
    "  * Confirms **sparse matrices** are returned.\n",
    "  * Prints **shapes** (feature dimensionality) for both configs.\n",
    "* Sets **Pipeline A as the default baseline** (lighter memory, faster fit), with Pipeline B reserved for comparison.\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "* Provides a **stable reference model** to benchmark improvements.\n",
    "* Confirms end-to-end integration of text + meta-features into a single sparse design matrix.\n",
    "* Ensures that all preprocessing choices (deduplication, TF-IDF limits, meta-features) are already baked into the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f95aaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE MODEL SETUP ===\n",
      "A sparse? True (1000, 13850)\n",
      "B sparse? True (1000, 63850)\n",
      "\n",
      "=== BASELINE MODEL READY ===\n",
      "Default: Version A (Word n-grams); Version B for comparison.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== BASELINE MODEL SETUP ===\")\n",
    "\n",
    "baseline_model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=2000,\n",
    "    solver=\"liblinear\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "features_transformer_A = build_features_transformer(all_meta_features, mode='word')\n",
    "features_transformer_B = build_features_transformer(all_meta_features, mode='word_char')\n",
    "\n",
    "pipeline_A = Pipeline([('features', features_transformer_A),\n",
    "                       ('classifier', baseline_model)])\n",
    "pipeline_B = Pipeline([('features', features_transformer_B),\n",
    "                       ('classifier', baseline_model)])\n",
    "\n",
    "# Rapid test on a sample for memory/density\n",
    "sample_size = min(1000, len(df_ready_model))\n",
    "X_sample = df_ready_model.iloc[:sample_size]\n",
    "XA = features_transformer_A.fit_transform(X_sample)\n",
    "XB = features_transformer_B.fit_transform(X_sample)\n",
    "print(\"A sparse?\", issparse(XA), XA.shape)\n",
    "print(\"B sparse?\", issparse(XB), XB.shape)\n",
    "\n",
    "print(\"\\n=== BASELINE MODEL READY ===\")\n",
    "print(\"Default: Version A (Word n-grams); Version B for comparison.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d42b92d",
   "metadata": {},
   "source": [
    "## Step 3.3 — Cross-Validation & Metrics\n",
    "\n",
    "**What this cell does:**\n",
    "\n",
    "* Splits the dataset into **train (80%)** and **test (20%)** with stratification to preserve class balance.\n",
    "* Runs a **5-fold Stratified Cross-Validation** loop on the training set using the baseline pipeline (`pipeline_A`).\n",
    "* Computes per-fold metrics:\n",
    "\n",
    "  * **PR-AUC (Average Precision)**\n",
    "  * **ROC-AUC**\n",
    "  * **F1-score @ threshold 0.5**\n",
    "  * Best threshold that maximizes **F1-score**\n",
    "  * Threshold ensuring **Recall ≥ 0.95**\n",
    "* Collects **out-of-fold (OOF) predictions** to build:\n",
    "\n",
    "  * An **aggregated confusion matrix**\n",
    "  * Global OOF metrics (PR-AUC, ROC-AUC, thresholds).\n",
    "* Stores all results (metrics, thresholds, predictions, confusion matrix) in a **`cv_results` dictionary** for later use (e.g. calibration, final testing).\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "* Provides a **robust evaluation** of the baseline model beyond a single split.\n",
    "* Identifies **optimal thresholds** for different objectives (balanced F1, high recall).\n",
    "* Creates reproducible OOF predictions that can be used in **model calibration** (Step 6).\n",
    "* Establishes a **performance baseline** before tuning or enhancements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1876f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CROSS-VALIDATION & METRICS ===\n",
      "\n",
      "• Stratified 80/20 split (holdout test set)\n",
      "Train shape: (3994, 13), Test shape: (999, 13)\n",
      "Spam % in train: 29.27%, test: 29.33%\n",
      "\n",
      "• Starting cross-validation (pipeline_A)...\n",
      "\n",
      "--- Fold 1 ---\n",
      "PR-AUC: 0.9736 | ROC-AUC: 0.9932 | F1@0.5: 0.9482\n",
      "Best F1 threshold: 0.5389 | High-recall (recall≥0.95) threshold: 0.5510\n",
      "\n",
      "--- Fold 2 ---\n",
      "PR-AUC: 0.9414 | ROC-AUC: 0.9850 | F1@0.5: 0.9277\n",
      "Best F1 threshold: 0.5786 | High-recall (recall≥0.95) threshold: 0.5828\n",
      "\n",
      "--- Fold 3 ---\n",
      "PR-AUC: 0.9409 | ROC-AUC: 0.9868 | F1@0.5: 0.9150\n",
      "Best F1 threshold: 0.5877 | High-recall (recall≥0.95) threshold: 0.5533\n",
      "\n",
      "--- Fold 4 ---\n",
      "PR-AUC: 0.9586 | ROC-AUC: 0.9882 | F1@0.5: 0.9388\n",
      "Best F1 threshold: 0.5078 | High-recall (recall≥0.95) threshold: 0.5419\n",
      "\n",
      "--- Fold 5 ---\n",
      "PR-AUC: 0.9771 | ROC-AUC: 0.9913 | F1@0.5: 0.9262\n",
      "Best F1 threshold: 0.6248 | High-recall (recall≥0.95) threshold: 0.5305\n",
      "\n",
      "=== CV RESULTS (mean ± std) ===\n",
      "PR-AUC:    0.9583 ± 0.0153\n",
      "ROC-AUC:   0.9889 ± 0.0030\n",
      "F1@0.5:    0.9312 ± 0.0114\n",
      "F1-max threshold (mean):      0.5676\n",
      "High-recall threshold (mean): 0.5519\n",
      "\n",
      "=== OOF CONFUSION MATRIX (mean F1-max threshold = 0.5676) ===\n",
      "             HAM (pred)  SPAM (pred)\n",
      "HAM (true)         2723          102\n",
      "SPAM (true)          61         1108\n",
      "\n",
      "=== OOF METRICS (global) ===\n",
      "PR-AUC (OOF):  0.9573\n",
      "ROC-AUC (OOF): 0.9889\n",
      "Global F1-max threshold: 0.5260702518985145\n",
      "Global high-recall threshold: 0.5564195903189517\n",
      "\n",
      "=== CV COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== CROSS-VALIDATION & METRICS ===\")\n",
    "\n",
    "# --- 1. Stratified 80/20 split ---\n",
    "print(\"\\n• Stratified 80/20 split (holdout test set)\")\n",
    "X = df_ready_model.drop(columns=['label_num'])\n",
    "y = df_ready_model['label_num'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(f\"Spam % in train: {np.mean(y_train)*100:.2f}%, test: {np.mean(y_test)*100:.2f}%\")\n",
    "\n",
    "# --- 2. CV setup ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- 3. CV loop ---\n",
    "pr_aucs, roc_aucs, f1s_05 = [], [], []\n",
    "f1_max_thresholds, highrec_thresholds = [], []\n",
    "oof_pred = np.zeros(len(X_train))\n",
    "oof_true = np.zeros(len(X_train))\n",
    "fold_indices = np.zeros(len(X_train), dtype=int)\n",
    "\n",
    "print(\"\\n• Starting cross-validation (pipeline_A)...\")\n",
    "for fold, (tr_idx, val_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n",
    "\n",
    "    # Fit pipeline\n",
    "    pipeline_A.fit(X_tr, y_tr)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_val_proba = pipeline_A.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Save OOF predictions\n",
    "    oof_pred[val_idx] = y_val_proba\n",
    "    oof_true[val_idx] = y_val\n",
    "    fold_indices[val_idx] = fold\n",
    "\n",
    "    # Metrics\n",
    "    pr_auc = average_precision_score(y_val, y_val_proba)\n",
    "    roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "    y_val_pred_05 = (y_val_proba >= 0.5).astype(int)\n",
    "    f1_05 = f1_score(y_val, y_val_pred_05, pos_label=1)\n",
    "\n",
    "    pr_aucs.append(pr_auc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    f1s_05.append(f1_05)\n",
    "               \n",
    "\n",
    "    # Threshold tuning\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "    prec_t, rec_t = precisions[:-1], recalls[:-1]\n",
    "    f1_scores = 2 * (prec_t * rec_t) / (prec_t + rec_t + 1e-8)\n",
    "    best_idx = int(np.nanargmax(f1_scores))\n",
    "    f1_max_thr = thresholds[best_idx]\n",
    "    f1_max_thresholds.append(f1_max_thr)\n",
    "\n",
    "    # High-recall threshold (Recall >= 0.95)\n",
    "    highrec_thr = None\n",
    "    mask = rec_t >= 0.95\n",
    "    if np.any(mask):  # exclude last point (always recall=1)\n",
    "        highrec_thr = thresholds[np.where(mask)[0][-1]]\n",
    "    else:\n",
    "        highrec_thr = thresholds[0]  # fallback: lowest threshold\n",
    "    highrec_thresholds.append(highrec_thr)\n",
    "\n",
    "    print(f\"PR-AUC: {pr_auc:.4f} | ROC-AUC: {roc_auc:.4f} | F1@0.5: {f1_05:.4f}\")\n",
    "    print(f\"Best F1 threshold: {f1_max_thr:.4f} | High-recall (recall≥0.95) threshold: {highrec_thr:.4f}\")\n",
    "\n",
    "# --- 4. Aggregate metrics report ---\n",
    "def mean_std(arr):\n",
    "    return f\"{np.mean(arr):.4f} ± {np.std(arr):.4f}\"\n",
    "\n",
    "print(\"\\n=== CV RESULTS (mean ± std) ===\")\n",
    "print(f\"PR-AUC:    {mean_std(pr_aucs)}\")\n",
    "print(f\"ROC-AUC:   {mean_std(roc_aucs)}\")\n",
    "print(f\"F1@0.5:    {mean_std(f1s_05)}\")\n",
    "print(f\"F1-max threshold (mean):      {np.mean(f1_max_thresholds):.4f}\")\n",
    "print(f\"High-recall threshold (mean): {np.mean(highrec_thresholds):.4f}\")\n",
    "\n",
    "# --- 5. Aggregated OOF confusion matrix ---\n",
    "# Chosen threshold: mean of F1-max thresholds\n",
    "chosen_thr = np.mean(f1_max_thresholds)\n",
    "oof_pred_label = (oof_pred >= chosen_thr).astype(int)\n",
    "cm = confusion_matrix(oof_true, oof_pred_label)\n",
    "cm_df = pd.DataFrame(cm, index=[\"HAM (true)\", \"SPAM (true)\"], columns=[\"HAM (pred)\", \"SPAM (pred)\"])\n",
    "\n",
    "print(f\"\\n=== OOF CONFUSION MATRIX (mean F1-max threshold = {chosen_thr:.4f}) ===\")\n",
    "print(cm_df)\n",
    "\n",
    "# Global OOF metrics\n",
    "oof_pr_auc  = average_precision_score(oof_true, oof_pred)\n",
    "oof_roc_auc = roc_auc_score(oof_true, oof_pred)\n",
    "print(f\"\\n=== OOF METRICS (global) ===\")\n",
    "print(f\"PR-AUC (OOF):  {oof_pr_auc:.4f}\")\n",
    "print(f\"ROC-AUC (OOF): {oof_roc_auc:.4f}\")\n",
    "\n",
    "# F1-max threshold on OOF (global)\n",
    "prec, rec, thr = precision_recall_curve(oof_true, oof_pred)\n",
    "prec_t, rec_t = prec[:-1], rec[:-1]           \n",
    "f1 = 2 * prec_t * rec_t / (prec_t + rec_t + 1e-8)\n",
    "thr_f1_global = float(thr[np.argmax(f1)])\n",
    "\n",
    "# High-recall threshold (Recall >= 0.95)\n",
    "mask = rec_t >= 0.95\n",
    "thr_hr_global = float(thr[np.where(mask)[0][-1]]) if mask.any() else float(thr[0])\n",
    "\n",
    "print(\"Global F1-max threshold:\", thr_f1_global)\n",
    "print(\"Global high-recall threshold:\", thr_hr_global)\n",
    "\n",
    "\n",
    "# --- 6. Save results for later use ---\n",
    "cv_results = {\n",
    "    \"pr_aucs\": pr_aucs,\n",
    "    \"roc_aucs\": roc_aucs,\n",
    "    \"f1s_05\": f1s_05,\n",
    "    \"f1_max_thresholds\": f1_max_thresholds,\n",
    "    \"highrec_thresholds\": highrec_thresholds,\n",
    "    \"oof_pred\": oof_pred,\n",
    "    \"oof_true\": oof_true,\n",
    "    \"fold_indices\": fold_indices,\n",
    "    \"chosen_thr\": chosen_thr,\n",
    "    \"confusion_matrix\": cm,\n",
    "    \"oof_pr_auc\": oof_pr_auc,\n",
    "    \"oof_roc_auc\": oof_roc_auc,\n",
    "    \"thr_f1_global\": thr_f1_global,\n",
    "    \"thr_hr_global\": thr_hr_global\n",
    "}\n",
    "print(\"\\n=== CV COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3fbcb4",
   "metadata": {},
   "source": [
    "## Step 3.4 — Final Evaluation on Holdout Test Set\n",
    "\n",
    "**What this cell does:**\n",
    "\n",
    "* **Refits** the baseline pipeline (`pipeline_A`) on the **entire training set** (after CV).\n",
    "* Computes **probability predictions** on the holdout **test set (20%)**.\n",
    "* Evaluates **probabilistic metrics** on the test set:\n",
    "\n",
    "  * **PR-AUC** (Average Precision)\n",
    "  * **ROC-AUC**\n",
    "* Evaluates the model at **two global thresholds** (derived from OOF CV in Step 3.3):\n",
    "\n",
    "  * **F1-max threshold** → optimizes F1-score balance\n",
    "  * **High-recall threshold** → ensures recall ≥ 0.95\n",
    "* For each threshold, prints:\n",
    "\n",
    "  * **Precision, Recall, F1-score**\n",
    "  * **Confusion Matrix** (HAM/SPAM true vs. predicted)\n",
    "* Saves results and thresholds in a dictionary `test_results` for downstream use.\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "* Provides a **fair estimate of generalization performance** on unseen data.\n",
    "* Confirms whether thresholds tuned on CV also work well on the test set.\n",
    "* Bridges the model from **cross-validation evaluation** to a **deployable state**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "773775d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• Re-fitting pipeline_A on full training data...\n",
      "=== TEST METRICS (probabilistic) ===\n",
      "PR-AUC:  0.9437\n",
      "ROC-AUC: 0.9862\n",
      "\n",
      "=== F1-max @ threshold=0.5261 ===\n",
      "Precision: 0.8994 | Recall: 0.9761 | F1: 0.9362\n",
      "            HAM(pred)  SPAM(pred)\n",
      "HAM(true)         674          32\n",
      "SPAM(true)          7         286\n",
      "\n",
      "=== High-recall (recall≥0.95) @ threshold=0.5564 ===\n",
      "Precision: 0.9051 | Recall: 0.9761 | F1: 0.9392\n",
      "            HAM(pred)  SPAM(pred)\n",
      "HAM(true)         676          30\n",
      "SPAM(true)          7         286\n"
     ]
    }
   ],
   "source": [
    "# 1) Refit on full training data\n",
    "print(\"\\n• Re-fitting pipeline_A on full training data...\")\n",
    "pipeline_A.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict probabilities on test set\n",
    "proba_test = pipeline_A.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 3) Probabilistic metrics\n",
    "print(\"=== TEST METRICS (probabilistic) ===\")\n",
    "print(f\"PR-AUC:  {average_precision_score(y_test, proba_test):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, proba_test):.4f}\")\n",
    "\n",
    "def eval_at_threshold(th, name=\"\"):\n",
    "    pred = (proba_test >= th).astype(int)\n",
    "    p = precision_score(y_test, pred)\n",
    "    r = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(f\"\\n=== {name} @ threshold={th:.4f} ===\")\n",
    "    print(f\"Precision: {p:.4f} | Recall: {r:.4f} | F1: {f1:.4f}\")\n",
    "    print(pd.DataFrame(cm, index=['HAM(true)','SPAM(true)'], columns=['HAM(pred)','SPAM(pred)']))\n",
    "    return {\"thr\": th, \"precision\": p, \"recall\": r, \"f1\": f1, \"cm\": cm}\n",
    "\n",
    "# Use global thresholds derived from OOF\n",
    "thr_f1_global = 0.5260702518985145\n",
    "thr_hr_global = 0.5564195903189517\n",
    "\n",
    "res_f1 = eval_at_threshold(thr_f1_global, \"F1-max\")\n",
    "res_hr = eval_at_threshold(thr_hr_global, \"High-recall (recall≥0.95)\")\n",
    "\n",
    "# Save for later use\n",
    "test_results = {\n",
    "    \"proba_test\": proba_test,\n",
    "    \"thr_f1_global\": thr_f1_global,\n",
    "    \"thr_hr_global\": thr_hr_global,\n",
    "    \"res_f1\": res_f1,\n",
    "    \"res_hr\": res_hr\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6bef4e",
   "metadata": {},
   "source": [
    "## Step 3.5 — Saving Baseline Artifacts\n",
    "\n",
    "**What this cell does:**\n",
    "\n",
    "* **Verifies** that the trained pipeline (`pipeline_A`) and datasets (`X_train`, `X_test`, `y_train`, `y_test`) exist.\n",
    "* **Computes test probabilities** and evaluates model performance at the selected global thresholds (**F1-max** and **High-recall**).\n",
    "* **Builds a structured JSON artifact** (`spam_baseline_artifacts.json`) containing:\n",
    "\n",
    "  * Random seed, dataset stats, and class distribution.\n",
    "  * Model parameters and type (Logistic Regression).\n",
    "  * Meta-features and subject weight.\n",
    "  * Cross-validation metrics (if available).\n",
    "  * Test set metrics (probabilistic + thresholded).\n",
    "* **Saves the trained model** as `spam_baseline_pipeline.joblib`.\n",
    "* **Exports error analysis samples**: false positives and false negatives are saved as CSV (`test_false_positives.csv`, `test_false_negatives.csv`) for quick inspection.\n",
    "* Provides an **optional preview** of FP/FN cases directly in the notebook.\n",
    "\n",
    "**Why it matters:**\n",
    "This step creates a **reproducible artifact package** (model + metadata + errors), ensuring that the trained model can be:\n",
    "\n",
    "* Reloaded later for inference or further training.\n",
    "* Evaluated consistently using the same thresholds.\n",
    "* Audited via saved error samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "613f2814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAVING BASELINE ARTIFACTS ===\n",
      "Saved: spam_baseline_pipeline.joblib, spam_baseline_artifacts.json\n",
      "Test FP: 30, FN: 7 @thr=0.5564\n",
      "Saved: test_false_positives.csv, test_false_negatives.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label_num</th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>registration confirmation from spinner . com registration confirmation from spinner . com thank you for joining spinner . com : the web ' s largest source o...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>registration confirmation from spinner . com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5014</td>\n",
       "      <td>young families egg hunt young families egg hunt bammelyoungfamilies - - - - - - - - - - - - - - - - - - - - - - - - - - - listbot sponsor - - - - - - - - - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>young families egg hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1362</td>\n",
       "      <td>http : / / www . pge - texas . com / www / gtt . nsf / htmlmedia / operations . html</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>http : / / www . pge - texas . com / www / gtt . nsf / htmlmedia / operations . html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4746</td>\n",
       "      <td>is this fri feb 11 a problem for taking vacation ?</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>is this fri feb 11 a problem for taking vacation ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1631</td>\n",
       "      <td>enbridge buys koch ' s east texas midstream assets for $ 231 m enbridge buys koch ' s east texas midstream assets for $ 231 m ngi ' s daily gas price index ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>enbridge buys koch ' s east texas midstream assets for $ 231 m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  \\\n",
       "0      26   \n",
       "1    5014   \n",
       "2    1362   \n",
       "3    4746   \n",
       "4    1631   \n",
       "\n",
       "                                                                                                                                                        text_clean  \\\n",
       "0  registration confirmation from spinner . com registration confirmation from spinner . com thank you for joining spinner . com : the web ' s largest source o...   \n",
       "1  young families egg hunt young families egg hunt bammelyoungfamilies - - - - - - - - - - - - - - - - - - - - - - - - - - - listbot sponsor - - - - - - - - - ...   \n",
       "2                                                                             http : / / www . pge - texas . com / www / gtt . nsf / htmlmedia / operations . html   \n",
       "3                                                                                                               is this fri feb 11 a problem for taking vacation ?   \n",
       "4  enbridge buys koch ' s east texas midstream assets for $ 231 m enbridge buys koch ' s east texas midstream assets for $ 231 m ngi ' s daily gas price index ...   \n",
       "\n",
       "   label_num label  \\\n",
       "0          0   ham   \n",
       "1          0   ham   \n",
       "2          0   ham   \n",
       "3          0   ham   \n",
       "4          0   ham   \n",
       "\n",
       "                                                                                subject  \n",
       "0                                          registration confirmation from spinner . com  \n",
       "1                                                               young families egg hunt  \n",
       "2  http : / / www . pge - texas . com / www / gtt . nsf / htmlmedia / operations . html  \n",
       "3                                    is this fri feb 11 a problem for taking vacation ?  \n",
       "4                        enbridge buys koch ' s east texas midstream assets for $ 231 m  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label_num</th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5162</td>\n",
       "      <td>anomaly boys from [number] anomaly boys from [number] uosda apaproved mledms heure crack mutagen poliomyelitis axisymmetric virus bernoulli pervade cadenza ...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>anomaly boys from 3881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1623</td>\n",
       "      <td>3 . 25 rate confirmation # [phone] jb wed , 29 jun [number] 09 : 35 : [phone] . 25 rate confirmation # [phone] jb wed , 29 jun [number] 09 : 35 : [phone] he...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>3 . 25 rate confirmation # 367886924 jb wed , 29 jun 2005 09 : 35 : 02 - 0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3352</td>\n",
       "      <td>fw : re : he rbv i agr a fw : re : he rbv i agr a see the . htm attachment for online purchases and special offers . thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>fw : re : he rbv i agr a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4950</td>\n",
       "      <td>( envelope - from [phone] . cca [phone] . [number] qi @ earthlink . com ) ( envelope - from [phone] . cca [phone] . [number] qi @ earthlink . com ) message ...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>( envelope - from 20040929124340 . cca 972659112757918286 . 39382 qi @ earthlink . com )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1541</td>\n",
       "      <td>re : re : thu , 06 may [number] 04 : 17 : [phone] the first gove . rnment mo ' rtgage program . under a new bill , we have aspecial budget to help you and y...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>re :</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  \\\n",
       "0    5162   \n",
       "1    1623   \n",
       "2    3352   \n",
       "3    4950   \n",
       "4    1541   \n",
       "\n",
       "                                                                                                                                                        text_clean  \\\n",
       "0  anomaly boys from [number] anomaly boys from [number] uosda apaproved mledms heure crack mutagen poliomyelitis axisymmetric virus bernoulli pervade cadenza ...   \n",
       "1  3 . 25 rate confirmation # [phone] jb wed , 29 jun [number] 09 : 35 : [phone] . 25 rate confirmation # [phone] jb wed , 29 jun [number] 09 : 35 : [phone] he...   \n",
       "2                                   fw : re : he rbv i agr a fw : re : he rbv i agr a see the . htm attachment for online purchases and special offers . thank you   \n",
       "3  ( envelope - from [phone] . cca [phone] . [number] qi @ earthlink . com ) ( envelope - from [phone] . cca [phone] . [number] qi @ earthlink . com ) message ...   \n",
       "4  re : re : thu , 06 may [number] 04 : 17 : [phone] the first gove . rnment mo ' rtgage program . under a new bill , we have aspecial budget to help you and y...   \n",
       "\n",
       "   label_num label  \\\n",
       "0          1  spam   \n",
       "1          1  spam   \n",
       "2          1  spam   \n",
       "3          1  spam   \n",
       "4          1  spam   \n",
       "\n",
       "                                                                                    subject  \n",
       "0                                                                    anomaly boys from 3881  \n",
       "1             3 . 25 rate confirmation # 367886924 jb wed , 29 jun 2005 09 : 35 : 02 - 0800  \n",
       "2                                                                  fw : re : he rbv i agr a  \n",
       "3  ( envelope - from 20040929124340 . cca 972659112757918286 . 39382 qi @ earthlink . com )  \n",
       "4                                                                                      re :  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== SAVING BASELINE ARTIFACTS ===\")\n",
    "\n",
    "# 1) Ensure required objects are present\n",
    "assert 'pipeline_A' in globals(), \"pipeline_A is missing. Fit the model before saving.\"\n",
    "assert 'X_test' in globals() and 'y_test' in globals(), \"X_test/y_test not found.\"\n",
    "assert 'X_train' in globals() and 'y_train' in globals(), \"X_train/y_train not found.\"\n",
    "\n",
    "# 2) Compute test probabilities (idempotent)\n",
    "proba_test = pipeline_A.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 3) Load thresholds from session (preferred) or fallback to prior JSON (if any)\n",
    "thr_f1_global = globals().get('thr_f1_global', None)\n",
    "thr_hr_global = globals().get('thr_hr_global', None)\n",
    "\n",
    "# Optional fallback: read an older minimal JSON if present\n",
    "if (thr_f1_global is None or thr_hr_global is None) and os.path.exists(\"spam_baseline_threshold.json\"):\n",
    "    try:\n",
    "        with open(\"spam_baseline_threshold.json\", \"r\") as f:\n",
    "            old = json.load(f)\n",
    "        # backward-compat: file may contain only one key \"threshold\"\n",
    "        thr_f1_global = thr_f1_global or old.get(\"threshold\", None)\n",
    "        thr_hr_global = thr_hr_global or old.get(\"threshold\", None)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Last resort defaults (should not be needed)\n",
    "if thr_f1_global is None: thr_f1_global = 0.5\n",
    "if thr_hr_global is None: thr_hr_global = 0.5\n",
    "\n",
    "def eval_at_threshold(y_true, y_proba, thr: float):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    p  = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return {\"precision\": float(p), \"recall\": float(r), \"f1\": float(f1), \"thr\": float(thr), \"cm\": cm.tolist()}\n",
    "\n",
    "# 4) Probabilistic metrics on test\n",
    "test_pr_auc  = float(average_precision_score(y_test, proba_test))\n",
    "test_roc_auc = float(roc_auc_score(y_test, proba_test))\n",
    "\n",
    "# 5) Thresholded metrics on test\n",
    "test_at_f1   = eval_at_threshold(y_test, proba_test, thr_f1_global)\n",
    "test_at_hr   = eval_at_threshold(y_test, proba_test, thr_hr_global)\n",
    "\n",
    "# 6) Collect meta/info\n",
    "clf = pipeline_A.named_steps['classifier']\n",
    "model_info = {\n",
    "    \"model_name\": \"LogisticRegression\",\n",
    "    \"model_class\": f\"{clf.__class__.__module__}.{clf.__class__.__name__}\",\n",
    "    \"model_params\": {k: (int(v) if isinstance(v, np.integer) else v) for k, v in clf.get_params().items()}\n",
    "}\n",
    "\n",
    "# Feature info (from earlier cells)\n",
    "subject_weight = globals().get(\"SUBJECT_WEIGHT\", None)\n",
    "meta_features  = globals().get(\"all_meta_features\", [])\n",
    "label_mapping  = {\"ham\": 0, \"spam\": 1}\n",
    "\n",
    "# 7) CV summary if present in memory (optional)\n",
    "cv_summary = {}\n",
    "if 'oof_pr_auc' in globals() and 'oof_roc_auc' in globals():\n",
    "    cv_summary[\"oof_pr_auc\"] = float(oof_pr_auc)\n",
    "    cv_summary[\"oof_roc_auc\"] = float(oof_roc_auc)\n",
    "if 'pr_aucs' in globals():\n",
    "    cv_summary[\"cv_pr_auc_mean\"] = float(np.mean(pr_aucs))\n",
    "    cv_summary[\"cv_pr_auc_std\"]  = float(np.std(pr_aucs))\n",
    "if 'roc_aucs' in globals():\n",
    "    cv_summary[\"cv_roc_auc_mean\"] = float(np.mean(roc_aucs))\n",
    "    cv_summary[\"cv_roc_auc_std\"]  = float(np.std(roc_aucs))\n",
    "if 'f1s_05' in globals():\n",
    "    cv_summary[\"cv_f1_at_0_5_mean\"] = float(np.mean(f1s_05))\n",
    "    cv_summary[\"cv_f1_at_0_5_std\"]  = float(np.std(f1s_05))\n",
    "\n",
    "# 8) Dataset stats\n",
    "data_info = {\n",
    "    \"train_shape\": list(X_train.shape),\n",
    "    \"test_shape\": list(X_test.shape),\n",
    "    \"train_spam_ratio\": float(np.mean(y_train)),\n",
    "    \"test_spam_ratio\": float(np.mean(y_test)),\n",
    "    \"deduplicated_dataset_shape\": list(df_ready_model.shape) if 'df_ready_model' in globals() else None\n",
    "}\n",
    "\n",
    "# 9) Build the artifacts JSON\n",
    "artifacts = {\n",
    "    \"artifacts_version\": 1,\n",
    "    \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    \"random_state\": int(globals().get(\"RANDOM_STATE\", 42)),\n",
    "    \"label_mapping\": label_mapping,\n",
    "    \"subject_weight\": subject_weight,\n",
    "    \"meta_features\": meta_features,\n",
    "    \"thresholds\": {\n",
    "        \"f1_global\": float(thr_f1_global),\n",
    "        \"high_recall_global\": float(thr_hr_global)\n",
    "    },\n",
    "    \"probabilistic_test_metrics\": {\n",
    "        \"pr_auc\": test_pr_auc,\n",
    "        \"roc_auc\": test_roc_auc\n",
    "    },\n",
    "    \"thresholded_test_metrics\": {\n",
    "        \"f1_global\": test_at_f1,\n",
    "        \"high_recall_global\": test_at_hr\n",
    "    },\n",
    "    \"cv_summary\": cv_summary,\n",
    "    \"data_info\": data_info,\n",
    "    \"model_info\": model_info\n",
    "}\n",
    "\n",
    "# 10) Save pipeline and JSON\n",
    "joblib.dump(pipeline_A, \"spam_baseline_pipeline.joblib\")\n",
    "with open(\"spam_baseline_artifacts.json\", \"w\") as f:\n",
    "    json.dump(artifacts, f, indent=2)\n",
    "print(\"Saved: spam_baseline_pipeline.joblib, spam_baseline_artifacts.json\")\n",
    "\n",
    "# 11) Save test FP/FN samples for quick inspection (subject + label + text_clean)\n",
    "\n",
    "def build_error_view(indexes):\n",
    "    \"\"\"\n",
    "    Build a compact view for error analysis:\n",
    "    - Always include 'text_clean' and 'label_num' from df_ready_model\n",
    "    - Optionally join 'label' and 'subject' from the original df (if available)\n",
    "    \"\"\"\n",
    "    # Base from df_ready_model\n",
    "    cols_ready = [c for c in ['text_clean', 'label_num'] if c in df_ready_model.columns]\n",
    "    view = df_ready_model.loc[indexes, cols_ready]\n",
    "\n",
    "    # Optional join with raw columns from original df\n",
    "    raw_cols = []\n",
    "    if 'df' in globals():\n",
    "        raw_cols = [c for c in ['label', 'subject'] if c in df.columns]\n",
    "    if raw_cols:\n",
    "        raw_part = df.reindex(indexes)[raw_cols]   # safe reindex to avoid KeyError\n",
    "        view = view.join(raw_part, how='left')\n",
    "\n",
    "    # Add row_id for traceability\n",
    "    view = view.reset_index().rename(columns={'index': 'row_id'})\n",
    "    return view\n",
    "\n",
    "thr_for_samples = artifacts[\"thresholds\"][\"high_recall_global\"]\n",
    "pred_test = (proba_test >= thr_for_samples).astype(int)\n",
    "test_idx  = X_test.index\n",
    "\n",
    "fp_mask = (pred_test == 1) & (y_test == 0)\n",
    "fn_mask = (pred_test == 0) & (y_test == 1)\n",
    "\n",
    "fp_idx = test_idx[fp_mask]\n",
    "fn_idx = test_idx[fn_mask]\n",
    "print(f\"Test FP: {len(fp_idx)}, FN: {len(fn_idx)} @thr={thr_for_samples:.4f}\")\n",
    "\n",
    "fp_df = build_error_view(fp_idx)\n",
    "fn_df = build_error_view(fn_idx)\n",
    "\n",
    "fp_df.to_csv(\"test_false_positives.csv\", index=False)\n",
    "fn_df.to_csv(\"test_false_negatives.csv\", index=False)\n",
    "print(\"Saved: test_false_positives.csv, test_false_negatives.csv\")\n",
    "\n",
    "# Optional preview\n",
    "pd.set_option('display.max_colwidth', 160)\n",
    "display(fp_df.head(5))\n",
    "display(fn_df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f052f5",
   "metadata": {},
   "source": [
    "# Step 4 — Topic Modeling, Stopwords: Build or Load\n",
    "\n",
    "**What this cell does (short):**\n",
    "\n",
    "* Builds (or updates) a **topic-specific stopword list** for spam-topic modeling.\n",
    "* Saves to `topic_stopwords.json` with three lists: `base`, `auto_candidates`, `final`.\n",
    "* Prefers a **predicted-SPAM corpus** (using your saved threshold in `spam_baseline_artifacts.json`); otherwise falls back to labeled spam.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "* Mines **high document-frequency unigrams** from the spam corpus (DF ≥ 60%) using `CountVectorizer`.\n",
    "* Adds rule-based boilerplate tokens (email header noise, HTML crumbs, your PII placeholders).\n",
    "* **Protects content-bearing words** (e.g., “free”, “offer”, “click”) from removal.\n",
    "* If `topic_stopwords.json` already exists, it **merges** prior choices so you don’t lose manual edits.\n",
    "\n",
    "**Inputs expected:**\n",
    "\n",
    "* `df_ready_model` with a `text_clean` column.\n",
    "* (Optional) `pipeline_A` and `spam_baseline_artifacts.json` to select spam via the saved threshold.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* `topic_stopwords.json`:\n",
    "\n",
    "  * `base`: conservative, handpicked boilerplate.\n",
    "  * `auto_candidates`: mined high-DF tokens + regex matches.\n",
    "  * `final`: union used by topic modeling (you can trim later).\n",
    "\n",
    "**When to re-run:**\n",
    "\n",
    "* After changing preprocessing, thresholds, or when you want to refresh topic stopwords for a new dataset slice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b94fb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOPIC STOPWORDS: BUILD OR LOAD ===\n",
      "Using saved threshold for SPAM selection: 0.5564\n",
      "Spam documents for stopword mining: 1525\n",
      "Saved/updated topic_stopwords.json\n",
      "- base: 27 terms\n",
      "- auto_candidates: 21 terms (df >= 60% or regex)\n",
      "- final (used): 29 terms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attached</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cc</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>from</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fw</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fwd</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mailto</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nbsp</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>number</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>original</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phone</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>re</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sent</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>subject</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>to</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>url</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term  note\n",
       "0        and  auto\n",
       "1   attached  auto\n",
       "2         cc  auto\n",
       "3        com  auto\n",
       "4      email  auto\n",
       "5       from  auto\n",
       "6         fw  auto\n",
       "7        fwd  auto\n",
       "8       http  auto\n",
       "9     mailto  auto\n",
       "10      nbsp  auto\n",
       "11    number  auto\n",
       "12  original  auto\n",
       "13     phone  auto\n",
       "14        re  auto\n",
       "15      sent  auto\n",
       "16   subject  auto\n",
       "17       the  auto\n",
       "18        to  auto\n",
       "19       url  auto"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== TOPIC STOPWORDS: BUILD OR LOAD ===\")\n",
    "\n",
    "# 0) Where to save/read\n",
    "STOPWORDS_JSON = \"topic_stopwords.json\"\n",
    "\n",
    "# 1) Base (conservative) stopwords that are safe to remove in email corpora\n",
    "BASE_TOPIC_STOP = {\n",
    "    # email/thread boilerplate\n",
    "    \"re\",\"fw\",\"fwd\",\"subject\",\"original\",\"message\",\"forwarded\",\"from\",\"to\",\"cc\",\"bcc\",\"sent\",\n",
    "    \"attach\",\"attached\",\"attachment\",\"mailto\",\n",
    "    # web artifacts / html noise\n",
    "    \"http\",\"https\",\"www\",\"com\",\"lt\",\"gt\",\"nbsp\",\n",
    "    # our placeholders after cleaning\n",
    "    \"url\",\"email\",\"phone\",\"number\"\n",
    "}\n",
    "\n",
    "# 2) Build a spam corpus to mine candidates\n",
    "# Prefer predicted-SPAM if artifacts/pipeline exist; otherwise fallback to labeled spam\n",
    "spam_corpus = None\n",
    "if 'pipeline_A' in globals() and 'df_ready_model' in globals():\n",
    "    # If you already chose a threshold and saved it in artifacts:\n",
    "    thr_for_spam = None\n",
    "    if os.path.exists(\"spam_baseline_artifacts.json\"):\n",
    "        with open(\"spam_baseline_artifacts.json\",\"r\") as f:\n",
    "            art = json.load(f)\n",
    "        thr_for_spam = art.get(\"thresholds\",{}).get(\"high_recall_global\") \\\n",
    "                       or art.get(\"thresholds\",{}).get(\"f1_global\")\n",
    "\n",
    "    if thr_for_spam is not None:\n",
    "        print(f\"Using saved threshold for SPAM selection: {thr_for_spam:.4f}\")\n",
    "        proba_all = pipeline_A.predict_proba(df_ready_model)[:,1]\n",
    "        pred_all  = (proba_all >= thr_for_spam).astype(int)\n",
    "        spam_corpus = df_ready_model.loc[pred_all==1, \"text_clean\"].astype(str).tolist()\n",
    "    else:\n",
    "        print(\"No saved threshold found; falling back to labeled spam.\")\n",
    "        spam_corpus = df_ready_model.loc[df_ready_model[\"label_num\"]==1, \"text_clean\"].astype(str).tolist()\n",
    "\n",
    "elif 'df_ready_model' in globals():\n",
    "    print(\"Pipeline not found; using labeled spam as corpus.\")\n",
    "    spam_corpus = df_ready_model.loc[df_ready_model[\"label_num\"]==1, \"text_clean\"].astype(str).tolist()\n",
    "else:\n",
    "    raise RuntimeError(\"df_ready_model not found. Build it before this cell.\")\n",
    "\n",
    "n_docs = len(spam_corpus)\n",
    "print(f\"Spam documents for stopword mining: {n_docs}\")\n",
    "\n",
    "# 3) Mine high document-frequency tokens as stopword candidates\n",
    "#    Heuristics:\n",
    "#    - english stopwords already removed in later TF-IDF; here we look for corpus-specific high-DF tokens\n",
    "#    - candidate if doc frequency ratio >= DF_THRESH (e.g., 0.60)\n",
    "#    - optional regex filters to catch capitalized initials, short tokens, or obvious boilerplate\n",
    "DF_THRESH = 0.60\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    ngram_range=(1,1),\n",
    "    min_df=5,\n",
    "    token_pattern=r\"(?u)\\b[^\\W\\d_][\\w\\-]{1,}\\b\",  # words with letters (allow hyphen); skip pure digits\n",
    "    lowercase=True,\n",
    ")\n",
    "X = cv.fit_transform(spam_corpus)\n",
    "terms = np.array(cv.get_feature_names_out())\n",
    "df_ratio = (X>0).sum(axis=0).A1 / max(1, n_docs)\n",
    "\n",
    "high_df_mask = df_ratio >= DF_THRESH\n",
    "candidates = set(terms[high_df_mask])\n",
    "\n",
    "# 4) Add rule-based candidates (common email tokens that may fly under DF thresh)\n",
    "RULE_REGEXES = [\n",
    "    r\"^(subject|forwarded|original)$\",\n",
    "    r\"^(http|https|www|mailto|com|lt|gt|nbsp)$\",\n",
    "    r\"^(re|fw|fwd)$\",\n",
    "    r\"^(from|to|cc|bcc|sent|attach|attached|attachment)$\",\n",
    "    r\"^(url|email|phone|number)$\",  # placeholders after cleaning\n",
    "]\n",
    "for t in terms:\n",
    "    for rgx in RULE_REGEXES:\n",
    "        if re.match(rgx, t):\n",
    "            candidates.add(t)\n",
    "\n",
    "# 5) Combine with base set; allow for an existing JSON to persist manual choices\n",
    "final_stop = set(BASE_TOPIC_STOP)\n",
    "\n",
    "if os.path.exists(STOPWORDS_JSON):\n",
    "    with open(STOPWORDS_JSON,\"r\") as f:\n",
    "        old = json.load(f)\n",
    "    old_final = set(old.get(\"final\", []))\n",
    "    old_base  = set(old.get(\"base\", []))\n",
    "    old_auto  = set(old.get(\"auto_candidates\", []))\n",
    "    # keep previous manual decisions\n",
    "    final_stop |= old_final\n",
    "    BASE_TOPIC_STOP |= old_base\n",
    "    candidates |= old_auto\n",
    "\n",
    "# 6) Exclude tokens that look content-bearing (very rough guard)\n",
    "#    Example: do NOT auto-remove typical spam content words\n",
    "PROTECT = {\"free\",\"offer\",\"click\",\"win\",\"prize\",\"update\",\"account\",\"confirm\",\"bank\",\"discount\",\"bitcoin\"}\n",
    "candidates = {w for w in candidates if w not in PROTECT}\n",
    "\n",
    "# 7) Build JSON and save\n",
    "topic_sw = {\n",
    "    \"base\": sorted(BASE_TOPIC_STOP),\n",
    "    \"auto_candidates\": sorted(candidates),\n",
    "    \"final\": sorted(final_stop | candidates)  # default: base ∪ auto; you can manually trim later if needed\n",
    "}\n",
    "with open(STOPWORDS_JSON, \"w\") as f:\n",
    "    json.dump(topic_sw, f, indent=2)\n",
    "\n",
    "print(f\"Saved/updated {STOPWORDS_JSON}\")\n",
    "print(f\"- base: {len(topic_sw['base'])} terms\")\n",
    "print(f\"- auto_candidates: {len(topic_sw['auto_candidates'])} terms (df >= {DF_THRESH:.0%} or regex)\")\n",
    "print(f\"- final (used): {len(topic_sw['final'])} terms\")\n",
    "\n",
    "# Optional preview\n",
    "pd.DataFrame({\n",
    "    \"term\": topic_sw[\"auto_candidates\"],\n",
    "    \"note\": \"auto\"\n",
    "}).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da52417",
   "metadata": {},
   "source": [
    "## Step 4.1 — Topic Modeling (using saved artifacts)\n",
    "\n",
    "**Purpose:**\n",
    "This cell sets up the **topic modeling pipeline** using the trained baseline classifier and the stopwords file created earlier. It identifies the spam subset of the dataset and prepares a TF-IDF representation for topic extraction.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Load artifacts**:\n",
    "\n",
    "   * Reloads the trained pipeline (`spam_baseline_pipeline.joblib`)\n",
    "   * Loads thresholds and metadata from `spam_baseline_artifacts.json`.\n",
    "\n",
    "2. **Select spam corpus**:\n",
    "\n",
    "   * Applies the classifier to `df_ready_model`.\n",
    "   * Uses the saved **high-recall threshold** (or falls back to F1-max threshold) to flag spam messages.\n",
    "   * Filters dataset → only predicted spam goes into topic modeling.\n",
    "\n",
    "3. **Load topic stopwords**:\n",
    "\n",
    "   * Reads `topic_stopwords.json` if available.\n",
    "   * Combines those stopwords with the default English stopword list.\n",
    "   * Falls back to English stopwords only if the JSON is missing.\n",
    "\n",
    "4. **Build TF-IDF matrix**:\n",
    "\n",
    "   * Uses 1–2 grams, document frequency filter (min\\_df=5, max\\_df=0.95).\n",
    "   * Produces a sparse document-term matrix for the spam corpus, ready for topic extraction.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* Console logs: spam corpus size, stopwords loaded, TF-IDF matrix dimensions.\n",
    "* Variables created:\n",
    "\n",
    "  * `spam_df`: filtered DataFrame with spam only.\n",
    "  * `X_topic`: TF-IDF matrix of spam messages.\n",
    "  * `feat_names`: vocabulary list (n-grams).\n",
    "\n",
    "This prepares the **input representation** for the next step: running topic models (e.g., NMF, LDA).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60fa9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 4: TOPIC MODELING (using saved artifacts) ===\n",
      "Using threshold for topics: 0.5564\n",
      "Predicted SPAM corpus: 1525 docs out of 4993 (30.54%)\n",
      "Loaded 29 topic stopwords from topic_stopwords.json\n",
      "TF-IDF topic matrix shape: (1525, 7123) (docs × terms)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 4: TOPIC MODELING (using saved artifacts) ===\")\n",
    "\n",
    "# 1) Load artifacts\n",
    "assert os.path.exists(\"spam_baseline_pipeline.joblib\"), \"Missing pipeline file.\"\n",
    "assert os.path.exists(\"spam_baseline_artifacts.json\"), \"Missing artifacts JSON.\"\n",
    "\n",
    "pipeline_A = joblib.load(\"spam_baseline_pipeline.joblib\")\n",
    "with open(\"spam_baseline_artifacts.json\", \"r\") as f:\n",
    "    artifacts = json.load(f)\n",
    "\n",
    "# 2) Threshold to select SPAM for topics\n",
    "THR_TOPIC = artifacts.get(\"thresholds\", {}).get(\"high_recall_global\",\n",
    "             artifacts.get(\"thresholds\", {}).get(\"f1_global\", 0.5564195903189517))\n",
    "print(f\"Using threshold for topics: {THR_TOPIC:.4f}\")\n",
    "\n",
    "# 3) Score the deduplicated dataset (df_ready_model must exist)\n",
    "assert 'df_ready_model' in globals(), \"df_ready_model is required for scoring.\"\n",
    "proba_all = pipeline_A.predict_proba(df_ready_model)[:, 1]\n",
    "pred_all  = (proba_all >= THR_TOPIC).astype(int)\n",
    "\n",
    "spam_mask = (pred_all == 1)\n",
    "spam_df   = df_ready_model.loc[spam_mask].copy()\n",
    "print(f\"Predicted SPAM corpus: {len(spam_df)} docs out of {len(df_ready_model)} \"\n",
    "      f\"({100*spam_mask.mean():.2f}%)\")\n",
    "\n",
    "# 4) TF-IDF for topic modeling (separate from classification TF-IDF)\n",
    "# Load topic stopwords from JSON (or fallback to english only)\n",
    "STOPWORDS_JSON = \"topic_stopwords.json\"\n",
    "if os.path.exists(STOPWORDS_JSON):\n",
    "    with open(STOPWORDS_JSON,\"r\") as f:\n",
    "        topic_sw = json.load(f)\n",
    "    topic_stopwords = set(topic_sw.get(\"final\", []))\n",
    "    print(f\"Loaded {len(topic_stopwords)} topic stopwords from {STOPWORDS_JSON}\")\n",
    "else:\n",
    "    topic_stopwords = set()  # fallback: rely on english stopwords only\n",
    "    print(\"No topic_stopwords.json found — using english stopwords only.\")\n",
    "\n",
    "topic_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.95,\n",
    "    stop_words=list(topic_stopwords) + list(TfidfVectorizer(stop_words='english').get_stop_words()),\n",
    "    strip_accents='unicode'\n",
    ")\n",
    "\n",
    "X_topic = topic_vectorizer.fit_transform(spam_df['text_clean'])\n",
    "feat_names = np.array(topic_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(f\"TF-IDF topic matrix shape: {X_topic.shape} (docs × terms)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28974fa",
   "metadata": {},
   "source": [
    "## Step 4.2 — Selecting the Number of Topics (K)\n",
    "\n",
    "**Purpose:**\n",
    "This cell evaluates different values of **K** (number of topics) for Non-negative Matrix Factorization (NMF) to identify the most stable and interpretable topic structure for the spam corpus.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Helper functions**:\n",
    "\n",
    "   * `fit_nmf(X, k, seed)`: fits NMF with a fixed random seed, returns matrices W (doc-topic) and H (topic-term).\n",
    "   * `topic_stability(H1, H2)`: measures how consistent topics are across two independent fits using cosine similarity and optimal matching.\n",
    "\n",
    "2. **Evaluation loop**:\n",
    "\n",
    "   * Tests a grid of values for K (5, 8, 11, 14, 17, 20).\n",
    "   * Uses bootstrapped subsets of the spam corpus to fit two NMF models for each K.\n",
    "   * Computes **topic stability** (higher = more consistent) and **reconstruction error** (lower = better fit).\n",
    "\n",
    "3. **Results visualization**:\n",
    "\n",
    "   * Plots stability vs. K and reconstruction error vs. K.\n",
    "   * Shows a summary table with metrics.\n",
    "\n",
    "4. **Best K selection**:\n",
    "\n",
    "   * Chooses the K with the **highest stability** and, if tied, the **lowest reconstruction error**.\n",
    "   * Saves result into `BEST_K`.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* DataFrame `k_eval`: summary of stability and error for each K.\n",
    "* Plots to visualize the trade-off.\n",
    "* Printed `BEST_K` with its stability and reconstruction error.\n",
    "\n",
    "This ensures that topic modeling uses a value of K that balances **robustness (stability)** with **fidelity (error minimization)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98a3f3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating K...\n",
      "\n",
      "=== K evaluation ===\n",
      "    K  stability  reconstruction_err\n",
      "0   5   0.981878           33.775212\n",
      "1   8   0.857863           33.439567\n",
      "2  11   0.844436           33.148497\n",
      "3  14   0.796888           32.890408\n",
      "4  17   0.918204           32.651736\n",
      "5  20   0.828885           32.426080\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen K = 5 (stability=0.9819, rec_err=33.7752)\n"
     ]
    }
   ],
   "source": [
    "RSTATE = int(artifacts.get(\"random_state\", 42))\n",
    "\n",
    "def fit_nmf(X, k, seed):\n",
    "    nmf = NMF(n_components=k, init='nndsvd', random_state=seed, max_iter=400, alpha_W=0.0, alpha_H=0.0, l1_ratio=0.0)\n",
    "    W = nmf.fit_transform(X)\n",
    "    H = nmf.components_\n",
    "    return nmf, W, H\n",
    "\n",
    "def topic_stability(H1, H2):\n",
    "    H1n = H1 / (np.linalg.norm(H1, axis=1, keepdims=True) + 1e-12)\n",
    "    H2n = H2 / (np.linalg.norm(H2, axis=1, keepdims=True) + 1e-12)\n",
    "    S   = cosine_similarity(H1n, H2n)\n",
    "    r, c = linear_sum_assignment(1 - S)\n",
    "    return S[r, c].mean()\n",
    "\n",
    "K_GRID = list(range(5, 21, 3))  # 5,8,11,14,17,20\n",
    "rows = []\n",
    "\n",
    "print(\"Evaluating K...\")\n",
    "m = X_topic.shape[0]\n",
    "boot_p = 0.8\n",
    "for k in K_GRID:\n",
    "    rng1 = np.random.RandomState(RSTATE)\n",
    "    rng2 = np.random.RandomState(RSTATE + 1)\n",
    "    idx1 = rng1.choice(m, int(m*boot_p), replace=False)\n",
    "    idx2 = rng2.choice(m, int(m*boot_p), replace=False)\n",
    "\n",
    "    nmf1, W1, H1 = fit_nmf(X_topic[idx1], k, seed=RSTATE)\n",
    "    nmf2, W2, H2 = fit_nmf(X_topic[idx2], k, seed=RSTATE+1)\n",
    "\n",
    "    stab = topic_stability(H1, H2)\n",
    "    rec_err = (nmf1.reconstruction_err_ + nmf2.reconstruction_err_) / 2.0\n",
    "    rows.append({\"K\": k, \"stability\": stab, \"reconstruction_err\": rec_err})\n",
    "\n",
    "k_eval = pd.DataFrame(rows).sort_values(\"K\")\n",
    "print(\"\\n=== K evaluation ===\")\n",
    "print(k_eval)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].plot(k_eval[\"K\"], k_eval[\"stability\"], marker='o'); ax[0].set_title(\"Stability ↑\"); ax[0].set_xlabel(\"K\"); ax[0].set_ylabel(\"mean cosine\")\n",
    "ax[1].plot(k_eval[\"K\"], k_eval[\"reconstruction_err\"], marker='o'); ax[1].set_title(\"Reconstruction error ↓\"); ax[1].set_xlabel(\"K\"); ax[1].set_ylabel(\"error\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "best_row = k_eval.sort_values([\"stability\", \"reconstruction_err\"], ascending=[False, True]).iloc[0]\n",
    "BEST_K = int(best_row[\"K\"])\n",
    "print(f\"\\nChosen K = {BEST_K} (stability={best_row['stability']:.4f}, rec_err={best_row['reconstruction_err']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c059c",
   "metadata": {},
   "source": [
    "## Step 4.3 — Final Topic Modeling and Assignment\n",
    "\n",
    "**Purpose:**\n",
    "This step fits the final **NMF model** using the optimal number of topics (`BEST_K`) and assigns each spam message to its most representative topic.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Final NMF fit**\n",
    "\n",
    "   * Uses all spam documents with `BEST_K` topics.\n",
    "   * Produces:\n",
    "\n",
    "     * `W`: document-topic matrix (topic weights per message).\n",
    "     * `H`: topic-term matrix (word importance per topic).\n",
    "\n",
    "2. **Top terms per topic**\n",
    "\n",
    "   * For each topic, prints the top 12 most relevant terms to allow human interpretation of themes.\n",
    "\n",
    "3. **Topic assignment per document**\n",
    "\n",
    "   * Each spam email is assigned:\n",
    "\n",
    "     * `topic`: index of the most probable topic.\n",
    "     * `topic_strength`: the confidence (max weight in `W`).\n",
    "\n",
    "4. **Export results**\n",
    "\n",
    "   * Creates `spam_topics_assignments.csv` containing (optionally) `subject`, topic assignment, topic strength, and cleaned text.\n",
    "   * Provides an overview of **topic distribution** (counts per topic).\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* Human-readable list of **top words per topic**.\n",
    "* CSV file with **topic assignments for each spam email**.\n",
    "* Summary of **how many messages fall into each topic**.\n",
    "\n",
    "This step completes the **topic modeling pipeline**, making it possible to interpret recurring spam themes and group messages by semantic similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abfd1d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP TERMS PER TOPIC ===\n",
      "Topic 00: online, want, new, click, meds, free, best, time, just, money, like, know\n",
      "Topic 01: computron, contact, ali duty, duty free, duty, 00, ali, remove, link, mail, reply, free\n",
      "Topic 02: company, statements, securities, stock, report, information, investment, looking statements, forward, forward looking, advice, looking\n",
      "Topic 03: xp, windows, adobe, software, office, professional, 00, 60, microsoft, 99, price, xp professional\n",
      "Topic 04: cialis, soft, tabs, soft tabs, viagra, cialis soft, hours, prescription, pills, tadalafil, 36 hours, 36\n",
      "Saved: spam_topics_assignments.csv (1525 rows)\n",
      "\n",
      "Topic distribution (counts):\n",
      "0    1064\n",
      "1      59\n",
      "2     132\n",
      "3     149\n",
      "4     121\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nmf_final, W, H = fit_nmf(X_topic, BEST_K, seed=RSTATE)\n",
    "\n",
    "def show_top_terms(H, feat_names, n_top=12):\n",
    "    for t in range(H.shape[0]):\n",
    "        top_idx = np.argsort(-H[t])[:n_top]\n",
    "        terms = \", \".join(feat_names[top_idx])\n",
    "        print(f\"Topic {t:02d}: {terms}\")\n",
    "\n",
    "print(\"\\n=== TOP TERMS PER TOPIC ===\")\n",
    "show_top_terms(H, feat_names, n_top=12)\n",
    "\n",
    "topic_labels   = W.argmax(axis=1)\n",
    "topic_strength = W.max(axis=1)\n",
    "\n",
    "spam_topics_df = spam_df.copy()\n",
    "spam_topics_df[\"topic\"] = topic_labels\n",
    "spam_topics_df[\"topic_strength\"] = topic_strength\n",
    "keep_cols = [\"topic\", \"topic_strength\", \"text_clean\"]\n",
    "if \"subject\" in spam_topics_df.columns:\n",
    "    keep_cols = [\"subject\"] + keep_cols\n",
    "\n",
    "spam_topics_export = spam_topics_df[keep_cols].reset_index(drop=True)\n",
    "spam_topics_export.to_csv(\"spam_topics_assignments.csv\", index=False)\n",
    "print(f\"Saved: spam_topics_assignments.csv ({len(spam_topics_export)} rows)\")\n",
    "\n",
    "topic_counts = pd.Series(topic_labels).value_counts().sort_index()\n",
    "print(\"\\nTopic distribution (counts):\")\n",
    "print(topic_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9248a",
   "metadata": {},
   "source": [
    "## Step 4.4 — Topic Heterogeneity Analysis\n",
    "\n",
    "**Purpose:**\n",
    "This step measures how **different or similar the topics are** in semantic space, providing insights into whether topics overlap or capture distinct themes.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Normalize topics (`Hn`)**\n",
    "\n",
    "   * Each topic’s term vector is L2-normalized so that comparisons are based on cosine similarity.\n",
    "\n",
    "2. **Compute pairwise distances (`D`)**\n",
    "\n",
    "   * Uses cosine similarity → transformed into cosine distance (`1 - similarity`).\n",
    "   * Lower distance = topics are semantically similar; higher distance = topics are distinct.\n",
    "\n",
    "3. **Summarize heterogeneity**\n",
    "\n",
    "   * Reports statistics (mean, median, min, max distance across topic pairs).\n",
    "\n",
    "4. **Visualize distances**\n",
    "\n",
    "   * Heatmap of the **topic distance matrix**, where darker squares mean higher similarity.\n",
    "\n",
    "5. **Export results**\n",
    "\n",
    "   * Saves full **topic distance matrix** as `spam_topic_distance_matrix.csv` for further inspection.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* Numeric summary of topic distances.\n",
    "* Heatmap visualization of topic similarities.\n",
    "* CSV file with all pairwise distances.\n",
    "\n",
    "This step validates whether the extracted topics are **well-separated** (ideal) or **overlapping** (indicating redundancy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "027cbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOPIC HETEROGENEITY (cosine distance) ===\n",
      "mean: 0.9005 | median: 0.9176 | min: 0.8083 | max: 0.9748\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAHmCAYAAABzt4RzAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXYJJREFUeJzt3Xl8TGf7P/DPRBIJiSTIhliqncSSVCJiC0pCaiuxNZbYq62lCFWq6M/zaKOKIiiliBCk9qW20KJIqC1FUNIsIpFKRFaT5fz+8J15jJmsk8yZZD7v12tebc595r6vM5mZXK77PudIBEEQQERERKQHDMQOgIiIiEhbmPgQERGR3mDiQ0RERHqDiQ8RERHpDSY+REREpDeY+BAREZHeYOJDREREeoOJDxEREekNJj5ERESkN5j4AEhISICjoyPmzp0rdih6r0ePHujRo4fWx/X394ejo6PStoiICDg6OmLNmjVaj6e6iImJQevWrfHTTz8pbVf3ehMVRRufxaL+DsydOxeOjo5ISEiotLEBYMuWLWjVqhUePnxYqeOQiImPo6NjmR779u0TK1SqQPr0B2/fvn16/94NDAyEpaUlRo0aJXYoRDpt+PDhsLKywnfffSd2KNWeoVgDT506VWXbtm3bkJGRgdGjR6NOnTpKbS1atKi0WGxtbXHs2DGYm5tX2hhUOlu3bhU7BAUXFxccO3YMVlZWYodSJV27dg2//fYbZs6cCVNTU7HDoSpMG59Fsf8OmJiYYMyYMfj+++9x7do1uLm5iRKHPhAt8Zk2bZrKtv379yMjIwNjxoxBo0aNtBaLkZERmjdvrrXxqGiNGzcWOwQFU1NTvi80sGPHDhgYGGDgwIFih0JVnDY+i7rwd+CDDz7AihUrsHPnTiY+lajKrPE5duwYRo4cibZt28LFxQX9+/fHhg0bIJPJVPaVrxPJyMjA4sWL0aVLFzg7O6NPnz4IDg7GmzekL26NT05ODjZu3IhBgwbB1dUVrq6u6N27N/773//i33//LTFuQRCwf/9++Pn5oUOHDnB2dka3bt0wYcIEHDt2TGX/pKQkLF68GF5eXmjdujXat2+PTz75BLdu3VLZd82aNXB0dERERASOHDmCQYMG4d1334Wnpye+/fZbxWtz6dIl+Pv7w83NDe3atcPnn3+OtLQ0lf4uX76MBQsWoE+fPnBzc4OLiwv69euHoKAgvHz5stjxjx8/jiFDhuDdd9+Fh4cHZs6cieTkZJXXODIyEoDyVKe/v79iv+LW+Bw7dgxjxoyBh4cHnJ2d0aNHDwQEBCAqKqqE38L/HD16FIMGDYKLiws6duyIzz//XCnO1xW1riA+Ph4LFixAz5494eLiAg8PD/Tv3x8LFy5UvK7+/v6YN28eAGDevHlKxytfK5CcnIygoCD4+fmhc+fOaN26NTw9PTFr1iz8/fffKvG8/j5NSEjAzJkz0b59ezg7O2PQoEE4e/ZskcddltfuyJEj8Pf3h7u7O5ydndG7d2+sW7dO7WetKJmZmThx4gRcXV1hZ2dX6ucVFhYiNDQUgwcPhqurK9q0aYPBgwdj586dKCwsVNrX09MTXbp0Uemje/fucHR0xNq1a5W2//7773B0dMSqVauUtufk5GDDhg0YMGAA2rRpA1dXV3z44Yc4cuSISt+vvydu3bqFSZMmwcPDo0LXgLz+e46Li8Nnn32G9u3bw9XVFePHj8f9+/cBAKmpqViwYAE8PT3h7OyMwYMH4/Lly2r7zMjIwPLly+Hj4wNnZ2e0a9cOEyZMwMWLF8t9jBXxPvn333+xdOlS+Pj4oE2bNnB3d4ePjw/mzp2L+Ph4tTG9Tj51npeXh6CgIHh7e8PZ2Rk+Pj7Ys2ePYr/Q0FD0798fLi4u6Nq1K1avXq3yfirrWs99+/Zh2rRp8PLygouLC9zc3ODn54eDBw+q3V8eq0wmQ1BQEHx8fNC6dWul8WxtbeHu7o4TJ04gMzOzVHFQ2YlW8SmLFStWYMOGDbCyskK/fv1Qq1YtnD9/HitWrMCFCxewefNmGBsbKz1HJpNh7NixyMjIQN++fZGXl4cTJ05gyZIliImJwaJFi0ocNz09HaNHj0Z0dDSaNWuGwYMHw8jICPHx8di7dy969uyJ+vXrF9vHypUrsWHDBjRq1Ai9e/eGubk5UlJSEBUVhePHj6NPnz6KfW/fvo3x48cjPT0dnp6e6NWrF9LS0nD69GmMGDECa9euRbdu3VTGCAkJwblz5+Dt7Q0PDw/88ccf2Lp1K9LT0+Hl5YWZM2fivffew4cffojr16/j0KFDSEtLw6ZNm5T6+emnnxATEwNXV1d069YNMpkM165dw5o1axAREYGtW7eiRo0aKuPv3LkTZ86cQY8ePdCuXTvcunULx44dQ3R0NA4ePAhjY2PUqVMHU6dOxf79+/H48WOlqc6GDRsW+xoKgoB58+Zh//79sLKyQs+ePVG3bl0kJSUhIiICzZo1g7Ozc7F9AK+m0b799lvUqVMHAwcOhLm5OS5cuIDhw4fDzMysxOcDwNOnTzFkyBBkZmaia9eu6NWrF16+fImEhAQcOnQIo0aNgpWVFXx9fWFubo7w8HB4eXkpTdXKp3GvXr2Kn376Ce3bt0evXr1Qq1YtxMbG4sSJEzhz5gxCQ0Ph5OSkEsPjx48xdOhQODg4YMCAAUhPT8exY8cwefJkbNmyBR06dCj3azdv3jzs27cPdnZ26NWrF+rUqYMbN25g1apVuHTpErZs2QJDw5K/Nq5cuYK8vDy0bdu2VK+r3Oeff44jR47A3t4eQ4YMgUQiwenTp/H//t//w59//only5cr9u3QoQMOHz6Mhw8fKv6lHhsbi8TERACvEvkpU6Yo9pcnBR07dlRse/HiBcaMGYM7d+6gVatWGDx4MAoLC3HhwgXMmjULDx48wMyZM1XivHHjBjZs2IC2bdti8ODBSEtLg5GRUZmOtSTy33Pz5s3h6+uLx48f49SpU/D398fu3bsxceJEmJmZoXfv3or3wEcffYQTJ06gQYMGSsc4fPhw/P3333B2dsaYMWOQlpaGX3/9FePHj8fXX38NPz+/Mh1jRbxPcnJyMHz4cMTFxaFz587o0aMHBEFAYmIiwsPD4ePjAwcHh1K9VgEBAbh58ya6desGQ0NDnDhxAgsWLIChoSHu3buHAwcO4L333kOHDh1w5swZrF27FiYmJpg0aVIZfiPKvv76a7z99tto164drK2t8fz5c/z++++YM2cOYmJiMGPGDLXP++yzzxAVFYWuXbvC29sb9erVU2p3c3NDZGQkrly5gu7du5c7PiqGoEO6d+8uSKVSIT4+XrHt2rVrglQqFbp16yY8ffpUsT0vL0/4+OOPBalUKqxfv15tP35+fsLLly8V29PS0gQvLy9BKpUKkZGRiu3x8fGCVCoVvvjiC6V+AgICBKlUKixcuFAoKChQasvMzBRevHhR4jF5eHgIXbp0EbKzs1Xanj17pnQ83t7eQuvWrYWIiAil/ZKSkgRPT0+hc+fOSsezevVqQSqVCm5ubsLff/+t2P7y5UuhT58+gpOTk+Dh4aHUX0FBgTB27FhBKpUKd+7cURonLi5OKCwsVIlz5cqVglQqFY4ePaq0XT6+q6urEB0drdQmf+3efM6oUaMEqVSqMoZc9+7dhe7duytt27VrlyCVSoXBgwervOb5+flCcnJykf3JxcfHC61atRLatWun9P4qKCgQpk6dKkilUpW4Ll++LEilUmH16tWKbcHBwYJUKhW2bt2qMkZWVpaQk5Oj+Hnv3r2CVCoV9u7dqzamf//9V8jIyFDZfvfuXaFNmzbChAkTVI5BHueaNWuU2s6dOydIpVJh4sSJStvL8trJ450yZYrScQjC/37X6o5bnWXLlglSqVQ4fvy42nZ174PDhw8LUqlUGDhwoJCZmanYnpWVJfj6+gpSqVQ4dOiQYntYWJgglUqFkJAQxbbQ0FBBKpUK48aNE1q1aqX0uRswYIDg4uKi9Bn64osvBKlUKmzcuFEpltzcXGH8+PGCo6Oj0udE/p6QSqVCaGio2mM7deqUsHr16lI/tmzZovT813/P69atU2oLCgoSpFKp0K5dO2HBggVK30v79+8XpFKpsGTJEqXnLFiwQJBKpcKCBQuUPt8xMTGCm5ub0KpVK6XPREnHWFHvk/DwcLXxCsKr77DXPxvqPouC8L/30aBBg4T09HTF9ri4OKFVq1aCu7u70L17dyEpKUnRlp6eLnh4eAjt27cX8vLyFNuL+jsgf4+8/hoJgiDExsaqjXv06NFCy5YtlcZ8PdZ+/fopffe/6dSpU4JUKhWWLl1a5D6kGZ2f6tq7dy8A4NNPP4W1tbViu6GhIb744gsYGBggLCxM7XNnzZqlVAmytLTE5MmTAaDEM22ePXuGY8eOwdraWjHO62rXrl3qRXCGhoZqKyV169ZV/P9vv/2GuLg4jBo1Ch4eHkr72draYuLEiUhJScGlS5dU+vH391eamzY2Nkbv3r1RWFiIbt26KfVnYGCADz74AAAQHR2t1I+DgwMkEolK/2PHjgUAnD9/Xu3xqTtTa+jQoQBQpmmoooSEhAAAFi9erPKa16hRAzY2NiX2cfjwYeTl5WHUqFFK68cMDAwwZ84cld9vSUxMTFS21apVS+32otSrV09tpcnJyQnt27dHREQE8vLyVNobNmyITz/9VGlbly5d0KBBA5Up0bK8dsHBwTA0NMQ333yjchyTJ0+GpaUlDh8+XKpje/LkCQAofWZLIv+sz5o1C7Vr11Zsr1WrFj7//HMAUPqsyys3r38mLl26hPr168Pf3x95eXn4888/AQBpaWmIjo5G27ZtFd8JaWlpOHToEFq3bo2PPvpIKZaaNWvi888/hyAIao+5RYsWaqskAHD69GkEBQWV+hEcHKy2n4YNG6pUJHx9fQG8qmi/+b7t378/DA0NcffuXcU2mUyGQ4cOoVatWggICFD6fDdt2lTxOh04cKDUx1iR7xNA/WfJ2Ni41FVYAJg9e7bSCTEODg5wc3PDixcvMHnyZNja2ira6tSpgx49eiAtLa3Iae7SULce0djYGCNHjkR+fr7a72oAmD59utJ3/5vknxn5Z4gqns5Pdd25cwcAlMr3cs2aNYOdnR0SEhKQkZGh9MVuaGgIV1dXlefIkwB5v0WJiopCYWEh2rVrh1q1apU7/v79+2P79u3o06cPevfujXbt2sHV1VXlj9CNGzcAAImJiWqvVfHPP/8AAB4+fKgy3dW6dWuV/eUf9FatWhXZlpSUpLQ9OzsbwcHBOHXqFP755x9kZWUprYd6+vSp2mNUN81kb28P4NV0oSays7Nx//591K9fHy1btix3P/Lfd7t27VTaHBwcYG9vj8ePH5fYT48ePbBixQosXrwYFy5cgKenJ9zc3PD222+rTRpL8ttvv2HXrl3466+/kJaWhvz8fKX2tLQ0lcTOyclJbSJtZ2eneB8BZXvtcnJyEB0dDSsrK2zbtk3tPsbGxqW+xsjz588BABYWFqXaH3j1OzIwMFBJ/IFXv7caNWoo/VFv2LAhHBwcEBkZicLCQkgkEkRGRqJTp05o164dDA0NcenSJXh6eiIiIgKCICh9j0RFRaGgoAASiUTtZ07+u3j06JFKm4uLS5HHERgYiMDAwFIfd1FatGih8nuWvxeaNm2qkhjUqFED9erVU/pjHhMTg5ycHLi5ucHS0lJljA4dOmD9+vVKr6ucumOsyPeJh4cHbG1tsXHjRty+fRvdunWDm5ub2uMuibrvQPlrVVxbUlJSiVPtRUlMTMRPP/2ES5cu4cmTJ8jNzVVqLyqpKu69A/zvM6NuHSZVDJ1PfDIyMgAU/S9Ha2trJCYm4sWLF0rJhJWVldoPj7wfeb9FefHiBQAo/UuhPObNm4dGjRph37592LhxIzZu3AhDQ0N07doVc+fORZMmTQD87w/F8ePHi+0vOztbZZu6ypP82Itre/2PbF5eHsaMGYNbt25BKpWiT58+qFu3rmKePigoqMhFi8WN8eYCwrKS/540/T3I+ylqTVb9+vVLlfg0bNgQv/zyC9asWYPz58/j5MmTAF4leuPHj8fo0aNLHdO2bdvwzTffwMLCAp06dYK9vT1MTU0V61qio6PVvuZvXupBztDQUOn1Lstr9+LFCwiCgNTUVAQFBZX6GIpSs2ZNAFC7KL4oGRkZsLCwUFmvB7w6NisrKzx79kxpe8eOHbFnzx7cvn0bRkZGSE1NRYcOHWBmZgZnZ2fFv7rl/3098ZF/5qKiooqtTGZlZalsK2ltX0VQ97mSfx6LqjYbGhoqfa5L8/0J/O/77nXqjrEi3ydmZmbYs2cPVq9ejTNnzuDChQsAXn13jxgxAp9++mmp100V91qpqxzJ2978h0ZpxcfHY8iQIXjx4gXc3d3h6ekJMzMz1KhRA48fP8b+/fuL/L4sqQoqT6DKUj2mstH5xEf+hv7333/VlhZTUlKU9pNLS0tDQUGBSvJT1P5vkv9x0aQUCrxKAMaOHYuxY8fi2bNn+PPPP3H06FEcP34cf//9N44ePQpjY2NFPOvWrYOXl5dGY5ZHeHg4bt26hUGDBuHbb79Vanv69GmF/DEsD/nrounv4fX30TvvvKPSXpoz9OSaN2+OH374Afn5+YiOjsbFixcREhKCJUuWwNTUVDHNV5z8/HwEBQXB2toa+/btU6nqvF65Ka+yvHbyPw4tW7bE/v37NR5bvmBTnlyUhrm5OdLT05GXl6fyBy8/Px9paWkqf8Q6dOiAPXv24NKlS4rnyKfA2rdvj40bN+L58+e4fPkyzM3NlSqg8tdn7NixijPwSqu46t7p06fVVlCKYm5urphOrmivv+/VKe77UN0xVvT7xM7ODt988w0EQcDff/+Ny5cvY8eOHVi7di0KCwuLXCAsti1btuD58+f49ttvMWjQIKW2I0eOFPvalFQZln9mipsOI83ofOLTokUL3L59GxERESqJT2xsLJKSktCoUSOVfwXn5+fj+vXrcHd3V9ouP526pNK/i4sLDAwMcOXKFWRnZ2s03SVXr1499OrVC7169cKYMWNw+fJl3L9/H61bt8a7774L4NWZPmIkPnFxcQCAnj17qrRduXKlwsaRr0lQl5SqU6tWLUilUty/fx937twp93RXy5YtcfLkSVy5ckXprB7g1b/eyjOfbmhoiNatW6N169Zwc3PDyJEjER4erkh8Xj/WN6WlpeHFixfo1auXStKTlZWF27dvlzmeN5XltatduzbeeecdPHjwAM+fP1c7LVIW8jVfjx49QqdOnUr1nBYtWuDSpUu4evWqyu/oypUrKCgoUDmGDh06QCKR4NKlSzA2NoaDg4NiDVfHjh3x448/4sCBA/jnn3/g5eWl9J6Tf8avXr2qyaGqOH36dJmSgoYNG1Za4tOsWTOYmpoiOjoaL168UPmejIiIAFDy96FcRb9P5CQSCd555x2888478Pb2xnvvvYfw8HCdTXxiY2MBAL169VJpk/+NKS/51GplXrRX3+n84ubBgwcDANavX4/U1FTF9oKCAixduhSFhYUYMmSI2ucuX75cqdz4/PlzrF+/HgBUsvQ31a1bF3369EFKSopinNdlZWWVOF0mk8kUiytfl5eXp1j7Ir+irZeXFxo3boydO3fi999/V9vf9evXkZOTU+yY5SWf537zQxsfH4/vv/++wsaRf1HKTzkuDfl1fhYuXKjymhcWFha59uh1/fv3h5GREUJCQpSuRVJYWIjvvvuu1FNyf/31l9rfu/xf1K+Xp+VXmVWXVNWrVw+mpqa4ffu20lRKXl4elixZUmHz+2V57caOHYu8vDx8+eWXaqc+0tPTS52QydfplKVyJf+sL1++XOl9npOToziN/c3Per169fDOO+/g2rVrKkmtm5sbatasiY0bNwJQXSdYr1499O/fH3/99RfWrl2rNkGNi4tTup5MaQQGBuLevXulfpw5c6ZM/ZeFsbEx+vfvj6ysLJXrF8XFxWH79u0wMjLCgAEDSt1nRb1PHjx4oLYSpe6zpGuK+r48f/48fvnlF436vnnzJoBXFUuqHDpf8XFzc8PEiROxadMm9OvXDz4+PjA1NcX58+dx//59tG3bFhMmTFB5nrW1NWQyGfr164cePXogPz8fx48fR0pKCkaMGKF2keubFi5ciAcPHmDXrl2IjIyEp6cnjIyMkJCQgAsXLmD9+vXFvjlzc3MxYsQINGnSBK1atUKDBg3w8uVLXLx4EQ8fPkSPHj0UZ2MZGRlhzZo1mDhxIiZNmgRXV1e0aNECJiYmSEpKQlRUFOLj43HhwoVKufx/9+7d0aRJE2zZsgX3799HixYt8OTJE5w9exbvvfdemRKV4nTs2BHHjx/HtGnT0K1bN9SsWRMNGjQo9uq+Q4cOxdWrV3Hw4EH06tULXl5eqFu3Lp4+fYrLly9j8ODBaq8E/rpGjRph1qxZCAwMhK+vr+KaShcuXEBGRgYcHR1x7969EuM/ePAgdu/ejbZt28LBwQEWFhaIi4vD2bNnYWxsjDFjxij2bdOmDUxNTbFt2zY8f/5csWbC398f5ubm8Pf3x8aNG9G/f394eXkhLy8PERERSE9PV5zVpamyvHZDhgzB7du3sXPnTvTs2ROenp6wt7dHeno6EhIScOXKFQwaNAiLFy8ucVypVIpmzZrh8uXLpa7u9e/fH+Hh4fj111/Rt29feHt7K9Y7JSQkoE+fPoozEl/XoUMHxUX9Xk98jI2N4ebmpljf82YVCXj1GY+NjcXq1atx6NAhuLm5oX79+nj69CkePnyIqKgorFixotTXk9FFs2bNwtWrVxESEoKoqCi0b99ecR2frKwsLFiwoEzHV1Hvkz/++APLli1DmzZt0LRpU9SrVw9JSUkIDw+HgYGB2u91XTFixAjs27cP06dPh4+PD2xsbPDgwQOcP38evXv3Vntx2tIoLCzExYsX0axZM0il0gqOmuR0PvEBXl3UrGXLlggJCcGBAweQn5+Pxo0bY8aMGRg/frzaxZDGxsbYunUrVqxYgaNHjyItLQ0ODg6YNGmS0pWCi2NhYYFdu3Zh27ZtOHbsGPbs2QMDAwPY29tj8ODBePvtt4t9vqmpKWbPno2IiAhcv34dp0+fRu3atdG4cWN8/fXXin/hyjk5OeHgwYPYsmULfvvtN+zbtw8GBgawtrZGy5YtMW3atEq7V02tWrWwbds2fP/994iMjMTVq1fh4OCAyZMnY9y4ceX+IL9p6NChSExMxNGjR7Fp0ybk5+fDw8Oj2MRHIpHgu+++g6enJ/bs2YNff/0VMpkM1tbWaNu2banv5j5u3DhYW1tj8+bN2L9/P2rXrg1PT098/vnnmD17dqn66NevH2QyGa5fv47bt28jNzcXtra26Nu3L8aNG6f0ZWVhYYHVq1dj7dq12L9/v2Jh+gcffABzc3PFaa1hYWHYvXs3zM3N0alTJ8yYMaPC7kJd1tdu0aJF6Nq1K3bt2oWLFy8qFhzb29tjwoQJahOPogwfPhzffPMNLly4oPbCm+qsWLEC7dq1w969e7F7924Ar9ZUjR8/HsOHD1f7nI4dOyI4OBgSiUTlHyIdO3ZUnOKubm2XmZkZtm/fjj179uDIkSM4efIkXr58ifr166NJkyaYN29eqafqdJWlpSV2796NDRs24NSpU9iyZQtMTEzg4uKCCRMmwNPTs8x9VsT7pEuXLnjy5AmuXLmC8PBwZGZmwsbGBp07d8bYsWN1+pYNTk5OCA4Oxg8//IDff/8d+fn5cHJyQlBQEMzNzcv9fXnx4kU8ffq0zGvOqGwkgvDG/RuqAfmXeWWWkImoeJmZmfD29oarq6tiipmIijZt2jRERkbi9OnTvGl2JdL5NT5EVDWZmZlh2rRpOHPmDP766y+xwyHSaXfu3MGpU6cwbdo0Jj2VrEpMdRFR1eTn54eMjIwyXS6ASB+lpKRg+vTpRV4RnCoOp7qIiIhIb1TLxIeIiIhIHa7xISIiIr3BNT5ERERaVJhUcdfoMbC7X2F96QtWfIiIiEhvsOLzf3oalHxjSVI2+6Hm95PSRw9e2okdQpXjYJxa8k6k4tFLm5J3IiUzW5ys9DEKUbpb5JQGqxdlx8SHiIhIiwqEikt8+Ee87JgsEhERkd5gskhERKRFheBVZMTExIeIiEiLKnKND5Udp7qIiIhIb7DiQ0REpEUFvGGCqJj4EBERaRHX+IiLU11ERESkN1jxISIi0qICVnxExcSHiIhIizjVJS5OdREREZHeYMWHiIhIi3hWl7iY+BAREWkRL18oLk51ERERkd5gxYeIiEiLeFaXuJj4EBERaVEB8x5RcaqLiIiI9AYrPkRERFrExc3iYuJDRESkRQWQiB2CXuNUFxEREekNVnyIiIi0qJCLm0XFig8RERHpDVZ8iIiItIhrfMTFxIeIiEiLmPiIi1NdREREpDdY8SEiItKiQoEVHzEx8SEiItIiTnWJi1NdREREpDdY8SEiItKiAtYcRMXEh4iISIu4xkdcTDuJiIhIb7DiQ0REpEVc3CwuJj5ERERaVCBwskVMfPWJiIhIb7DiQ0REpEWFrDmISqcTn+TkZERFRSEpKQk5OTkwNTWFnZ0dnJ2dYWtrK3Z4REREZcY1PuLSycTnwYMHWLJkCSIiIgAAgiAo2iSSV2+Y9u3b48svv4RUKhUlRiIiIqp6dC7xefDgAfz8/FBYWIiBAwfC1dUVtra2qFmzJl6+fInk5GRcv34dx48fx/DhwxEaGsrkh4iIqgwubhaXziU+K1asgIWFBXbs2AF7e3u1+wwbNgzTpk3DqFGj8MMPP2DdunVajpKIiKh8CjnVJSqdSzv//PNP+Pv7F5n0yDVo0ACjRo3C1atXtRQZERERVXU6V/HJy8uDsbFxqfatWbMm8vLyKjkiIiKiisN7dYlL5159qVSK3bt3Izs7u9j9srKysGvXLq7vISKiKqVAMKiwB5WdzlV8JkyYgM8++wz9+vXDkCFDFIubjY2NIZPJFIubw8LCkJSUhFWrVokdMhEREVUROpf49OrVC//5z3+wdOlSrF69WnH6+usEQUDt2rXx9ddfo1evXiJESUREVD68gKG4dC7xAYChQ4fCx8cH4eHhuHnzJpKSkpCbmwsTExPY2dnBxcUF3t7eqFOnjtihEhERlUmBwLO6xKSTiQ8A1KlTB76+vvD19RU7FCIiIqomdDbxISIiqo54Vpe4mPgQERFpUSHPxhIVX30iIiLSG6z4EBERaRGnusTFV5+IiIj0Bis+REREWsTT2cXFxIeIiEiLeAFDcfHVJyIiIr3Big8REZEW8eai4mLiQ0REpEWF4BofMTHtJCIiIr3Big8REZEWcapLXEx8iIiItIgXMBQXX30iIiLSG6z4EBERaVEhL2AoKiY+REREWsSpLnEx8SEiItJTJ0+exKZNm3D//n0YGRmhbdu2CAgIgFQqLdXzo6OjsWHDBty8eRMpKSmoV68eWrVqhQkTJsDNza2Soy8fpp1ERERaVCgYVNhDE2FhYZg2bRpycnIwe/ZsfPLJJ7h37x78/Pxw7969Ep9/69YtDB06FFevXoWvry8WLlwIX19f3LhxAyNHjsSFCxc0iq+ysOJDRESkRQU6cAHD9PR0BAYGws7ODqGhoTAzMwMA9O7dG3379sWSJUsQHBxcbB/BwcGQyWTYvHmzUoXI29sbgwYNwp49e+Dp6Vmpx1EerPgQERHpmfDwcGRmZmLo0KGKpAcAGjRoAB8fH0RERODJkyfF9pGZmQkAsLGxUdpua2sLADA1Na3gqCsGKz5ERERapOkU1eu8vLyKbQ8PD1e7/ebNmwAAV1dXlTZXV1fs378fUVFRsLe3L7JvT09PnD17FrNmzcJnn30GOzs7JCYmYtWqVbCwsMD48ePLcCTaw8SHiIhIi3Rhqis5ORkAYGdnp9Im35aUlFRsH8OHD0dycjJCQkIwbNgwxXapVIo9e/agadOmFRdwBWLiQ0REVEUVVdEpSU5ODgDA2NhYpU2+LTc3t9g+DAwMYGtrCycnJ3h7e6Np06b4559/sHnzZkycOBHbtm1Dw4YNyxVfZWLiQ0REpEUVOdVVXvL1NzKZTKVNvs3ExKTYPpYvX44tW7Zg//79SoubPT09MWjQIHz33XdYtWpVBUZdMZj4EBERaZEu3KRUvgA5KSkJzZs3V2qTT3GpmwaTy8vLw9atW/HWW2+pXPPH0dERb731FiIiIio46ooh/qtPREREWuXi4gIAuH79ukrbjRs3AADOzs5FPj8tLQ15eXkoKChQ256fn19km9iY+BAREWlRISQV9igvb29v1K5dG2FhYYrT0gEgMTERx48fh4eHh+KMrpycHDx8+BBPnz5V7Fe/fn1YWVkhJiZGkSjJXb9+Hf/8848iudI1THyIiIi0qEAwqLBHeVlYWGDOnDlISkrC8OHDERISgp9//hmjRo0CAMyfP1+x761bt9CnTx+sWLFCsc3AwADTpk1DYWEhxo0bh6VLl2L37t1YunQpxo8fDyMjI0yfPr38L1Il4hofIiIiPeTn5wdLS0ts3rwZy5Ytg5GREdzd3TFjxgw4OTmV+PyRI0fC1tYW27dvxy+//IKsrCxYWlqiS5cumDx5cqn6EAMTHyIiIi0qFMS/jo/c+++/j/fff7/Yfdq3b1/kvbu8vb3h7e1dGaFVGiY+/2f2w9tih1DlfN+8ldghVEm7Ei6JHUKVk16om4skdV3/Wtlih0BqFHCViaj46hMREZHeYMWHiIhIi3RpqksfseJDREREeoMVHyIiIi0qZM1BVEx8iIiItKiAU12iYtpJREREeoMVHyIiIi3i4mZxMfEhIiLSokIduDu7PuOrT0RERHqDFR8iIiItKtDgruqkOSY+REREWsQ1PuLiVBcRERHpDVZ8iIiItIiLm8XFxIeIiEiLCrnGR1RMO4mIiEhvsOJDRESkRbxlhbiY+BAREWkR1/iIi68+ERER6Q1WfIiIiLSI1/ERFxMfIiIiLeJZXeLiVBcRERHpDVZ8iIiItIhTXeJi4kNERKRFPKtLXHz1iYiISG+w4kNERKRFnOoSFxMfIiIiLeJZXeLiVBcRERHpDVZ8iIiItIhTXeJi4kNERKRFTHzExakuIiIi0hus+BAREWkRKz7iYsWHiIiI9AYrPkRERFrEio+4mPgQERFpEa/jIy5OdREREZHeYMWHiIhIizjVJS4mPkRERFrExEdcVX6qa/369WjZsqXYYRAREVEVUC0qPoIgiB0CERFRqbDiI65qkfgQERFVFUx8xKWTiU/r1q1LvS+rPURERNVHXl4eLl26hEePHiErKwtTpkwBALx8+RKZmZmwsrKCgUH5V+roZOJTUFCAevXqoVmzZiXum5iYiMTERC1ERUREpDmBFZ8inTt3DvPnz8e///4LQRAgkUgUic/du3cxfPhwLFu2DP369Sv3GDqZ+DRu3Bj29vbYunVrifuuX78eq1evrvygiIiIKgAvYKheVFQUpkyZAisrK8ybNw+3bt3C0aNHFe1t2rRBo0aNcOrUKY0SH508q6tly5a4e/eu2GEQERGRlqxbtw6mpqbYu3cvRo8ejaZNm6rs4+zsjOjoaI3G0cnEp0WLFkhPT0d8fHyJ+zZo0ADu7u5aiIqIiEhzhYKkwh7VybVr1+Dl5QVra+si97Gzs0NKSopG4+hk4jNp0iRER0fDwcGhxH0HDBiA7du3ayEqIiIizQmCpMIe1Ul2djasrKyK3Sc3N1fjk5p0MvEhIiIi/WJra4u///672H3u3r2LRo0aaTQOEx8iIiIt4lSXel27dsWFCxdw9epVte2///47rl+/ju7du2s0jk6e1UVERFRdVbcpqory8ccf4+jRo5gwYQJGjRqFx48fAwB+++03XLlyBTt37oS1tTXGjh2r0ThMfIiIiEh0tra2+PnnnzFjxgxs3rxZsf3TTz+FIAho3Lgx1qxZg7p162o0DhMfIiIiLapuU1QVqVWrVjh+/Dh+++033LhxA8+fP4eZmRnatGkDLy8vGBpqnrYw8SEiItIi3mmpeDVq1ICXlxe8vLwqpX8ubiYiIiK9wcSHiIhIiwohqbBHdbJu3Tq0atUKycnJatuTk5PRunVrbNy4UaNxmPgQERFpES9gqN7Zs2fh4eEBW1tbte22trZo3749wsPDNRqHiQ8RERGJLi4uDs2bNy92n+bNmyM2Nlajcbi4mYiISIt4Vpd6ubm5MDU1LXafmjVrIisrS6NxmPgQERFpEc/qUs/Ozg43btwodp8bN24UORVWWpzqIiIiItF16dIFV69exbFjx9S2Hz16FFeuXEHXrl01GocVHyIiIi2qbouSK8pHH32Ew4cPY9asWTh27Bi6dOkCW1tbJCcn49y5czhz5gwsLCwwadIkjcZh4kNERESis7W1xaZNmzB9+nScPn1a6ewtQRDQsGFDrFq1CnZ2dhqNw8SHiIhIi1jxKZqzszNOnDiBs2fP4saNG8jIyIC5uTnatGmD7t27w8jISOMxmPgQERFpEc/qKp6RkRF69eqFXr16VUr/XNxMREREeoMVHyIiIi3i6ezFi4qKwq1bt/DixQsUFBSotEskEkyZMqXc/TPxISIi0iJdWuNz8uRJbNq0Cffv34eRkRHatm2LgIAASKXSUvdx+/ZtbNiwAX/++SfS09NhZWWFVq1a4auvvkKjRo1K3U9mZiamTp2KiIgICMVkh0x8iIiIqMzCwsLw1VdfQSqVYvbs2Xj58iVCQkLg5+eH0NBQODo6ltjHkSNHMGfOHDg5OWHMmDGoW7cuUlNTERUVhfT09DIlPt999x0uX74Md3d3DBo0CPb29qhRo4Ymh6gWEx8iIiIt0oWKT3p6OgIDA2FnZ4fQ0FCYmZkBAHr37o2+fftiyZIlCA4OLraPmJgYfPnll+jXrx8CAwNhYKDZsuHw8HC0bNkSwcHBGvdVHC5uJiIi0iKhAh/lFR4ejszMTAwdOlSR9ABAgwYN4OPjg4iICDx58qTYPjZv3oyCggLMnTsXBgYGyMnJgUwmK3dMGRkZaN++faUmPQArPkRERFWWl5dXse2vXwTwdTdv3gQAuLq6qrS5urpi//79iIqKgr29fZF9//bbb3jrrbdw8+ZNLFu2DA8fPoSBgQFcXFwQEBCA9u3bl+FIgCZNmuDZs2dlek55sOJDRESkRYIgqbBHeSUnJwOA2qsgy7clJSUV+fyMjAykpKTg6dOnmDp1Kjp06ICgoCAEBATg77//xvjx4xEZGVmmmEaOHImzZ88qYqssrPgQERFpUwWezl5URackOTk5AABjY2OVNvm23NzcIp+flZUFAHj+/Dk+/vhjBAQEKNpat26NsWPHYsWKFdi1a1epY+ratSsuX76M4cOHY8qUKWjVqhXq1Kmjdt8GDRqUut83MfEhIiLSM6ampgCgdk2OfJuJiUmRz69Zs6bi/wcNGqTU1rFjRzRo0AA3b95ETk6OYqyS9OjRAxKJBIIg4KuvvipyP4lEgjt37pSqT3WY+BAREWmRLpzVZWtrC+DVdFbz5s2V2uRTXMXdDNTS0hK1atVCdnY2rK2tVdqtra2RmJiIFy9elDrxGThwICSSyn9tmPgQERFpkS5cudnFxQW7du3C9evX0blzZ6W2GzduAHh1w9CiSCQSODs7IyIiQm3y9OTJExgaGsLS0rLUMQUGBpZ6X01wcTMREZGe8fb2Ru3atREWFobMzEzF9sTERBw/fhweHh6KM7pycnLw8OFDPH36VKkPX19fAMCOHTuUtp8+fRpPnz5Fx44dlabEdAUrPkRERFqkC1NdFhYWmDNnDhYtWoThw4fjww8/hEwmQ0hICABg/vz5in1v3bqF0aNHw9fXV6kqM2DAABw+fBg7duzAs2fP0L59e8THxyMkJATm5uaYO3eu1o+rNJj4/J8HL4ueyyT1diVcEjuEKsmvUUexQ6hyfo6/IHYIVdJLIU/sEKqc0q1G0ZAOJD4A4OfnB0tLS2zevBnLli2DkZER3N3dMWPGDDg5OZX4fAMDA6xfvx4//fQTDh06hPDwcNSuXRve3t747LPP0KxZs3LFdevWLVy4cAHJyclqF19LJBJ888035eobACRCcXcC0yNB0T3EDqHKGV7nvtghVElMfMqOiU/51Dco+qwcUs/UPqbSx2i+q/x/tN/00O/LCutLbIIgYO7cuTh06BAEQVCc4SUn/1kikeDu3bvlHodrfIiIiLRIECruUZ2EhITg4MGDGDBgAPbu3QtBEDBmzBjs2rULAQEBqF27Nvr27YvTp09rNA6nuoiIiLSpmiUsFWX//v1o1qyZ0joic3NztGnTBm3atIGnpyeGDRuGTp06YfDgweUehxUfIiIiEl1MTAw6dOigtK2goEDx/y1btkT37t2xc+dOjcZh4kNERKRFunCvLl1lbm6u+H9TU1Okp6crtTdp0gSPHj3SaAxOdREREWkTp7rUsrGxUbpBqYODA27fvq20T2xsLGrVqqXROKz4EBERkehcXFyUEp2uXbvi1q1bWLt2LR48eIAdO3YgPDwc7777rkbjMPEhIiLSIk51qefj44OCggLEx8cDACZOnIgGDRpgzZo1+OCDD/Cf//wH5ubmmDVrlkbjcKqLiIhImzjVpZa3tze8vb0VP1taWuLAgQPYs2cP4uLi0LBhQwwcOBA2NjYajcPEh4iIiHSSubk5JkyYUKF9cqqLiIhIqyQV+Kg+5s2bh/Dw8GL3OXv2LObNm6fROEx8iIiISHT79+8v8VYU0dHROHDggEbjcKqLiIhIm7jGp9xkMhlq1KihUR9MfIiIiLSJiU+RJJKip+9kMhmuXr2K+vXrazRGuRKf1NRUPHz4EC1atICZmZlKe2ZmJu7evYvmzZujbt26GgVIRERE1ZOXl5fSz9u2bcO+fftU9issLERqaipkMhn8/Pw0GrNca3zWrVuHTz75pMhyk4GBAT755BNs3LhRo+CIiIiqHUFScY8qThAExUMikSj9/PrD0NAQUqkUH330EebMmaPRmOWq+Fy8eBGdO3eGqamp2vZatWqhc+fOuHDhgkbBERERVTcCp7oUzpw5o/h/JycnjBkzBlOnTq3UMctV8Xny5AkcHByK3cfBwQFPnjwpV1BERESkX4KDg+Hr61vp45Sr4iORSJCXl1fsPnl5eSgsLCxXUERERNUWKz5qeXh4qN2el5eHBw8ewMTEBG+99ZbG45Sr4tOsWbNip7EEQcCFCxfQuHHjcgdGRERULXGNj1rHjh3D9OnT8fz5c8W2uLg49OvXD4MHD0bfvn0xdepU5OfnazROuRIfHx8fPHr0CIsXL0Zubq5SW25uLhYvXoyYmBj06dNHo+CIiIhIP+zduxePHj2CpaWlYltgYCBiY2PRvn17ODo6Ijw8XO1ZX2VRrqmu0aNH4+jRowgNDcXp06fRrl072NjY4OnTp7hy5QqePn2qWKRERERE/yPhVJdaDx8+RKdOnRQ/Z2Zm4ty5c+jduzdWrlyJvLw8DBw4EPv27cOwYcPKPU65Eh8TExNs374d/+///T/8+uuvOHr0qKLNwMAA/fr1w8KFC2FiYlLuwIiIiKolJj5qpaamwtraWvHz9evXkZ+fj759+wIAjIyM0KlTJ6WcozzKfeXmOnXqYPny5Zg/fz6ioqLw4sUL1KlTB87OzrxoIREREZVJ7dq1kZmZqfj5ypUrkEgkcHNzU2yrWbMmsrKyNBpH41tW1K1bF926ddO0GyIiIv1QzRYlV5QmTZrg3LlzkMlkAIBff/0Vjo6OSsWUxMRE1KtXT6NxeHd2IiIibRIq8FGNfPjhh4iPj0evXr3Qp08fJCQkYNCgQUr73L59G2+//bZG45Sq4jNv3jxIJBIEBASgfv36mDdvXqk6l0gk+OabbzQKkIiIiKo/X19fxMTEYPfu3QCAkSNHwt/fX9F+7do1xMbGarSwGQAkglDyxbOdnJwgkUhw7NgxNGvWDE5OTqXrXCLB3bt3NQpQW4Kie4gdQpUzvM59sUOokvwadRQ7hCrn53je/qY86hvwBJOyMrWPqfQxmq7/vsL6+ufT2RXWl66TyWR4+fIlTE1NYWhY/pU6pXpmeHg4AMDW1lbpZyIiIiqjajZFpS3GxsYwNjbWuJ9SJT4NGzYs9mciIiKiqkDjs7qIiIioDHhWF4BXy2gMDAxw9OhRxTIaiaTk10YikeDOnTvlHlejxOfq1avYt28f7t69i4yMDJibm6Nly5bw9fWFu7u7Jl0TERFVS7xy8yvt2rUDAJiamir9XNnKnfj85z//wc6dO/Hm2ui7d+9i3759GDlyJL766iuNAyQiIqLqZ/v27cX+XFnKlfhs374dO3bsgIODAyZPngwPDw9YW1sjJSUFERERWL9+PXbs2IFmzZph5MiRFR0zERFR1cWKj6jKdQHDXbt2wcbGBnv37oWvry8aNmwIY2NjNGzYEIMGDUJYWBjq16+PnTt3VnS8REREROVWropPfHw8hg0bhjp16qhtt7S0hI+PD/bs2aNRcERERFQ9BQUFlet5EokEU6ZMKfe45Up8LC0tYWRkVOw+RkZGsLKyKldQMTExWL16Ne7du4d69eph8ODBGDhwoMp+p0+fxrfffsvrChERUZXBxc2vqEt8Xj+r6/U1xPLtgiCIk/h4e3vjzJkzCAgIUJsAyWQynDlzBt7e3mXuOyUlBX5+fkhPTwcAPHr0CFevXsWZM2ewbNky1KxZU7FvdnY2EhMTy3MIRERE4uDp7ACA4OBglW1bt27FuXPn0L9/f3h4eKB+/fr4999/ERERgSNHjqBbt24YM2aMRuOWK/EJCAjArVu3MG7cOAQEBMDV1RUSiQSCIODatWtYsWIF6tSpg5kzZ5a57w0bNiAzMxOLFy9Gnz59kJycjFWrVuHkyZN48eIFNmzYoJT8EBERUdXj4eGh9POBAwdw8eJF7N69G61atVJq8/X1xciRIzFq1Cj07NlTo3HLlfgMGDAAeXl5SElJwciRI1GjRg1YWVkhLS0NBQUFAABra2sMGDBA6XkSiQSnT58utu9Lly5h4MCBipuQmZmZYfXq1fjxxx/xww8/YPLkyVi/fn2FXLaaiIhI6zjVpdbWrVvRu3dvlaRHztnZGb1798a2bdvULn8prXKd1SUIAgwNDWFvbw97e3vY2NjAyMgINjY2im2GhoYQBEHpUVhYWGLfiYmJaNOmjcr2Tz75BPPmzcMff/yBadOmIS8vrzyhExERkQ6KiYmBjY1NsfvY2NggJkazG8mWq+Jz5swZjQYtTu3atZGbm6u2bcyYMSgsLMTSpUsxffr0cq0hIiIiEhUrPmqZmZnh2rVrxe7z559/olatWhqNU66KT2VycHDAjRs3imyXrys6c+YMVqxYob3AiIiIKoBEqLhHddKtWzdcvXoVS5cuRWZmplJbZmYmAgMDce3aNXTv3l2jcSrkJqWZmZmKe3WZmZlp1FenTp2wZcsWZGZmFtnXpEmTUFhYiB9++KFUNzQjIiIi3TZr1ixERkZi69atCAsLQ4sWLVCvXj08e/YMd+/eRWZmJhwcHBAQEKDROOVOfPLz8/Hzzz8jLCwMCQkJiu2NGjXC0KFDMX78eBgalr37Dz74ADKZDLGxsUUucAJerfkxNzfHX3/9Va74iYiIRFHNKjUVpV69eggLC8OKFStw5MgRXLlyRdFmamqKYcOGYebMmeW+RqCcRHjzLqOlIJPJMHHiRFy5cgUSiQR2dnaKe3UlJSVBEAS4u7tj8+bNVebsq6DoHmKHUOUMr3Nf7BCqJL9GHcUOocr5Of6C2CFUSfUNTMQOocoxtdds4WxpNP++4pZpPJytWfVDV+Xn5+PRo0eK2aS33nqrXMUUdcrVy9atWxEZGYn33nsPc+fORdOmTRVtcXFxCAwMxNmzZ7F161ZMmjSpQgIlIiIi/WBoaAipVFopfZdrcfPhw4fxzjvvYN26dUpJDwA0btwYQUFBePvtt3H48OGKiJGIiKja4OJmcZUr8YmLi0PXrl1hYKD+6QYGBujatSvi4uI0Co6IiKjaESQV96AyK1fiY2RkhOzs7GL3ycnJqbD5OCIiIqKKUK7Ex9HRESdOnEBqaqra9tTUVJw4cQJOTk4aBUdERFTtCBX4oDIrdeJz4MABREdHAwBGjhyJ1NRUDBkyBGFhYYiPj0dubi7i4+Oxd+9eDBs2DKmpqRg5cmSlBU5ERFQVcY2PuEo9FzV37lxMnToVTk5O6NOnD6Kjo7Fx40YsXLhQZV9BEDBx4kT06dOnQoMlIiIi0kS5F+EEBASgR48e+OWXX3Dnzh3FlZZbtmyJwYMHw9XVtSLjJCIiqh5YqSmV9PR0ZGdnw97evkL71Wj1cZs2bdTeSZ2IiIjU4xRV0bKysrBmzRocPnwYqampkEgkuHPnDgDg5s2bCAoKwowZM4q9s0NJdO4mpURERKR/MjIy4Ofnh61bt8LGxgbNmzfH6zeXkEqluHr1Ko4cOaLROGWq+GRkZCAxMbFMAzRo0KBM+xMREVVrrPiotX79ejx48ACBgYEYOHAggoKCsHbtWkW7qakpPDw8cPnyZY3GKVPiExwcjODg4FLv/3qJioiIiMDEpwinTp2Cp6cnBg4cWOQ+DRo0QFRUlEbjlCnxMTMzg7m5uUYDEhEREb0pKSkJvXr1KnafWrVqISMjQ6NxypT4jBkzBlOnTtVoQCIiIn3Gxc3q1a5du8gLI8slJCTAyspKo3G4uJmIiIhE5+zsjLNnzyIzM1Nt+9OnT3Hu3Dm0bdtWo3GY+BAREZHoRo8ejefPn2PSpEl4+PChUtvDhw8xffp0vHz5Ev7+/hqNw7uIEhERaROnutTq0qULpk6diqCgIPTr109xo/P27dvjxYsXEAQBs2fPhpubm0bjMPEhIiLSIq7xKdrUqVPh7u6O7du34+bNm3j+/DkkEgm6deuGMWPGoGPHjhqPUerER36DUiIiIqLK0qFDB3To0KHS+mfFh4iISJtY8REVEx8iIiJtYuJTopycHLx48QIFBQVq2zW5KwQTHyIiIj118uRJbNq0Cffv34eRkRHatm2LgIAASKXSMvd19+5dDBkyBPn5+fjuu+8wYMCAMvdx4MABbNq0SeWsrtdpelcIJj5ERERapCuLm8PCwvDVV19BKpVi9uzZePnyJUJCQuDn54fQ0FA4OjqWuq/8/HzMnz8fxsbGyM/PL1c8+/btw5dffokaNWrA3d0ddnZ2ijO7KhITHyIiIj2Tnp6OwMBA2NnZITQ0FGZmZgCA3r17o2/fvliyZEmZ7s35888/459//sFHH32EVatWlSumn3/+GRYWFti5cyeaN29erj5KgxcwJCIi0iahAh/lFB4ejszMTAwdOlSR9ACv1s74+PggIiICT548KVVfMTExCAoKwsyZM2FnZ1fumGJjY+Hj41OpSQ/AxIeIiEirJELFPcrr5s2bAABXV1eVNvm20twFXRAEzJ8/H05OThg5cmT5AwJgYWEBY2NjjfooDU51ERERVVFeXl7FtoeHh6vdnpycDABqKzTybUlJSSWOv3PnTty6dQt79+6FgYFmtZTu3bsjMjISgiBAIpFo1FdxWPEhIiLSJh2Y6srJyQEAtRUW+bbc3Nxi+0hMTMTy5csxfvz4Mi2ELkpAQABkMhkWLVqErKwsjfsrCis+RERE2lSBZ3UVVdEpiampKQBAJpOptMm3mZiYFNvHwoULUb9+fUyZMqVcMbxp+vTpMDU1RVhYGA4fPoymTZvC3NxcZT+JRIJt27aVexwmPkRERHrG1tYWwKvprDcXE8unuIpbqHzq1CmcP38eixcvVpoSe/bsmeK/sbGxsLGxUSRZJYmMjFT8f05ODu7evat2P02nwZj4/B8H41SxQ6hy0gvVX1GTivdz/AWxQ6hyxjt4ih1ClbQq9qLYIVQ5LbUwhi5cx8fFxQW7du3C9evX0blzZ6W2GzduAACcnZ2LfP7jx48BvKr6qLN06VIsXboUP/30E7p27VqqmLR1T1AmPkRERNqkA4mPt7c3lixZgrCwMIwdO1ZxSntiYiKOHz8ODw8P2NvbA3hVfUlMTIS5uTlsbGwAvFqIrK4iFBkZiR07dsDf3x/u7u5o2VIbqWTZMPEhIiLSMxYWFpgzZw4WLVqE4cOH48MPP4RMJkNISAgAYP78+Yp9b926hdGjR8PX1xeBgYEAgCZNmqBJkyYq/WZnZwN4VS16//33tXAkZcfEh4iISJt0oOIDAH5+frC0tMTmzZuxbNkyGBkZwd3dHTNmzICTk1Olj3/lyhUAr6bdatasqfi5NNq1a1fucSWCIOjIr0BcBx+1ETuEKsfZOFnsEKoko8q7PEW1xTU+5cM1PmXX0uFxpY/Res7KCuvrr+9mVlhf2ubk5ASJRIJjx46hWbNmip9Lo6iFz6XBig8RERFp3ZQpUyCRSGBlZaX0c2Vj4kNERKRNnGcBAEybNq3YnysLEx8iIiIt0oXT2fUZEx8iIiISXUFBAWQymcoFDy9duoTw8HCYmppi2LBhcHBw0GgcJj5ERETaxIqPWkuXLkVoaCguXryouFXF0aNHMXv2bMjPwwoLC8P+/fsV1xgqD96klIiISJt04Caluujq1ato37690v25goKCUKdOHSxduhSff/45MjIysGXLFo3GYcWHiIiIRPfkyRO4uroqfo6Pj0dMTAymTJmCAQMGAHh17Z/z589rNA4rPkRERFokqcBHdZKZmam4dQYA/Pnnn5BIJOjSpYti2zvvvKN0U9TyYMWHiIhIm6rZFFVFsba2RkJCguLnS5cuwcTEBK1atVJsy87OhqGhZqkLEx8iIiISXZs2bXDmzBmcPXsWNWvWxIkTJ9ChQwcYGRkp9klISICtra1G4zDxISIi0iJex0e9jz/+GOHh4Zg8eTIAwMDAAJ9++qmi/eXLl7h69Sp8fHw0GoeJDxERkTYx8VHL0dERe/bswYEDBwAAvXv3houLi6L9zp076NChA/r166fROEx8iIiISCc4Ojriiy++UNvm6uqKtWvXajwGEx8iIiJtYsWnVDIzM5GRkQFzc3Ols700xcSHiIhIi7jGp2j5+fn4+eefERYWpnSGV6NGjTB06FCMHz+eZ3URERFR1SeTyTBx4kRcuXIFEokE9vb2sLa2RkpKCh4/foyVK1fi/Pnz2Lx5M4yNjcs9DhMfIiIibWLFR62tW7ciMjIS7733HubOnYumTZsq2uLi4hAYGIizZ89i69atmDRpUrnH4ZWbiYiISHSHDx/GO++8g3Xr1iklPQDQuHFjBAUF4e2338bhw4c1GoeJDxERkRZJhIp7VCdxcXHo2rUrDAzUpyYGBgbo2rUr4uLiNBqHU11ERETaVM0SlopiZGSE7OzsYvfJycnReHEzKz5EREQkOkdHR5w4cQKpqalq21NTU3HixAk4OTlpNA4THyIiIi3iVJd6I0eORGpqKoYMGYKwsDDEx8cjNzcX8fHx2Lt3L4YNG4bU1FSMHDlSo3E41UVERKRN1SxhqSh9+vRBdHQ0Nm7ciIULF6q0C4KAiRMnok+fPhqNw8SHiIiIdEJAQAB69OiBX375BXfu3EFmZibMzMzQsmVLDB48GK6urhqPwcSHiIhIm1jxKVabNm3Qpk2bSuufiQ8REZEWVbe1OVUNFzcTERGR6H799VeMHj0aycnJatuTk5MxZswYnDx5UqNxmPgQERFpk1CBj2rkl19+QUZGBmxtbdW229raIiMjA2FhYRqNw8SHiIhIiySCUGGP6uTevXto3bp1sfs4Ozvj3r17Go3DxIeIiIhEl56ejrp16xa7j6WlJdLS0jQah4ubiYiItKl6FWoqjJWVFWJjY4vdJzY2FnXq1NFonCpX8UlMTER0dDRkMpnYoRAREZUZr9ysnpubG86cOYOHDx+qbX/48CHCw8PRtm1bjcbRycTnjz/+wNixYzFo0CAEBQWhsLAQOTk5mDRpEry8vODr64suXbrgyJEjYodKREREFWD8+PEoKCjAiBEjEBwcjJiYGGRnZyMmJgbbtm3DiBEjUFhYiAkTJmg0js5Ndd25cwcff/wxBEFAzZo1sXbtWshkMmRlZeHBgwcYMWIEcnNzcfr0aXzxxRdo0qQJnJ2dxQ6biIiodKpZpaaiuLi4YNGiRVi8eDG+/fZbfPvtt0rtNWrUwNdff413331Xo3F0LvHZtGkTrK2tsWfPHtStWxezZs3Crl270KhRIxw8eFAxt/fpp59i4MCB2L59O7777juRoyYiIiqd6jZFVZGGDRuGtm3bYufOnbh58yYyMjJgbm6ONm3aYPjw4WjevLnGY+hc4nPz5k34+vrC2toawKvS1/HjxzFgwAClBU2NGjXCwIEDcfbsWbFCJSIiogrWvHlzLFiwoNL617k1PikpKWjYsKHi5wYNGgAAmjZtqrLvW2+9hZSUFG2FRkREpDlewFBUOlfxMTU1RU5OjuLnGjVqAACMjY1V9hUEQdFORERUFXCqS1w6l/jY2dnh8ePHip/Nzc0RHByMFi1aqOz7+PFj1KtXT5vhERERURWmc4lPy5YtcePGDcXPhoaG8PDwULvvuXPnSry8NRERkU5hxUdUOpf4zJkzBxkZGSXu9+zZM3Tq1Andu3fXQlREREQVg1Nd4tK5xMfKygpWVlYl7levXj18+eWXWoiIiIiIqgudS3yIiIiqtWp2V/WqhokPERGRFnGqS1w6dx0fIiIiosrCig8REZE2seIjKlZ8iIiISG+w4kNERKRFkkKxI9BvTHyIiIi0iVNdouJUFxEREekNVnyIiIi0iKezi4uJDxERkTbxAoai4lQXERER6Q1WfIiIiLSIU13iYuJDRESkTUx8RMWpLiIiItIbrPgQERFpEae6xMXEh4iISJt4VpeoONVFREREeoMVHyIiIi3iVJe4mPgQERFpExMfUXGqi4iIiPQGKz5ERERaxKkucTHxISIi0qZCZj5i4lQXERER6Q1WfIiIiLSJBR9RMfEhIiLSIl1a43Py5Els2rQJ9+/fh5GREdq2bYuAgABIpdISn3vmzBmEh4fjxo0bSExMRM2aNdGkSRMMHToUAwcOhKGhbqYYnOoiIiLSQ2FhYZg2bRpycnIwe/ZsfPLJJ7h37x78/Pxw7969Ep+/YMECREREoEuXLvjyyy8xadIk5OfnY/78+Zg8eTIEHb1CtW6mY0RERNWVDiQE6enpCAwMhJ2dHUJDQ2FmZgYA6N27N/r27YslS5YgODi42D6+//57dOjQARKJRLFtzJgx8Pf3x++//45z586hW7dulXoc5cGKDxERkRZJhIp7lFd4eDgyMzMxdOhQRdIDAA0aNICPjw8iIiLw5MmTYvvo2LGjUtIDADVq1MD7778PAKWqGomBiQ8REZGeuXnzJgDA1dVVpU2+LSoqqlx9JycnAwDq1atXzugqF6e6iIiItKkCZ7q8vLyKbQ8PD1e7XZ6c2NnZqbTJtyUlJZU5nqSkJOzevRsWFhYlxiYWJj5ERERaJNGBNT45OTkAAGNjY5U2+bbc3Nwy9ZmVlYXJkycjMzMTa9asgaWlpcZxVgYmPv/n0UsbsUOocvrXyhY7hCrppZAndghVzqrYi2KHUCVNb9JJ7BCqnFOFYkdQNkVVdEpiamoKAJDJZCpt8m0mJial7i8rKwuTJk3CnTt3sGDBAvTs2bNccWkD1/gQERFpU2EFPsrJ1tYWgPrpLPk2ddNg6mRmZmLixIn4888/8fXXX2PkyJHlD0wLmPgQERHpGRcXFwDA9evXVdpu3LgBAHB2di6xn4yMDEyYMAE3btzAf//7X/j5+VVonJWBiQ8REZEWSQShwh7l5e3tjdq1ayMsLAyZmZmK7YmJiTh+/Dg8PDxgb28P4NV6oIcPH+Lp06dKfWRkZGD8+PGIiorCt99+iyFDhpQ7Hm3iGh8iIiJtEn9tMywsLDBnzhwsWrQIw4cPx4cffgiZTIaQkBAAwPz58xX73rp1C6NHj4avry8CAwMV28eOHYu//voLXl5ekEgkOHjwoNIYjo6OcHJy0s4BlQETHyIiIj3k5+cHS0tLbN68GcuWLYORkRHc3d0xY8aMUiUsf/31F4BXC6zVLbKeOnUqEx8iIiK9pwOns8u9//77iistF6V9+/Zqr8Ksq1dmLgkTHyIiIi3Spbuz6yMubiYiIiK9wYoPERGRNunQVJc+YuJDRESkRZIqdnXo6oZTXURERKQ3WPEhIiLSJk51iYqJDxERkTYx7xEVp7qIiIhIb7DiQ0REpEWa3GOLNMfEh4iISJuY+IiKU11ERESkN1jxISIi0iZex0dUTHyIiIi0iGt8xMWpLiIiItIbrPgQERFpEys+omLiQ0REpE1MfETFqS4iIiLSG6z4EBERaRPP6hIVEx8iIiIt4lld4uJUFxEREekNVnyIiIi0iRUfUTHxISIi0iYmPqLiVBcRERHpDVZ8iIiItIkVH1Gx4kNERER6gxUfIiIibeJ1fETFxIeIiEiLeB0fcXGqi4iIiPRGlUp8nj17hlmzZuHWrVtih0JERFQ+glBxDyqzKpX4ZGVl4ejRo0hOThY7FCIiovIpFCruQWWmU2t8xo8fX2x7bm4uACAoKAihoaGQSCTYvHmzNkIjIiKiakCnEp+LFy9CIpFAKKZ8J5FIcO/ePcX/ExERVSmcohKVTiU+Li4u+PvvvzFz5kz4+/urtMfGxsLHxwerV69Gr169RIiQiIhIQ0x8RKVTa3x2796NadOmYcWKFfjwww9x//59pXZWeIiIiEgTOpX4SCQSjBs3DocOHYKJiQkGDRqElStXQiaTiR0aERFRxeBZXaLSqcRHzsHBAdu2bcPChQuxc+dO9O/fH5cvXxY7LCIiIs3xrC5R6WTiIzds2DAcOXIEb731FsaNG4fFixdzuouIiIjKTacTHwCwtbXF+vXr8f333+POnTvFnvFFRESk84TCintQmenUWV3F6du3L3r27ImXL1/C1NRU7HCIiIjKh/+AF1WVSXwAwNjYGMbGxmKHQURERFVUlUp8iIiIqjwuShYVEx8iIiJt4lSXqHR+cTMRERFRRWHFh4iISJtY8REVEx8iIiJtYuIjKk51ERERkd5gxYeIiEibCnnhQTEx8SEiItImTnWJilNdREREpDdY8SEiItImVnxExcSHiIhIm3jlZlFxqouIiIj0Bis+REREWiQIPKtLTKz4EBERkd5gxYeIiEibuMZHVEx8iIiItIlndYmKU11ERESkN1jxISIi0ibeskJUTHyIiIi0iVNdouJUFxEREekNVnyIiIi0SOBUl6iY+BAREWkTp7pExakuIiIi0hus+BAREWkTL2AoKiY+RERE2sR7dYmKU11ERESkN1jxISIi0iJBh6a6Tp48iU2bNuH+/fswMjJC27ZtERAQAKlUWqrn5+TkYO3atTh27BiePn0KGxsb9O3bF5MnT4apqWklR18+THyIiIi0SUemusLCwvDVV19BKpVi9uzZePnyJUJCQuDn54fQ0FA4OjoW+/yCggJMmjQJkZGRGDBgANq1a4fo6Ghs3rwZt27dwpYtW2BgoHsTS0x8iIiI9Ex6ejoCAwNhZ2eH0NBQmJmZAQB69+6Nvn37YsmSJQgODi62j/379yMyMhL+/v746quvFNsbNmyIpUuX4tChQxg4cGBlHka56F4qRkREVI0JhUKFPcorPDwcmZmZGDp0qCLpAYAGDRrAx8cHERERePLkSbF9HDx4EAAwbtw4pe0jRoyAiYkJDhw4UO74KhMrPv9nZouTYodAekI3Z711W0uxA6iiTunGjAq9SQemum7evAkAcHV1VWlzdXXF/v37ERUVBXt7e7XPFwQBUVFRsLGxQcOGDZXaTExM0KJFC0RFRVV84BWAiQ8REVEV5eXlVWx7eHi42u3JyckAADs7O5U2+bakpKQi+33+/DlycnLwzjvvqG23tbXF9evXkZmZqVRR0gVMfIiIiLToVGFYhfVVUuJTlJycHACAsbGxSpt8W25ubpHPl7epez4A1KxZUzEOEx8iIiKqEEVVdEoiP9VcJpOptMm3mZiYFPl8eZu65wPAy5cvlcbRJVzcTEREpGdsbW0BqJ/Okm9TNw0mZ2lpCVNT0yKnw5KTk2FmZqZz1R6AiQ8REZHecXFxAQBcv35dpe3GjRsAAGdn5yKfL5FI0Lp1azx9+hSPHz9WasvNzcXdu3eLfb6YmPgQERHpGW9vb9SuXRthYWHIzMxUbE9MTMTx48fh4eGhOKMrJycHDx8+xNOnT5X6GDBgAABgy5YtSttDQ0ORm5uraNc1EkEQdOfa2URERKQVu3btwqJFiyCVSvHhhx9CJpMhJCQEaWlpCA0NhZOTEwAgIiICo0ePhq+vLwIDAxXPLygowOjRo3H16lUMHDgQ7u7uuHfvHnbu3Im2bdti69atqFGjhliHVyQubiYiItJDfn5+sLS0xObNm7Fs2TIYGRnB3d0dM2bMUCQ9xalRowY2btyItWvX4tdff8XRo0dhbW2NcePGYcqUKTqZ9ACs+BAREZEe4RofIiIi0htMfIiIiEhvMPEhIiIivcHEh4iIiPQGEx8iIiLSGzydXUedPHkSmzZtwv3792FkZIS2bdsiICAAUqlU7NB00saNG3Hnzh3cuXMHcXFxMDAwwJ07d8QOS6f9888/OHz4MP744w/Ex8cjKysLDRo0QKdOnTBp0iTY2NiIHaJOSk1NxbJly3D79m0kJycjOzsb1tbWePfddzFx4kS0atVK7BCrhMLCQvj5+eHmzZvo2LEjtm7dKnZIpCeY+OigsLAwfPXVV5BKpZg9ezZevnyJkJAQ+Pn5ITQ0FI6OjmKHqHOWL1+OOnXqoEWLFsjOzkZqaqrYIem8X375BTt27ED37t3Ru3dvmJiY4MaNG9i5cycOHTqE0NBQNG/eXOwwdU5GRgZiYmLQqVMnNGjQAKampnj8+DH279+PYcOG4ccff0SXLl3EDlPnbdu2DQ8ePBA7DNJDvI6PjklPT0ePHj1gZmaGo0ePKm7wlpiYiL59+8LZ2RnBwcEiR6l74uLi0LhxYwCAv78//vzzT1Z8ShAVFYUmTZqgTp06Stt3796NhQsX4v3338eqVatEiq7qSU5ORvfu3eHu7s7PaAni4+PRv39/zJw5E9988w0rPqRVXOOjY8LDw5GZmYmhQ4cq3dW2QYMG8PHxQUREBJ48eSJihLpJnvRQ6Tk7O6skPQDQt29fAMC9e/e0HVKVVr9+fdSsWRMZGRlih6LzvvrqK7z99tvw9/cXOxTSQ0x8dMzNmzcBAK6uript8m1RUVFajYn0S3JyMoBXf8ipaHl5eUhNTUVKSgpu3bqFWbNmITs7G++9957Yoem0PXv24OrVq/jvf/8LAwP+CSLt4xofHSP/o2NnZ6fSJt+WlJSk1ZhIv8intwYNGiRyJLrt2rVrGD16tOJnc3NzfPTRR5gyZYqIUem25ORkfPfddxg3blyp7gVFVBmY+OiYnJwcAICxsbFKm3xbbm6uVmMi/fHjjz/ixIkT8Pb2hq+vr9jh6DQnJyds2bIFMpkM//zzDw4ePIisrCzIZDIYGvKrVZ2vv/4aVlZWmDp1qtihkB7jp1PHmJqaAgBkMplKm3ybiYmJVmMi/bBt2zasXLkSHh4e+P777yGRSMQOSadZWFigU6dOip99fX0xYMAAxMfHY9OmTSJGppuOHj2KM2fOYMuWLfwOI1FxglXH2NraAlA/nSXfpm4ajEgTW7ZsUZxds3HjRkUCTqVnYWGBHj164Pz580hISBA7HJ0ik8nw3//+F56enmjYsCFiY2MVD+BVFTs2Nhb//vuvyJGSPmDFR8e4uLhg165duH79Ojp37qzUduPGDQCvzsYhqigbN27E8uXL0aVLF6xduxY1a9YUO6QqSz4N/eLFC5Ej0S25ublITU3FhQsX0KtXL5X269evo1evXujTpw9WrlwpQoSkT5j46Bhvb28sWbIEYWFhGDt2rNJ1fI4fPw4PDw/Y29uLHCVVFz/++CNWrlyJ7t27Y/Xq1WrXlpGyf//9V+0ZbwkJCQgPD4e5uTkv/PgGU1PTIq8JNX36dEilUkyZMoXfbaQVTHx0jIWFBebMmYNFixZh+PDh+PDDDyGTyRASEgIAmD9/vsgR6qYDBw4gMTERAPD48WMIgoB169Yp2idPnixWaDprx44dWLlyJerXr4+ePXvi119/VWqvXbs2vL29RYpOd23YsAEXL15E165d0ahRIwDAo0ePcODAAWRnZyMwMJBVszcYGRnh/fffL7K9Xr16xbYTVSReuVlHHT9+HJs3b1bcq8vd3R0zZszgKaBF8Pf3R2RkZJHtvBifqrlz52L//v1Ftjds2BBnzpzRYkRVw8WLF7Fr1y789ddfSE1NRX5+PmxsbODq6ooxY8bAxcVF7BCrFEdHR165mbSKiQ8RERHpDZ7VRURERHqDiQ8RERHpDSY+REREpDeY+BAREZHeYOJDREREeoOJDxEREekNJj5ERESkN5j4EBERkd5g4kNERER6g4kPEZVJQkICHB0dMXfuXLFDISIqM96klKgKcHR0LNP+3377LQYNGlRJ0RARVV1MfIiqgKlTp6ps27ZtGzIyMjB69GjUqVNHqa1FixaVFoutrS2OHTsGc3PzShuDiKiy8CalRFVUjx498PjxY4SHh6NRo0Zih0NEVCWw4kNUDR07dgw7duxAdHQ08vLy0KRJE/Tr1w/jxo2DsbGx0r49evQAABw8eBArV67EqVOn8Pz5czg4OMDPzw/+/v6QSCSK/RMSEuDl5QVfX18EBgYq9ZWTk4Pt27fj+PHjiImJAQDY2dmhc+fO+OSTT1C/fv1KPnIiouIx8SGqZlasWIENGzbAysoK/fr1Q61atXD+/HmsWLECFy5cwObNm1WSH5lMhrFjxyIjIwN9+/ZFXl4eTpw4gSVLliAmJgaLFi0qcdz09HSMHj0a0dHRaNasGQYPHgwjIyPEx8dj79696NmzJxMfIhIdEx+iauT69evYsGED7O3tERYWBmtrawDArFmzMHXqVJw9exY///wzPvnkE6XnpaSkwMHBAUeOHFEkRdOmTcOQIUOwc+dO9OnTB+3atSt27MWLFyM6Ohp+fn5YtGgRDAz+d9JoVlYWCgsLK/hoiYjKjqezE1Uje/fuBQB8+umniqQHAAwNDfHFF1/AwMAAYWFhap87a9YspUqQpaUlJk+eDADYt29fseM+e/YMx44dg7W1tWKc19WuXZuLoYlIJzDxIapG7ty5AwDo0KGDSluzZs1gZ2eHhIQEZGRkKLUZGhrC1dVV5TkeHh5K/RYlKioKhYWFaNeuHWrVqlXe8ImIKh0TH6JqRJ7QvF7teZ18+4sXL5S2W1lZoUaNGkXu/2ai9CZ5f7a2tmULmIhIy5j4EFUj8umkf//9V217SkqK0n5yaWlpKCgoKPX+b5JfRyg5OblsARMRaRkTH6JqRH7hwoiICJW22NhYJCUloVGjRioXPMzPz8f169dVnhMZGQkAaNmyZbHjuri4wMDAAFeuXEF2dnZ5wyciqnRMfIiqkcGDBwMA1q9fj9TUVMX2goICLF26FIWFhRgyZIja5y5fvhwymUzx8/Pnz7F+/XoAKPH2F3Xr1kWfPn2QkpKiGOd1WVlZJU6XERFpA09nJ6pG3NzcMHHiRGzatAn9+vWDj48PTE1Ncf78edy/fx9t27bFhAkTVJ5nbW0NmUyGfv36oUePHsjPz8fx48eRkpKCESNGlHgqOwAsXLgQDx48wK5duxAZGQlPT08YGRkhISEBFy5cwPr169G+ffvKOGwiolJj4kNUzXz++edo2bIlQkJCcODAAeTn56Nx48aYMWMGxo8fr3LxQgAwNjbG1q1bsWLFChw9ehRpaWlwcHDApEmT4O/vX6pxLSwssGvXLmzbtg3Hjh3Dnj17YGBgAHt7ewwePBhvv/12RR8qEVGZ8V5dRHpOfsuKM2fOiBwJEVHl4xofIiIi0htMfIiIiEhvMPEhIiIivcE1PkRERKQ3WPEhIiIivcHEh4iIiPQGEx8iIiLSG0x8iIiISG8w8SEiIiK9wcSHiIiI9AYTHyIiItIbTHyIiIhIb/x/z7RuYdrUJCMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: spam_topic_distance_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "Hn = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-12)\n",
    "S  = cosine_similarity(Hn)\n",
    "D  = 1.0 - S\n",
    "\n",
    "tri = D[np.triu_indices_from(D, k=1)]\n",
    "print(\"\\n=== TOPIC HETEROGENEITY (cosine distance) ===\")\n",
    "print(f\"mean: {tri.mean():.4f} | median: {np.median(tri):.4f} | min: {tri.min():.4f} | max: {tri.max():.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(D, cmap=\"viridis\", annot=False, square=True, cbar_kws={'label': 'cosine distance'})\n",
    "plt.title(\"Topic semantic distance (lower=more similar)\")\n",
    "plt.xlabel(\"Topic\"); plt.ylabel(\"Topic\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "dist_df = pd.DataFrame(D, index=[f\"T{t:02d}\" for t in range(BEST_K)],\n",
    "                          columns=[f\"T{t:02d}\" for t in range(BEST_K)])\n",
    "dist_df.to_csv(\"spam_topic_distance_matrix.csv\")\n",
    "print(\"Saved: spam_topic_distance_matrix.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc05e5b",
   "metadata": {},
   "source": [
    "## Step 4.5 — Saving Topic Modeling Artifacts\n",
    "\n",
    "**Purpose:**\n",
    "This step consolidates all **topic modeling results and parameters** into reusable artifacts, so the analysis can be reloaded later without retraining.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Save fitted models**\n",
    "\n",
    "   * `topic_vectorizer.joblib`: TF-IDF vectorizer trained on SPAM corpus.\n",
    "   * `topic_nmf_model.joblib`: Final NMF topic model with `K = BEST_K`.\n",
    "\n",
    "2. **Top terms per topic**\n",
    "\n",
    "   * Extracts the top 15 terms for each topic.\n",
    "   * Stored in JSON for interpretability.\n",
    "\n",
    "3. **Topic statistics**\n",
    "\n",
    "   * Distribution of documents across topics.\n",
    "   * Distance stats (mean, median, min, max cosine distance between topics).\n",
    "\n",
    "4. **K evaluation (optional)**\n",
    "\n",
    "   * If available, the K evaluation table (`topic_k_eval.csv`) is also saved.\n",
    "\n",
    "5. **Threshold info**\n",
    "\n",
    "   * Records which classification threshold was used to select SPAM messages for topic modeling.\n",
    "\n",
    "6. **Stopwords info**\n",
    "\n",
    "   * Saves reference to the `topic_stopwords.json` file, with a count of stopwords applied.\n",
    "\n",
    "7. **Final JSON export**\n",
    "\n",
    "   * `topic_model_artifacts.json` contains:\n",
    "\n",
    "     * Model metadata (K, vocab size, n\\_docs).\n",
    "     * Vectorizer parameters.\n",
    "     * Topic counts and top terms.\n",
    "     * Distance statistics.\n",
    "     * Stopwords file reference.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* `topic_vectorizer.joblib`\n",
    "* `topic_nmf_model.joblib`\n",
    "* `topic_k_eval.csv` (if available)\n",
    "* `topic_model_artifacts.json`\n",
    "\n",
    "This ensures the **entire topic modeling pipeline is reproducible**, portable, and interpretable.\n",
    "\n",
    "Vuoi che ti prepari anche una **cella markdown di “Summary finale Step 4”** che riassuma tutto il blocco di Topic Modeling (4 → 4.5)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0e81b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAVING TOPIC MODELING ARTIFACTS ===\n",
      "Saved: topic_vectorizer.joblib, topic_nmf_model.joblib\n",
      "Saved: topic_k_eval.csv\n",
      "Saved: topic_model_artifacts.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SAVING TOPIC MODELING ARTIFACTS ===\")\n",
    "\n",
    "# Sanity checks: we expect these from 6A–6D\n",
    "required = ['topic_vectorizer', 'nmf_final', 'BEST_K', 'X_topic', 'H', 'W', 'spam_df']\n",
    "for name in required:\n",
    "    assert name in globals(), f\"Missing '{name}'. Please run Cells 6A–6D first.\"\n",
    "\n",
    "# 1) Save the fitted vectorizer and NMF model\n",
    "joblib.dump(topic_vectorizer, \"topic_vectorizer.joblib\")\n",
    "joblib.dump(nmf_final, \"topic_nmf_model.joblib\")\n",
    "print(\"Saved: topic_vectorizer.joblib, topic_nmf_model.joblib\")\n",
    "\n",
    "# 2) Build top-terms per topic\n",
    "def top_terms_by_topic(H, feat_names, topn=15):\n",
    "    out = {}\n",
    "    for t in range(H.shape[0]):\n",
    "        top_idx = np.argsort(-H[t])[:topn]\n",
    "        out[f\"T{t:02d}\"] = [str(feat_names[i]) for i in top_idx]\n",
    "    return out\n",
    "\n",
    "feat_names = np.array(topic_vectorizer.get_feature_names_out())\n",
    "top_terms = top_terms_by_topic(H, feat_names, topn=15)\n",
    "\n",
    "# 3) Topic counts and basic distance stats (from 6D if available)\n",
    "topic_labels = W.argmax(axis=1)\n",
    "topic_counts = pd.Series(topic_labels).value_counts().sort_index().to_dict()\n",
    "\n",
    "distance_stats = {}\n",
    "if 'D' in globals():\n",
    "    tri = D[np.triu_indices_from(D, k=1)]\n",
    "    distance_stats = {\n",
    "        \"mean\": float(tri.mean()),\n",
    "        \"median\": float(np.median(tri)),\n",
    "        \"min\": float(tri.min()),\n",
    "        \"max\": float(tri.max())\n",
    "    }\n",
    "\n",
    "# 4) K evaluation table (if you ran 6B). Save CSV too.\n",
    "if 'k_eval' in globals() and isinstance(k_eval, pd.DataFrame):\n",
    "    k_eval.to_csv(\"topic_k_eval.csv\", index=False)\n",
    "    print(\"Saved: topic_k_eval.csv\")\n",
    "\n",
    "# 5) Threshold used for SPAM selection (read from artifacts JSON if present)\n",
    "thr_used = None\n",
    "if os.path.exists(\"spam_baseline_artifacts.json\"):\n",
    "    with open(\"spam_baseline_artifacts.json\", \"r\") as f:\n",
    "        base_art = json.load(f)\n",
    "    thr_used = base_art.get(\"thresholds\", {}).get(\"high_recall_global\") or \\\n",
    "               base_art.get(\"thresholds\", {}).get(\"f1_global\")\n",
    "\n",
    "# 6) Stopwords file (if present)\n",
    "stopwords_file = \"topic_stopwords.json\" if os.path.exists(\"topic_stopwords.json\") else None\n",
    "stopwords_count = None\n",
    "if stopwords_file:\n",
    "    with open(stopwords_file, \"r\") as f:\n",
    "        swj = json.load(f)\n",
    "    stopwords_count = len(swj.get(\"final\", []))\n",
    "\n",
    "# 7) Build a compact JSON with everything needed to reload the topics\n",
    "topic_artifacts = {\n",
    "    \"version\": 1,\n",
    "    \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    \"k\": int(BEST_K),\n",
    "    \"vocab_size\": int(len(feat_names)),\n",
    "    \"n_docs_spam\": int(len(spam_df)),\n",
    "    \"selection_threshold\": float(thr_used) if thr_used is not None else None,\n",
    "    \"vectorizer_params\": {k: v for k, v in topic_vectorizer.get_params().items()\n",
    "                          if k in [\"analyzer\",\"ngram_range\",\"min_df\",\"max_df\",\"strip_accents\",\"stop_words\"]},\n",
    "    \"stopwords_file\": stopwords_file,\n",
    "    \"stopwords_count\": stopwords_count,\n",
    "    \"topic_counts\": {str(k): int(v) for k, v in topic_counts.items()},\n",
    "    \"top_terms\": top_terms,\n",
    "    \"distance_stats\": distance_stats\n",
    "}\n",
    "\n",
    "with open(\"topic_model_artifacts.json\", \"w\") as f:\n",
    "    json.dump(topic_artifacts, f, indent=2)\n",
    "\n",
    "print(\"Saved: topic_model_artifacts.json\")\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893146d4",
   "metadata": {},
   "source": [
    "# Step 5 - NER on HAM: HAM Selection & Raw Text Preparation for NER\n",
    "\n",
    "**Purpose:**\n",
    "This step isolates the **HAM (non-spam) corpus** and prepares raw text with original casing for **Named Entity Recognition (NER)** or further linguistic analysis.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Load baseline artifacts**\n",
    "\n",
    "   * Reloads the trained spam classifier (`spam_baseline_pipeline.joblib`) and threshold settings (`spam_baseline_artifacts.json`).\n",
    "   * Uses the saved **SPAM threshold** (`high_recall_global` preferred, fallback to `f1_global` or `0.5`).\n",
    "\n",
    "2. **Score entire dataset**\n",
    "\n",
    "   * Runs spam probabilities (`P(spam)`) on the deduplicated dataset (`df_ready_model`).\n",
    "   * Selects documents predicted as **HAM** (`pred_spam == 0`).\n",
    "\n",
    "3. **Extract HAM subset**\n",
    "\n",
    "   * Creates `ham_df` with all HAM emails.\n",
    "   * Reports size and percentage relative to the full dataset.\n",
    "\n",
    "4. **Rebuild raw text for NER**\n",
    "\n",
    "   * Combines original **subject + body** if available in `df`.\n",
    "   * Falls back to raw `text` if subject/body not present.\n",
    "   * As last resort, uses `text_clean`.\n",
    "   * Preserves **original casing and formatting**, which are critical for NER tasks.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* `ham_df`: HAM-only dataset (deduplicated).\n",
    "* `ham_raw_text`: Series with original-style text, ready for NER.\n",
    "\n",
    "This step ensures that the **ham corpus is isolated** and **raw, human-readable text** is available for entity extraction, avoiding the lowercased/normalized `text_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffdee872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SPAM threshold for selection: 0.5564\n",
      "Predicted HAM: 3468 docs out of 4993 (69.46%)\n",
      "Built raw text for NER (subject+body if available).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nthis is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary\\nflow data provided by daren } ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see attached file : hplnol 09 . xls )\\n- hplnol 09 . xls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re around to that most wonderful time of the year - - - neon leaders retreat time !\\ni know that this time of year is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          raw_text\n",
       "0  Subject: enron methanol ; meter # : 988291\\nthis is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary\\nflow data provided by daren } ....\n",
       "1                                                                Subject: hpl nom for january 9 , 2001\\n( see attached file : hplnol 09 . xls )\\n- hplnol 09 . xls\n",
       "2  Subject: neon retreat\\nho ho ho , we ' re around to that most wonderful time of the year - - - neon leaders retreat time !\\ni know that this time of year is..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Load baseline artifacts\n",
    "assert os.path.exists(\"spam_baseline_pipeline.joblib\"), \"Missing spam_baseline_pipeline.joblib\"\n",
    "assert os.path.exists(\"spam_baseline_artifacts.json\"), \"Missing spam_baseline_artifacts.json\"\n",
    "\n",
    "pipeline_A = joblib.load(\"spam_baseline_pipeline.joblib\")\n",
    "with open(\"spam_baseline_artifacts.json\", \"r\") as f:\n",
    "    artifacts = json.load(f)\n",
    "\n",
    "thr_spam = artifacts[\"thresholds\"].get(\"high_recall_global\") or artifacts[\"thresholds\"].get(\"f1_global\") or 0.5\n",
    "print(f\"Using SPAM threshold for selection: {thr_spam:.4f}\")\n",
    "\n",
    "# 2) df_ready_model must exist from previous steps (deduplicated + text_clean)\n",
    "assert \"df_ready_model\" in globals(), \"df_ready_model is required (deduplicated DataFrame).\"\n",
    "\n",
    "# 3) Score full deduplicated set and select predicted HAM\n",
    "proba_all = pipeline_A.predict_proba(df_ready_model)[:, 1]  # P(spam)\n",
    "pred_spam = (proba_all >= thr_spam).astype(int)\n",
    "ham_mask  = pred_spam == 0\n",
    "\n",
    "ham_idx = df_ready_model.index[ham_mask]\n",
    "ham_df  = df_ready_model.loc[ham_idx].copy()\n",
    "print(f\"Predicted HAM: {len(ham_df)} docs out of {len(df_ready_model)} ({100*len(ham_df)/len(df_ready_model):.2f}%)\")\n",
    "\n",
    "# 4) Build an input text column for NER using ORIGINAL casing (subject + body if available)\n",
    "#    Falls back to 'text' if subject/body are not present.\n",
    "def build_raw_text(i):\n",
    "    if \"df\" in globals():\n",
    "        subj = str(df.loc[i, \"subject\"]) if \"subject\" in df.columns else \"\"\n",
    "        body = str(df.loc[i, \"body\"]) if \"body\" in df.columns else \"\"\n",
    "        if (subj.strip() != \"\") or (body.strip() != \"\"):\n",
    "            return ((\"Subject: \" + subj) if subj else \"\") + (\"\\n\" + body if body else \"\")\n",
    "        # fallback to original text if present\n",
    "        if \"text\" in df.columns:\n",
    "            return str(df.loc[i, \"text\"])\n",
    "    # ultimate fallback: use cleaned text (lowercased)\n",
    "    return str(df_ready_model.loc[i, \"text_clean\"])\n",
    "\n",
    "ham_raw_text = pd.Series({i: build_raw_text(i) for i in ham_idx}, name=\"raw_text\")\n",
    "print(\"Built raw text for NER (subject+body if available).\")\n",
    "\n",
    "# Optional: quick sanity preview\n",
    "display(ham_raw_text.head(3).to_frame())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30497c",
   "metadata": {},
   "source": [
    "## Step 5.1 — NER Pipeline Setup\n",
    "\n",
    "**Purpose:**\n",
    "This step initializes the **Named Entity Recognition (NER)** pipeline that will be used to extract entities (e.g., companies, organizations) from the **HAM corpus**.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Try loading spaCy pre-trained models**\n",
    "\n",
    "   * Attempts to load one of the English models: `en_core_web_sm`, `en_core_web_md`, or `en_core_web_lg`.\n",
    "   * If successful, a proper NER pipeline with pretrained entity recognition is ready.\n",
    "\n",
    "2. **Fallback to rule-based NER**\n",
    "\n",
    "   * If none of the spaCy models are available, a lightweight **rule-based EntityRuler** is built.\n",
    "   * Defines custom patterns to detect **organizations** (`ORG`), such as:\n",
    "\n",
    "     * Company suffixes: `Inc.`, `Corp.`, `Ltd.`, `LLC`, `GmbH`, `plc`, etc.\n",
    "     * Acronyms in uppercase (e.g., `IBM`, `NASA`).\n",
    "     * Explicit keywords like `Google`, `Amazon`, `PayPal`, `Citibank`.\n",
    "\n",
    "3. **Return the NER pipeline**\n",
    "\n",
    "   * Always returns a working `nlp` pipeline (either pretrained or rule-based).\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* `nlp`: an initialized spaCy pipeline ready to process text for **entity extraction**.\n",
    "\n",
    "This ensures we always have **NER capability**, even without downloading external spaCy models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17a13bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NER PIPELINE SETUP ===\n",
      "Loaded spaCy model: en_core_web_md\n",
      "NER pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== NER PIPELINE SETUP ===\")\n",
    "\n",
    "def build_ner():\n",
    "    \"\"\"\n",
    "    Try to load a trained English model. If unavailable, build a rule-based ORG detector.\n",
    "    \"\"\"\n",
    "    nlp = None\n",
    "    tried = []\n",
    "    for name in (\"en_core_web_sm\", \"en_core_web_md\", \"en_core_web_lg\"):\n",
    "        try:\n",
    "            nlp = spacy.load(name, disable=[\"textcat\"])\n",
    "            print(f\"Loaded spaCy model: {name}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            tried.append(name)\n",
    "    if nlp is None:\n",
    "        print(f\"Could not load spaCy models {tried} — using a rule-based EntityRuler.\")\n",
    "        nlp = spacy.blank(\"en\")\n",
    "        ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "        patterns = [\n",
    "            # common company suffix cues\n",
    "            {\"label\": \"ORG\", \"pattern\": [{\"IS_ALPHA\": True, \"OP\": \"+\"}, {\"LOWER\": {\"IN\": [\"inc\",\"inc.\",\"corp\",\"corp.\",\"ltd\",\"ltd.\",\"llc\",\"co\",\"co.\",\"company\",\"bank\",\"university\",\"institute\",\"group\",\"plc\",\"ag\",\"gmbh\"]}}]},\n",
    "            {\"label\": \"ORG\", \"pattern\": [{\"IS_UPPER\": True, \"OP\": \"+\"}]},  # acronyms sequences\n",
    "            # explicit keywords (adjust as needed)\n",
    "            {\"label\": \"ORG\", \"pattern\": [{\"LOWER\": {\"IN\": [\"google\",\"microsoft\",\"amazon\",\"paypal\",\"visa\",\"mastercard\",\"citibank\",\"bank\",\"university\"]}}]},\n",
    "        ]\n",
    "        ruler.add_patterns(patterns)\n",
    "    return nlp\n",
    "\n",
    "nlp = build_ner()\n",
    "print(\"NER pipeline ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034e369",
   "metadata": {},
   "source": [
    "## Step 5.2 — Extract ORG Entities from HAM\n",
    "\n",
    "**Purpose:**\n",
    "This step applies the **NER pipeline** built before to the predicted HAM corpus, in order to **extract organization names (ORG entities)**.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Batch processing with spaCy**\n",
    "\n",
    "   * Uses `nlp.pipe()` over batches of 128 texts at a time to keep memory usage efficient.\n",
    "\n",
    "2. **Normalization of organization names**\n",
    "\n",
    "   * Strips punctuation and whitespace.\n",
    "   * Canonicalizes suffixes (`Inc. → Inc`, `Corp. → Corp`, `Ltd. → Ltd`).\n",
    "   * Collapses multiple spaces and removes extraneous symbols.\n",
    "   * Preserves acronyms in uppercase (e.g., `IBM`).\n",
    "   * Title-cases other organization names for readability.\n",
    "\n",
    "3. **Entity extraction loop**\n",
    "\n",
    "   * Iterates over HAM documents, extracting only entities labeled `ORG`.\n",
    "   * Skips very short or invalid tokens.\n",
    "   * Stores both the raw mention (`org_raw`) and its normalized form (`org_norm`).\n",
    "\n",
    "4. **Results**\n",
    "\n",
    "   * Builds a DataFrame `org_df` with one row per extracted ORG mention.\n",
    "   * Columns:\n",
    "\n",
    "     * `row_id` → index of the HAM email.\n",
    "     * `org_raw` → raw text of the extracted entity.\n",
    "     * `org_norm` → normalized form for grouping/analysis.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* Printed progress (documents processed).\n",
    "* Number of ORG mentions extracted.\n",
    "* A preview of the first 10 extractions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07782250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXTRACTING ORG ENTITIES FROM HAM ===\n",
      "Processed 512/3468 documents...\n",
      "Processed 1024/3468 documents...\n",
      "Processed 1536/3468 documents...\n",
      "Processed 2048/3468 documents...\n",
      "Processed 2560/3468 documents...\n",
      "Processed 3072/3468 documents...\n",
      "Processed 3468/3468 documents...\n",
      "Extracted 11709 ORG mentions from 3468 HAM emails.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>org_raw</th>\n",
       "      <th>org_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>xls</td>\n",
       "      <td>Xls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>xls</td>\n",
       "      <td>Xls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>teco pvr revenue</td>\n",
       "      <td>Teco Pvr Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>teco</td>\n",
       "      <td>Teco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>teco</td>\n",
       "      <td>Teco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>enron</td>\n",
       "      <td>Enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>enron</td>\n",
       "      <td>Enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>enron</td>\n",
       "      <td>Enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>noms</td>\n",
       "      <td>Noms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>xls</td>\n",
       "      <td>Xls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id           org_raw          org_norm\n",
       "0       1               xls               Xls\n",
       "1       1               xls               Xls\n",
       "2       4  teco pvr revenue  Teco Pvr Revenue\n",
       "3       4              teco              Teco\n",
       "4       4              teco              Teco\n",
       "5       5             enron             Enron\n",
       "6       8             enron             Enron\n",
       "7       8             enron             Enron\n",
       "8       8              noms              Noms\n",
       "9       9               xls               Xls"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== EXTRACTING ORG ENTITIES FROM HAM ===\")\n",
    "\n",
    "def iter_docs(text_series, batch_size=128):\n",
    "    \"\"\"Generator over texts to keep memory usage low.\"\"\"\n",
    "    for batch_start in range(0, len(text_series), batch_size):\n",
    "        yield text_series.iloc[batch_start: batch_start + batch_size]\n",
    "\n",
    "def normalize_org(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize organization names for grouping:\n",
    "    - strip whitespace/punct\n",
    "    - collapse multiple spaces\n",
    "    - unify common suffixes (inc./inc → inc, corp./corporation → corp, ltd./limited → ltd)\n",
    "    - keep acronyms uppercase (e.g., 'IBM')\n",
    "    \"\"\"\n",
    "    raw = name.strip()\n",
    "    # keep original case for acronym detection; create a working lower version\n",
    "    low = raw.lower()\n",
    "    # remove brackets & quotes around\n",
    "    low = re.sub(r\"^[\\s\\\"'(\\[]+|[\\s\\\"')\\]]+$\", \"\", low)\n",
    "    # canonicalize suffixes\n",
    "    low = re.sub(r\"\\bincorporated\\b|\\binc\\.\\b\", \"inc\", low)\n",
    "    low = re.sub(r\"\\bcorporation\\b|\\bcorp\\.\\b\", \"corp\", low)\n",
    "    low = re.sub(r\"\\blimited\\b|\\bltd\\.\\b\", \"ltd\", low)\n",
    "    low = re.sub(r\"\\bco\\.\\b\", \"co\", low)\n",
    "    # collapse spaces & punctuation (keep & and -)\n",
    "    low = re.sub(r\"[^\\w&\\- ]+\", \" \", low)\n",
    "    low = re.sub(r\"\\s+\", \" \", low).strip()\n",
    "\n",
    "    # if the original looked like an acronym, preserve uppercase form\n",
    "    if raw.isupper() and len(raw) <= 10:\n",
    "        return raw\n",
    "    # Title-case for readability (keeps IBM as Ibm if not caught above; you may extend logic if desired)\n",
    "    return low.title()\n",
    "\n",
    "# Extract entities\n",
    "records: List[Dict] = []\n",
    "total_docs = len(ham_raw_text)\n",
    "processed = 0\n",
    "\n",
    "for batch in iter_docs(ham_raw_text, batch_size=128):\n",
    "    for doc, idx in zip(nlp.pipe(batch.tolist(), batch_size=128, n_process=1), batch.index):\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ != \"ORG\":\n",
    "                continue\n",
    "            org_raw = ent.text.strip()\n",
    "            # quick filters: avoid extremely short tokens or numeric-like\n",
    "            if len(re.sub(r\"[\\W_]\", \"\", org_raw)) < 2:\n",
    "                continue\n",
    "            org_norm = normalize_org(org_raw)\n",
    "            if len(org_norm) < 2:\n",
    "                continue\n",
    "            records.append({\"row_id\": int(idx), \"org_raw\": org_raw, \"org_norm\": org_norm})\n",
    "    processed += len(batch)\n",
    "    if processed % 512 == 0 or processed == total_docs:\n",
    "        print(f\"Processed {processed}/{total_docs} documents...\")\n",
    "\n",
    "org_df = pd.DataFrame.from_records(records)\n",
    "print(f\"Extracted {len(org_df)} ORG mentions from {total_docs} HAM emails.\")\n",
    "display(org_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c4f5e",
   "metadata": {},
   "source": [
    "## Step 5.3 — Aggregation & Top Organizations\n",
    "\n",
    "**Purpose:**\n",
    "This step aggregates all the **organization mentions** extracted from HAM emails and produces summary statistics.\n",
    "\n",
    "**Main actions:**\n",
    "\n",
    "1. **Aggregate mentions**\n",
    "\n",
    "   * Counts how many times each organization (`mentions`) appears.\n",
    "   * Counts in how many distinct documents each organization is mentioned (`docs`).\n",
    "   * Keeps one representative raw mention (`org_raw`) for readability.\n",
    "\n",
    "2. **Sorting & Top list**\n",
    "\n",
    "   * Organizations are sorted by descending `mentions` (then by `docs`).\n",
    "   * Displays the **Top 30 most frequent organizations**.\n",
    "\n",
    "3. **Outputs & persistence**\n",
    "\n",
    "   * Saves two CSV files:\n",
    "\n",
    "     * `ham_org_top.csv` → aggregated stats (org\\_norm, mentions, docs, example\\_raw).\n",
    "     * `ham_org_mentions.csv` → the full list of extracted mentions (row-level).\n",
    "\n",
    "4. **Coverage metric**\n",
    "\n",
    "   * Calculates the percentage of HAM emails that contain at least one detected organization.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* A DataFrame `agg` with normalized organizations and their stats.\n",
    "* Printed coverage percentage.\n",
    "* Two CSV artifacts with the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daf99ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AGGREGATION & TOP ORGANIZATIONS ===\n",
      "Top organizations by mentions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_norm</th>\n",
       "      <th>mentions</th>\n",
       "      <th>docs</th>\n",
       "      <th>org_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enron</td>\n",
       "      <td>3180</td>\n",
       "      <td>1085</td>\n",
       "      <td>enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xls</td>\n",
       "      <td>872</td>\n",
       "      <td>476</td>\n",
       "      <td>xls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Teco</td>\n",
       "      <td>358</td>\n",
       "      <td>223</td>\n",
       "      <td>teco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ami Chokshi Corp Enron</td>\n",
       "      <td>194</td>\n",
       "      <td>145</td>\n",
       "      <td>ami chokshi / corp / enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Txu</td>\n",
       "      <td>176</td>\n",
       "      <td>79</td>\n",
       "      <td>txu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ena</td>\n",
       "      <td>152</td>\n",
       "      <td>84</td>\n",
       "      <td>ena \u0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Noms</td>\n",
       "      <td>148</td>\n",
       "      <td>134</td>\n",
       "      <td>noms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tenaska</td>\n",
       "      <td>139</td>\n",
       "      <td>77</td>\n",
       "      <td>tenaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Doc</td>\n",
       "      <td>137</td>\n",
       "      <td>104</td>\n",
       "      <td>doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lauri</td>\n",
       "      <td>112</td>\n",
       "      <td>77</td>\n",
       "      <td>lauri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vance L Taylor Hou</td>\n",
       "      <td>108</td>\n",
       "      <td>76</td>\n",
       "      <td>vance l taylor / hou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tx</td>\n",
       "      <td>97</td>\n",
       "      <td>51</td>\n",
       "      <td>tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hanks Hou</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>hanks / hou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Redeliveries</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>redeliveries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aep</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>aep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Enron North America Corp</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "      <td>enron north america corp .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Allen Hou</td>\n",
       "      <td>77</td>\n",
       "      <td>59</td>\n",
       "      <td>allen / hou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aol</td>\n",
       "      <td>74</td>\n",
       "      <td>24</td>\n",
       "      <td>aol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Exxon</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>exxon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Enron Corp</td>\n",
       "      <td>61</td>\n",
       "      <td>29</td>\n",
       "      <td>enron corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Megan Parker Corp Enron</td>\n",
       "      <td>58</td>\n",
       "      <td>38</td>\n",
       "      <td>megan parker / corp / enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Valero</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>valero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ews</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>ews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pg &amp; E</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>pg &amp; e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mobil</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>mobil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Katherine Herrera Corp Enron</td>\n",
       "      <td>49</td>\n",
       "      <td>27</td>\n",
       "      <td>katherine herrera / corp / enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Coastal Oil &amp; Gas Corp</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>coastal oil &amp; gas corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Enron Capital &amp; Trade Resources Corp</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>enron capital &amp; trade resources corp .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>el paso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Speckels</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>speckels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                org_norm  mentions  docs  \\\n",
       "0                                  Enron      3180  1085   \n",
       "1                                    Xls       872   476   \n",
       "2                                   Teco       358   223   \n",
       "3                 Ami Chokshi Corp Enron       194   145   \n",
       "4                                    Txu       176    79   \n",
       "5                                    Ena       152    84   \n",
       "6                                   Noms       148   134   \n",
       "7                                Tenaska       139    77   \n",
       "8                                    Doc       137   104   \n",
       "9                                  Lauri       112    77   \n",
       "10                    Vance L Taylor Hou       108    76   \n",
       "11                                    Tx        97    51   \n",
       "12                             Hanks Hou        89    69   \n",
       "13                          Redeliveries        88    71   \n",
       "14                                   Aep        84    33   \n",
       "15              Enron North America Corp        80    69   \n",
       "16                             Allen Hou        77    59   \n",
       "17                                   Aol        74    24   \n",
       "18                                 Exxon        63    31   \n",
       "19                            Enron Corp        61    29   \n",
       "20               Megan Parker Corp Enron        58    38   \n",
       "21                                Valero        58    31   \n",
       "22                                   Ews        52     5   \n",
       "23                                Pg & E        49    39   \n",
       "24                                 Mobil        49    28   \n",
       "25          Katherine Herrera Corp Enron        49    27   \n",
       "26                Coastal Oil & Gas Corp        45     4   \n",
       "27  Enron Capital & Trade Resources Corp        44    40   \n",
       "28                               El Paso        42    29   \n",
       "29                              Speckels        40    32   \n",
       "\n",
       "                                   org_raw  \n",
       "0                                    enron  \n",
       "1                                      xls  \n",
       "2                                     teco  \n",
       "3               ami chokshi / corp / enron  \n",
       "4                                      txu  \n",
       "5                                    ena \u0001  \n",
       "6                                     noms  \n",
       "7                                  tenaska  \n",
       "8                                      doc  \n",
       "9                                    lauri  \n",
       "10                    vance l taylor / hou  \n",
       "11                                      tx  \n",
       "12                             hanks / hou  \n",
       "13                            redeliveries  \n",
       "14                                     aep  \n",
       "15              enron north america corp .  \n",
       "16                             allen / hou  \n",
       "17                                     aol  \n",
       "18                                   exxon  \n",
       "19                              enron corp  \n",
       "20             megan parker / corp / enron  \n",
       "21                                  valero  \n",
       "22                                     ews  \n",
       "23                                  pg & e  \n",
       "24                                   mobil  \n",
       "25        katherine herrera / corp / enron  \n",
       "26           coastal oil & gas corporation  \n",
       "27  enron capital & trade resources corp .  \n",
       "28                                 el paso  \n",
       "29                                speckels  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ham_org_top.csv, ham_org_mentions.csv\n",
      "Coverage: 76.36% of HAM emails contain at least one ORG.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AGGREGATION & TOP ORGANIZATIONS ===\")\n",
    "\n",
    "if org_df.empty:\n",
    "    print(\"No ORG entities extracted. Nothing to aggregate.\")\n",
    "else:\n",
    "    # doc-level unique ORGs\n",
    "    doc_orgs = org_df.drop_duplicates([\"row_id\", \"org_norm\"])\n",
    "    # overall counts\n",
    "    counts = org_df[\"org_norm\"].value_counts().rename_axis(\"org_norm\").reset_index(name=\"mentions\")\n",
    "    docs   = doc_orgs[\"org_norm\"].value_counts().rename_axis(\"org_norm\").reset_index(name=\"docs\")\n",
    "\n",
    "    agg = counts.merge(docs, on=\"org_norm\", how=\"outer\").fillna(0)\n",
    "    agg[\"mentions\"] = agg[\"mentions\"].astype(int)\n",
    "    agg[\"docs\"]     = agg[\"docs\"].astype(int)\n",
    "    agg = agg.sort_values([\"mentions\",\"docs\"], ascending=False)\n",
    "\n",
    "    # Optional: join one example of the raw form for readability\n",
    "    example_raw = org_df.groupby(\"org_norm\")[\"org_raw\"].agg(lambda s: s.iloc[0]).reset_index()\n",
    "    agg = agg.merge(example_raw, on=\"org_norm\", how=\"left\")\n",
    "\n",
    "    print(\"Top organizations by mentions:\")\n",
    "    display(agg.head(30))\n",
    "\n",
    "    # Save artifacts\n",
    "    agg.to_csv(\"ham_org_top.csv\", index=False)\n",
    "    org_df.to_csv(\"ham_org_mentions.csv\", index=False)\n",
    "    print(\"Saved: ham_org_top.csv, ham_org_mentions.csv\")\n",
    "\n",
    "    # Coverage: % of HAM docs with at least 1 ORG\n",
    "    coverage = doc_orgs[\"row_id\"].nunique() / len(ham_df) * 100\n",
    "    print(f\"Coverage: {coverage:.2f}% of HAM emails contain at least one ORG.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7d8cb",
   "metadata": {},
   "source": [
    "## Step 5.4 — Optional: Samples for QA (Qualitative Review)\n",
    "\n",
    "**Purpose**\n",
    "Give quick, human-readable **examples of emails** mentioning the top organizations found in Step 5.3, so you can sanity-check extraction quality and topic relevance.\n",
    "\n",
    "**What it does**\n",
    "\n",
    "1. **Sampling helper** `sample_org(org_name, k=5)`\n",
    "\n",
    "   * Finds up to *k* example rows (`row_id`) where `org_norm == org_name`.\n",
    "   * **Prefers raw context** from the original `df` (columns `subject`, `body`, or `text` if present).\n",
    "   * **Falls back** to `df_ready_model['text_clean']` when raw columns aren’t available.\n",
    "\n",
    "2. **Generate samples for top orgs**\n",
    "\n",
    "   * For the **top 5 organizations** in `agg`, prints up to **3 examples** each with contextual text.\n",
    "\n",
    "3. **Persist examples (optional)**\n",
    "\n",
    "   * Concatenates first examples per org into a single CSV: **`ham_org_samples.csv`**.\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "* Printed tables with sample emails per top org (max 3 each).\n",
    "* File: `ham_org_samples.csv` (row\\_id, org\\_norm, and available text columns).\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* Requires `org_df` (from Step 4.7) and `agg` (from Step 5.3).\n",
    "* If `agg` is missing or empty, the cell skips sampling gracefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "919282e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OPTIONAL: SAMPLES FOR QA ===\n",
      "\n",
      "--- Samples for: Enron ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>ehronline web address change</td>\n",
       "      <td>this message is intended for ehronline users only .\\ndue to a recent change to ehronline , the url ( aka \" web address \" ) for accessing ehronline needs to ...</td>\n",
       "      <td>Subject: ehronline web address change\\nthis message is intended for ehronline users only .\\ndue to a recent change to ehronline , the url ( aka \" web addres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>noms / actual flow for 2 / 26</td>\n",
       "      <td>we agree\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by melissa jones / texas utilities on\\n02 / 27 / 2001\\n10 : 33 am - - - - - - - - - - - - - ...</td>\n",
       "      <td>Subject: noms / actual flow for 2 / 26\\nwe agree\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by melissa jones / texas utilities on\\n02 / 27 / 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>enron / hpl actuals for august 28 , 2000</td>\n",
       "      <td>teco tap 20 . 000 / enron ; 120 . 000 / hpl gas daily\\nls hpl lsk ic 20 . 000 / enron</td>\n",
       "      <td>Subject: enron / hpl actuals for august 28 , 2000\\nteco tap 20 . 000 / enron ; 120 . 000 / hpl gas daily\\nls hpl lsk ic 20 . 000 / enron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                   subject  \\\n",
       "0       5              ehronline web address change   \n",
       "1       8             noms / actual flow for 2 / 26   \n",
       "2      12  enron / hpl actuals for august 28 , 2000   \n",
       "\n",
       "                                                                                                                                                              body  \\\n",
       "0  this message is intended for ehronline users only .\\ndue to a recent change to ehronline , the url ( aka \" web address \" ) for accessing ehronline needs to ...   \n",
       "1  we agree\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by melissa jones / texas utilities on\\n02 / 27 / 2001\\n10 : 33 am - - - - - - - - - - - - - ...   \n",
       "2                                                                            teco tap 20 . 000 / enron ; 120 . 000 / hpl gas daily\\nls hpl lsk ic 20 . 000 / enron   \n",
       "\n",
       "                                                                                                                                                              text  \n",
       "0  Subject: ehronline web address change\\nthis message is intended for ehronline users only .\\ndue to a recent change to ehronline , the url ( aka \" web addres...  \n",
       "1  Subject: noms / actual flow for 2 / 26\\nwe agree\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by melissa jones / texas utilities on\\n02 / 27 / 200...  \n",
       "2                         Subject: enron / hpl actuals for august 28 , 2000\\nteco tap 20 . 000 / enron ; 120 . 000 / hpl gas daily\\nls hpl lsk ic 20 . 000 / enron  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Samples for: Xls ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hpl nom for january 9 , 2001</td>\n",
       "      <td>( see attached file : hplnol 09 . xls )\\n- hplnol 09 . xls</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see attached file : hplnol 09 . xls )\\n- hplnol 09 . xls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>nominations for oct . 21 - 23 , 2000</td>\n",
       "      <td>( see attached file : hplnl 021 . xls )\\n- hplnl 021 . xls</td>\n",
       "      <td>Subject: nominations for oct . 21 - 23 , 2000\\n( see attached file : hplnl 021 . xls )\\n- hplnl 021 . xls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>hpl nom for january 25 , 2001</td>\n",
       "      <td>( see attached file : hplnol 26 . xls )\\n- hplnol 26 . xls</td>\n",
       "      <td>Subject: hpl nom for january 25 , 2001\\n( see attached file : hplnol 26 . xls )\\n- hplnol 26 . xls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                               subject  \\\n",
       "0       1          hpl nom for january 9 , 2001   \n",
       "1       9  nominations for oct . 21 - 23 , 2000   \n",
       "2      22         hpl nom for january 25 , 2001   \n",
       "\n",
       "                                                         body  \\\n",
       "0  ( see attached file : hplnol 09 . xls )\\n- hplnol 09 . xls   \n",
       "1  ( see attached file : hplnl 021 . xls )\\n- hplnl 021 . xls   \n",
       "2  ( see attached file : hplnol 26 . xls )\\n- hplnol 26 . xls   \n",
       "\n",
       "                                                                                                        text  \n",
       "0          Subject: hpl nom for january 9 , 2001\\n( see attached file : hplnol 09 . xls )\\n- hplnol 09 . xls  \n",
       "1  Subject: nominations for oct . 21 - 23 , 2000\\n( see attached file : hplnl 021 . xls )\\n- hplnl 021 . xls  \n",
       "2         Subject: hpl nom for january 25 , 2001\\n( see attached file : hplnol 26 . xls )\\n- hplnol 26 . xls  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Samples for: Teco ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>re : indian springs</td>\n",
       "      <td>this deal is to book the teco pvr revenue . it is my understanding that teco\\njust sends us a check , i haven ' t received an answer as to whether there is ...</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to book the teco pvr revenue . it is my understanding that teco\\njust sends us a check , i haven ' t received an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>enron / hpl actuals for august 28 , 2000</td>\n",
       "      <td>teco tap 20 . 000 / enron ; 120 . 000 / hpl gas daily\\nls hpl lsk ic 20 . 000 / enron</td>\n",
       "      <td>Subject: enron / hpl actuals for august 28 , 2000\\nteco tap 20 . 000 / enron ; 120 . 000 / hpl gas daily\\nls hpl lsk ic 20 . 000 / enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>re : enron / hpl actuals for october 11 , 2000 - revision</td>\n",
       "      <td>please note that the pricing allocation of volumes for october 11 , 2000 should\\nbe changed as follows .\\nteco tap 40 . 000 / enron ; 25 . 209 / hpl iferc ;...</td>\n",
       "      <td>Subject: re : enron / hpl actuals for october 11 , 2000 - revision\\nplease note that the pricing allocation of volumes for october 11 , 2000 should\\nbe chan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                                    subject  \\\n",
       "0       4                                        re : indian springs   \n",
       "1      12                   enron / hpl actuals for august 28 , 2000   \n",
       "2      25  re : enron / hpl actuals for october 11 , 2000 - revision   \n",
       "\n",
       "                                                                                                                                                              body  \\\n",
       "0  this deal is to book the teco pvr revenue . it is my understanding that teco\\njust sends us a check , i haven ' t received an answer as to whether there is ...   \n",
       "1                                                                            teco tap 20 . 000 / enron ; 120 . 000 / hpl gas daily\\nls hpl lsk ic 20 . 000 / enron   \n",
       "2  please note that the pricing allocation of volumes for october 11 , 2000 should\\nbe changed as follows .\\nteco tap 40 . 000 / enron ; 25 . 209 / hpl iferc ;...   \n",
       "\n",
       "                                                                                                                                                              text  \n",
       "0  Subject: re : indian springs\\nthis deal is to book the teco pvr revenue . it is my understanding that teco\\njust sends us a check , i haven ' t received an ...  \n",
       "1                         Subject: enron / hpl actuals for august 28 , 2000\\nteco tap 20 . 000 / enron ; 120 . 000 / hpl gas daily\\nls hpl lsk ic 20 . 000 / enron  \n",
       "2  Subject: re : enron / hpl actuals for october 11 , 2000 - revision\\nplease note that the pricing allocation of volumes for october 11 , 2000 should\\nbe chan...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Samples for: Ami Chokshi Corp Enron ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>19 th noms on copanos</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 18 / 2000\\n11 : 11 am - - - - - - - - - - - - - - - - - - - - - ...</td>\n",
       "      <td>Subject: 19 th noms on copanos\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 18 / 2000\\n11 : 11 am - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>21 st changes</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 20 / 2000\\n10 : 39 am - - - - - - - - - - - - - - - - - - - - - ...</td>\n",
       "      <td>Subject: 21 st changes\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 20 / 2000\\n10 : 39 am - - - - - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>7 th noms</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 06 / 2000\\n10 : 49 am - - - - - - - - - - - - - - - - - - - - - ...</td>\n",
       "      <td>Subject: 7 th noms\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 06 / 2000\\n10 : 49 am - - - - - - - - - - - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                subject  \\\n",
       "0      38  19 th noms on copanos   \n",
       "1      81          21 st changes   \n",
       "2     108              7 th noms   \n",
       "\n",
       "                                                                                                                                                              body  \\\n",
       "0  - - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 18 / 2000\\n11 : 11 am - - - - - - - - - - - - - - - - - - - - - ...   \n",
       "1  - - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 20 / 2000\\n10 : 39 am - - - - - - - - - - - - - - - - - - - - - ...   \n",
       "2  - - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 06 / 2000\\n10 : 49 am - - - - - - - - - - - - - - - - - - - - - ...   \n",
       "\n",
       "                                                                                                                                                              text  \n",
       "0  Subject: 19 th noms on copanos\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 18 / 2000\\n11 : 11 am - - - - - ...  \n",
       "1  Subject: 21 st changes\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 20 / 2000\\n10 : 39 am - - - - - - - - - ...  \n",
       "2  Subject: 7 th noms\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 01 / 06 / 2000\\n10 : 49 am - - - - - - - - - - - ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Samples for: Txu ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>fw : txu fuel deals imbalances</td>\n",
       "      <td>daren ,\\nthe deals listed below are related to tufco imbalances . . . let me know if you have any objections to me entering the deals . . . o ' neal 3 - 968...</td>\n",
       "      <td>Subject: fw : txu fuel deals imbalances\\ndaren ,\\nthe deals listed below are related to tufco imbalances . . . let me know if you have any objections to me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>@ ect . enron . com email notification !</td>\n",
       "      <td>we are one @ enron . com !\\nplease be aware of the following senders were automatically notified to ( a ) .\\nstop sending internet mail to your @ ect . enro...</td>\n",
       "      <td>Subject: @ ect . enron . com email notification !\\nwe are one @ enron . com !\\nplease be aware of the following senders were automatically notified to ( a )...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121</td>\n",
       "      <td>txu noms . for 10 / 14 - 16 / 00</td>\n",
       "      <td>attached , please find the txu nominations for the weekend of october 14 - 16 ,\\n2000 .\\nno scheduled flows\\n( see attached file : hplnl 014 . xls )\\n- hpln...</td>\n",
       "      <td>Subject: txu noms . for 10 / 14 - 16 / 00\\nattached , please find the txu nominations for the weekend of october 14 - 16 ,\\n2000 .\\nno scheduled flows\\n( se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                   subject  \\\n",
       "0      61            fw : txu fuel deals imbalances   \n",
       "1      79  @ ect . enron . com email notification !   \n",
       "2     121          txu noms . for 10 / 14 - 16 / 00   \n",
       "\n",
       "                                                                                                                                                              body  \\\n",
       "0  daren ,\\nthe deals listed below are related to tufco imbalances . . . let me know if you have any objections to me entering the deals . . . o ' neal 3 - 968...   \n",
       "1  we are one @ enron . com !\\nplease be aware of the following senders were automatically notified to ( a ) .\\nstop sending internet mail to your @ ect . enro...   \n",
       "2  attached , please find the txu nominations for the weekend of october 14 - 16 ,\\n2000 .\\nno scheduled flows\\n( see attached file : hplnl 014 . xls )\\n- hpln...   \n",
       "\n",
       "                                                                                                                                                              text  \n",
       "0  Subject: fw : txu fuel deals imbalances\\ndaren ,\\nthe deals listed below are related to tufco imbalances . . . let me know if you have any objections to me ...  \n",
       "1  Subject: @ ect . enron . com email notification !\\nwe are one @ enron . com !\\nplease be aware of the following senders were automatically notified to ( a )...  \n",
       "2  Subject: txu noms . for 10 / 14 - 16 / 00\\nattached , please find the txu nominations for the weekend of october 14 - 16 ,\\n2000 .\\nno scheduled flows\\n( se...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ham_org_samples.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=== OPTIONAL: SAMPLES FOR QA ===\")\n",
    "\n",
    "# Build a small view by joining back to the raw subject/body for context\n",
    "def sample_org(org_name, k=5):\n",
    "    subset_idx = org_df.loc[org_df[\"org_norm\"] == org_name, \"row_id\"].unique()[:k]\n",
    "    # prefer original df (subject/body) if available\n",
    "    if \"df\" in globals():\n",
    "        cols = [c for c in [\"subject\",\"body\",\"text\"] if c in df.columns]\n",
    "        return df.loc[subset_idx, cols].reset_index().rename(columns={\"index\":\"row_id\"})\n",
    "    # fallback: df_ready_model\n",
    "    return df_ready_model.loc[subset_idx, [\"text_clean\"]].reset_index().rename(columns={\"index\":\"row_id\"})\n",
    "\n",
    "if 'agg' in globals() and not agg.empty:\n",
    "    samples = {}\n",
    "    for org_name in agg.head(5)[\"org_norm\"]:\n",
    "        samples[org_name] = sample_org(org_name, k=3)\n",
    "        print(f\"\\n--- Samples for: {org_name} ---\")\n",
    "        display(samples[org_name])\n",
    "\n",
    "    # Optionally save one merged CSV with first N examples per top org\n",
    "    rows = []\n",
    "    for org_name, sdf in samples.items():\n",
    "        sdf = sdf.copy()\n",
    "        sdf.insert(1, \"org_norm\", org_name)\n",
    "        rows.append(sdf)\n",
    "    if rows:\n",
    "        pd.concat(rows, ignore_index=True).to_csv(\"ham_org_samples.csv\", index=False)\n",
    "        print(\"Saved: ham_org_samples.csv\")\n",
    "else:\n",
    "    print(\"No agg table found or empty; skip samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d593e",
   "metadata": {},
   "source": [
    "# STEP 6 - Calibration, Thresholding, Final Fit & Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa295e31",
   "metadata": {},
   "source": [
    "## Step 6.1 — Shared Helpers\n",
    "\n",
    "**Purpose**\n",
    "Centralize **reusable functions** for building classifiers and pipelines, ensuring consistency across experiments.\n",
    "\n",
    "**What it does**\n",
    "\n",
    "1. **`make_logreg`**\n",
    "\n",
    "   * Returns a Logistic Regression with:\n",
    "\n",
    "     * `class_weight=\"balanced\"` (handles class imbalance).\n",
    "     * `solver=\"liblinear\"` (stable for small/medium sparse data).\n",
    "     * `max_iter=2000`, reproducible with `random_state`.\n",
    "\n",
    "2. **`make_calibrated`**\n",
    "\n",
    "   * Wraps a base model into `CalibratedClassifierCV`.\n",
    "   * Provides version-safe handling of `estimator` vs `base_estimator`.\n",
    "   * Calibration improves **probability estimates**.\n",
    "\n",
    "3. **`build_pipeline_by_name`**\n",
    "\n",
    "   * Factory function to build full sklearn `Pipeline` variants:\n",
    "\n",
    "     * `\"A_word+meta\"` → Word n-grams + meta-features.\n",
    "     * `\"B_word+char+meta\"` → Word n-grams + character n-grams + meta-features.\n",
    "     * `\"C_text_only\"` → Only text features, without meta-features.\n",
    "   * Each pipeline ends with either:\n",
    "\n",
    "     * A raw Logistic Regression, or\n",
    "     * A calibrated version (if `calibrated=True`).\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "* No direct artifacts.\n",
    "* Defines helper functions for use in later steps (model training & comparison).\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* Keeps pipeline definitions **consistent and reproducible**.\n",
    "* Makes it easier to switch between feature sets and calibration options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a5755e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 6.1 — SHARED HELPERS ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 6.1 — SHARED HELPERS ===\")\n",
    "\n",
    "def make_logreg(random_state=42):\n",
    "    return LogisticRegression(\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=2000,\n",
    "        solver=\"liblinear\",\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "# Version-safe wrapper for CalibratedClassifierCV (estimator vs base_estimator)\n",
    "def make_calibrated(base, cv=5, method=\"sigmoid\"):\n",
    "    try:\n",
    "        return CalibratedClassifierCV(estimator=base, cv=cv, method=method)\n",
    "    except TypeError:\n",
    "        return CalibratedClassifierCV(base_estimator=base, cv=cv, method=method)\n",
    "\n",
    "# Build a full sklearn Pipeline by name, using your existing factory\n",
    "def build_pipeline_by_name(name: str, calibrated: bool = False):\n",
    "    if name == \"A_word+meta\":\n",
    "        feat = build_features_transformer(all_meta_features, mode=\"word\")\n",
    "    elif name == \"B_word+char+meta\":\n",
    "        feat = build_features_transformer(all_meta_features, mode=\"word_char\")\n",
    "    elif name == \"C_text_only\":\n",
    "        feat = build_features_transformer([], mode=\"word\")  # disable numeric branch\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown pipeline '{name}'\")\n",
    "\n",
    "    base = make_logreg()\n",
    "    clf = make_calibrated(base) if calibrated else base\n",
    "    return Pipeline([(\"features\", feat), (\"clf\", clf)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8f6cc",
   "metadata": {},
   "source": [
    "## Step 6.2 — Ablation & Model Comparison\n",
    "\n",
    "**Purpose**\n",
    "Compare different **feature configurations** (with/without meta-features, with/without char n-grams) to measure their contribution and choose the best pipeline.\n",
    "\n",
    "**What it does**\n",
    "\n",
    "1. **Loads dataset** (`df_ready_model.csv`) and sets up **StratifiedKFold (5 folds)** for balanced CV.\n",
    "2. **Defines pipelines**:\n",
    "\n",
    "   * **A\\_word+meta** → Word n-grams + meta-features.\n",
    "   * **B\\_word+char+meta** → Word n-grams + char n-grams + meta-features.\n",
    "   * **C\\_text\\_only** → Only word n-grams, no meta-features.\n",
    "3. **Cross-validation loop** (`evaluate_cv`) computes for each fold:\n",
    "\n",
    "   * PR-AUC (Precision-Recall AUC)\n",
    "   * ROC-AUC\n",
    "   * F1\\@0.5\n",
    "   * Training time\n",
    "4. Collects and aggregates results (`mean ± std`).\n",
    "5. Displays a comparison table and selects the **best pipeline** (by PR-AUC, tie-breaking with ROC, then F1).\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "* A summary DataFrame with CV metrics for each pipeline.\n",
    "* Variable `BEST_PIPELINE_NAME` storing the name of the chosen pipeline.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* This is a **controlled ablation test**: helps to quantify the added value of **meta-features** and **character n-grams** beyond word-level TF-IDF.\n",
    "* Ensures model choice is **data-driven** before moving to final training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97aa0c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 6.2 — ABLATION & MODEL COMPARISON ===\n",
      "\n",
      ">>> A_word+meta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fold 1: PR-AUC 0.9690 | ROC-AUC 0.9910 | F1@0.5 0.9386\n",
      "  fold 2: PR-AUC 0.9515 | ROC-AUC 0.9896 | F1@0.5 0.9355\n",
      "  fold 3: PR-AUC 0.9666 | ROC-AUC 0.9906 | F1@0.5 0.9333\n",
      "  fold 4: PR-AUC 0.9388 | ROC-AUC 0.9882 | F1@0.5 0.9325\n",
      "  fold 5: PR-AUC 0.9723 | ROC-AUC 0.9907 | F1@0.5 0.9475\n",
      "\n",
      ">>> B_word+char+meta\n",
      "  fold 1: PR-AUC 0.9876 | ROC-AUC 0.9964 | F1@0.5 0.9714\n",
      "  fold 2: PR-AUC 0.9846 | ROC-AUC 0.9954 | F1@0.5 0.9525\n",
      "  fold 3: PR-AUC 0.9935 | ROC-AUC 0.9974 | F1@0.5 0.9649\n",
      "  fold 4: PR-AUC 0.9665 | ROC-AUC 0.9941 | F1@0.5 0.9732\n",
      "  fold 5: PR-AUC 0.9961 | ROC-AUC 0.9984 | F1@0.5 0.9571\n",
      "\n",
      ">>> C_text_only\n",
      "  fold 1: PR-AUC 0.9961 | ROC-AUC 0.9984 | F1@0.5 0.9604\n",
      "  fold 2: PR-AUC 0.9901 | ROC-AUC 0.9968 | F1@0.5 0.9435\n",
      "  fold 3: PR-AUC 0.9897 | ROC-AUC 0.9963 | F1@0.5 0.9494\n",
      "  fold 4: PR-AUC 0.9902 | ROC-AUC 0.9964 | F1@0.5 0.9652\n",
      "  fold 5: PR-AUC 0.9966 | ROC-AUC 0.9985 | F1@0.5 0.9572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline</th>\n",
       "      <th>PR-AUC (mean±std)</th>\n",
       "      <th>ROC-AUC (mean±std)</th>\n",
       "      <th>F1@0.5 (mean±std)</th>\n",
       "      <th>time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_text_only</td>\n",
       "      <td>0.9925 ± 0.0031</td>\n",
       "      <td>0.9973 ± 0.0010</td>\n",
       "      <td>0.9551 ± 0.0078</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_word+char+meta</td>\n",
       "      <td>0.9857 ± 0.0104</td>\n",
       "      <td>0.9964 ± 0.0015</td>\n",
       "      <td>0.9638 ± 0.0080</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_word+meta</td>\n",
       "      <td>0.9596 ± 0.0126</td>\n",
       "      <td>0.9900 ± 0.0010</td>\n",
       "      <td>0.9375 ± 0.0055</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pipeline PR-AUC (mean±std) ROC-AUC (mean±std) F1@0.5 (mean±std)  \\\n",
       "2       C_text_only   0.9925 ± 0.0031    0.9973 ± 0.0010   0.9551 ± 0.0078   \n",
       "1  B_word+char+meta   0.9857 ± 0.0104    0.9964 ± 0.0015   0.9638 ± 0.0080   \n",
       "0       A_word+meta   0.9596 ± 0.0126    0.9900 ± 0.0010   0.9375 ± 0.0055   \n",
       "\n",
       "  time_sec  \n",
       "2      7.2  \n",
       "1     64.6  \n",
       "0      7.7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen pipeline: C_text_only\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 6.2 — ABLATION & MODEL COMPARISON ===\")\n",
    "# --- Reuse previously defined artifacts ---\n",
    "assert \"all_meta_features\" in globals(), \"all_meta_features not found. Run feature discovery cell.\"\n",
    "assert \"build_features_transformer\" in globals(), \"build_features_transformer() missing. Run Cell 2.\"\n",
    "# Optional: if your notebook already defined a named to-csr function/scaler pipeline, they are used inside build_features_transformer.\n",
    "\n",
    "df_ready_model = pd.read_csv(\"df_ready_model.csv\")\n",
    "X = df_ready_model.drop(columns=[\"label_num\"])\n",
    "y = df_ready_model[\"label_num\"].values\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Pipelines for ablation — built via your existing factory\n",
    "pipelines = {\n",
    "    \"A_word+meta\": Pipeline([\n",
    "        (\"features\", build_features_transformer(all_meta_features, mode=\"word\")),\n",
    "        (\"clf\", make_logreg())\n",
    "    ]),\n",
    "    \"B_word+char+meta\": Pipeline([\n",
    "        (\"features\", build_features_transformer(all_meta_features, mode=\"word_char\")),\n",
    "        (\"clf\", make_logreg())\n",
    "    ]),\n",
    "    # text-only: pass a blank list for meta features so the numeric column is \"off\"\n",
    "    \"C_text_only\": Pipeline([\n",
    "        (\"features\", build_features_transformer([], mode=\"word\")),\n",
    "        (\"clf\", make_logreg())\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "def evaluate_cv(pipe, X, y, cv):\n",
    "    pr, roc, f1s = [], [], []\n",
    "    t0 = time.time()\n",
    "    for k, (tr, va) in enumerate(cv.split(X, y), 1):\n",
    "        X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "        y_tr, y_va = y[tr], y[va]\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        proba = pipe.predict_proba(X_va)[:, 1]\n",
    "        pr.append(average_precision_score(y_va, proba))\n",
    "        roc.append(roc_auc_score(y_va, proba))\n",
    "        f1s.append(f1_score(y_va, (proba >= 0.5).astype(int)))\n",
    "        print(f\"  fold {k}: PR-AUC {pr[-1]:.4f} | ROC-AUC {roc[-1]:.4f} | F1@0.5 {f1s[-1]:.4f}\")\n",
    "    return {\"pr_mean\": np.mean(pr), \"pr_std\": np.std(pr),\n",
    "            \"roc_mean\": np.mean(roc), \"roc_std\": np.std(roc),\n",
    "            \"f1_mean\": np.mean(f1s), \"f1_std\": np.std(f1s),\n",
    "            \"time_sec\": time.time() - t0}\n",
    "\n",
    "rows = []\n",
    "for name, pipe in pipelines.items():\n",
    "    print(f\"\\n>>> {name}\")\n",
    "    s = evaluate_cv(pipe, X, y, cv)\n",
    "    rows.append({\"pipeline\": name,\n",
    "                 \"PR-AUC (mean±std)\": f\"{s['pr_mean']:.4f} ± {s['pr_std']:.4f}\",\n",
    "                 \"ROC-AUC (mean±std)\": f\"{s['roc_mean']:.4f} ± {s['roc_std']:.4f}\",\n",
    "                 \"F1@0.5 (mean±std)\": f\"{s['f1_mean']:.4f} ± {s['f1_std']:.4f}\",\n",
    "                 \"time_sec\": f\"{s['time_sec']:.1f}\"})\n",
    "comparison_df = pd.DataFrame(rows).sort_values(\"PR-AUC (mean±std)\", ascending=False)\n",
    "display(comparison_df)\n",
    "\n",
    "# Choose best by PR-AUC (tie-breaker ROC, then F1)\n",
    "best_idx = np.argmax([float(r[\"PR-AUC (mean±std)\"].split(\" ± \")[0]) for r in rows])\n",
    "BEST_PIPELINE_NAME = rows[best_idx][\"pipeline\"]\n",
    "print(f\"\\nChosen pipeline: {BEST_PIPELINE_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d19ef",
   "metadata": {},
   "source": [
    "## Step 6.3 — Calibration (Sigmoid)\n",
    "\n",
    "**Purpose**\n",
    "Check whether **probability calibration** improves the reliability of predicted probabilities.\n",
    "\n",
    "**What it does**\n",
    "\n",
    "1. **Builds two versions** of the best pipeline (`BEST_PIPELINE_NAME`):\n",
    "\n",
    "   * `pipe_uncal`: Uncalibrated Logistic Regression.\n",
    "   * `pipe_cal`: Same model, wrapped with **CalibratedClassifierCV (sigmoid)**.\n",
    "2. **Runs cross-validation (5 folds)** and computes **out-of-fold (OOF) probabilities** for each version.\n",
    "\n",
    "   * Ensures robustness by dynamically detecting the positive-class index (`classes_`).\n",
    "3. Computes **Brier score** (lower = better calibration).\n",
    "4. Plots **reliability curves** (fraction of positives vs predicted probability).\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "* `oof_uncal`, `oof_cal`: OOF predicted probabilities for uncalibrated vs calibrated.\n",
    "* Printed **Brier scores** for both versions.\n",
    "* Calibration plot comparing uncalibrated vs calibrated.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* Calibration usually improves **probability estimates**, especially for logistic regression with strong regularization or imbalanced data.\n",
    "* Even if AUC remains the same, **better calibration means better decision thresholds** and more interpretable probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87966fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 6.3 — CALIBRATION (SIGMOID) ===\n",
      "Computing OOF probs (uncalibrated)...\n",
      "Computing OOF probs (calibrated)...\n",
      "Brier uncal: 0.0421\n",
      "Brier cal  : 0.0161\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== STEP 6.3 — CALIBRATION (SIGMOID) ===\")\n",
    "\n",
    "assert \"BEST_PIPELINE_NAME\" in globals(), \"Run Cell 6A to select BEST_PIPELINE_NAME.\"\n",
    "\n",
    "pipe_uncal = build_pipeline_by_name(BEST_PIPELINE_NAME, calibrated=False)\n",
    "pipe_cal   = build_pipeline_by_name(BEST_PIPELINE_NAME, calibrated=True)\n",
    "\n",
    "X = df_ready_model.drop(columns=[\"label_num\"])\n",
    "y = df_ready_model[\"label_num\"].values\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def oof_proba(pipe: Pipeline, X, y, cv):\n",
    "    \"\"\"\n",
    "    Compute OOF probabilities for the POSITIVE class (label=1) robustly.\n",
    "    We resolve the positive-class index from pipe.named_steps['clf'].classes_\n",
    "    AFTER fitting in each fold (it can vary across folds with calibration).\n",
    "    \"\"\"\n",
    "    oof = np.zeros(len(X), dtype=float)\n",
    "    for fold, (tr, va) in enumerate(cv.split(X, y), 1):\n",
    "        X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "        y_tr       = y[tr]\n",
    "\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "\n",
    "        # Resolve positive-class column index for this fitted fold\n",
    "        clf = pipe.named_steps.get(\"clf\")\n",
    "        assert hasattr(clf, \"classes_\"), \"Classifier has no .classes_ attribute after fit.\"\n",
    "        classes = clf.classes_\n",
    "        pos_idx = int(np.where(classes == 1)[0][0])\n",
    "\n",
    "        # Use the correct column for P(class=1)\n",
    "        proba_va = pipe.predict_proba(X_va)[:, pos_idx]\n",
    "        oof[va]  = proba_va\n",
    "\n",
    "    return oof\n",
    "\n",
    "\n",
    "print(\"Computing OOF probs (uncalibrated)...\")\n",
    "oof_uncal = oof_proba(pipe_uncal, X, y, cv)\n",
    "print(\"Computing OOF probs (calibrated)...\")\n",
    "oof_cal   = oof_proba(pipe_cal, X, y, cv)\n",
    "\n",
    "print(f\"Brier uncal: {brier_score_loss(y, oof_uncal):.4f}\")\n",
    "print(f\"Brier cal  : {brier_score_loss(y, oof_cal):.4f}\")\n",
    "\n",
    "# Reliability\n",
    "plt.figure(figsize=(6,5))\n",
    "for proba, label in [(oof_uncal, \"uncalibrated\"), (oof_cal, \"calibrated\")]:\n",
    "    frac_pos, mean_pred = calibration_curve(y, proba, n_bins=10, strategy=\"uniform\")\n",
    "    plt.plot(mean_pred, frac_pos, marker=\"o\", label=label)\n",
    "plt.plot([0,1],[0,1], '--', alpha=0.6)\n",
    "plt.xlabel(\"Mean predicted probability\"); plt.ylabel(\"Fraction of positives\")\n",
    "plt.title(\"Reliability (OOF)\"); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2338f62",
   "metadata": {},
   "source": [
    "## Step 6.4 — Robust Threshold Selection\n",
    "\n",
    "**Purpose**\n",
    "Turn calibrated probabilities into decisions by choosing operating thresholds that match different goals (maximize F1, guarantee high recall, guarantee high precision, or minimize a custom FP/FN cost).\n",
    "\n",
    "**What it does**\n",
    "\n",
    "* Uses the **calibrated OOF probabilities** (`oof_cal`) from Step 6.3 and the true labels `y`.\n",
    "* Prints quick sanity quantiles to verify separation between positive/negative scores.\n",
    "* Computes four thresholds:\n",
    "\n",
    "  * **`f1_global`**: threshold that maximizes F1 on OOF data.\n",
    "  * **`high_recall_global`**: highest threshold with **Recall ≥ 0.95**.\n",
    "  * **`high_precision_global`**: lowest threshold with **Precision ≥ 0.98**.\n",
    "  * **`min_cost_global`**: threshold that minimizes **C\\_FP·FP + C\\_FN·FN** (default C\\_FP=1, C\\_FN=5).\n",
    "* (Optional) **Persists** the selected thresholds back into the model artifact JSON.\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "* A dictionary `thresholds_selected` with the four thresholds (and the cost params).\n",
    "* Console printout of each chosen threshold.\n",
    "* If `spam_model_v1_artifacts.json` exists, it is **updated** with these thresholds so downstream cells (inference, reporting) can load them without recomputation.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* Because probabilities are calibrated, these thresholds should be **stable** and interpretable.\n",
    "* Pick the threshold that matches your deployment objective (e.g., **high recall** to catch nearly all spam, or **min-cost** if you have explicit FP/FN costs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cfaebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 6.4 — THRESHOLD SELECTION ===\n",
      "Pos probs q10/50/90: [0.8088912669928549, 0.9924010896533921, 0.9998199100393588]\n",
      "Neg probs q90/99/999: [0.02382657211987437, 0.7097697765797085, 0.992938942380201]\n",
      "f1_global: 0.4193\n",
      "high_recall_global: 0.6527\n",
      "high_precision_global: 0.8283\n",
      "min_cost_global: 0.2696\n",
      "Updated thresholds in spam_model_v1_artifacts.json\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 6.4 — THRESHOLD SELECTION ===\")\n",
    "\n",
    "assert \"oof_cal\" in globals(), \"Run Cell 6B first (compute calibrated OOF).\"\n",
    "y = df_ready_model[\"label_num\"].astype(int).values\n",
    "\n",
    "# --- Quick sanity on calibrated OOF probabilities ---\n",
    "pos = oof_cal[y == 1]; neg = oof_cal[y == 0]\n",
    "print(\"Pos probs q10/50/90:\", [float(np.quantile(pos, q)) for q in [0.10, 0.50, 0.90]])\n",
    "print(\"Neg probs q90/99/999:\", [float(np.quantile(neg, q)) for q in [0.90, 0.99, 0.999]])\n",
    "\n",
    "def find_f1_max_threshold(y_true, proba):\n",
    "    p, r, thr = precision_recall_curve(y_true, proba)\n",
    "    # thresholds[i] corresponds to p[i+1], r[i+1]\n",
    "    f1 = 2 * (p * r) / (p + r + 1e-8)\n",
    "    # We ignore the first point (no threshold) when selecting threshold\n",
    "    i = int(np.nanargmax(f1[1:])) + 1\n",
    "    return float(thr[i-1]), float(f1[i])\n",
    "\n",
    "def find_thr_for_recall(y_true, proba, target=0.95):\n",
    "    p, r, thr = precision_recall_curve(y_true, proba)\n",
    "    # Map thresholds[:] <-> recall[1:]\n",
    "    mask = r[1:] >= target\n",
    "    if np.any(mask):\n",
    "        # choose the LARGEST threshold that still meets the target (last True)\n",
    "        i = int(np.where(mask)[0][-1])\n",
    "        return float(thr[i])\n",
    "    else:\n",
    "        # fallback: smallest threshold (classify almost everything as positive)\n",
    "        return float(thr[-1])\n",
    "\n",
    "def find_thr_for_precision(y_true, proba, target=0.98):\n",
    "    p, r, thr = precision_recall_curve(y_true, proba)\n",
    "    mask = p[1:] >= target\n",
    "    if np.any(mask):\n",
    "        i = int(np.where(mask)[0][0])    # first threshold that meets precision\n",
    "        return float(thr[i])\n",
    "    else:\n",
    "        # fallback: largest threshold (very strict)\n",
    "        return float(thr[0])\n",
    "\n",
    "def find_min_cost_threshold(y_true, proba, C_FP=1.0, C_FN=5.0):\n",
    "    # grid on unique scores; clip to reasonable size if needed\n",
    "    grid = np.unique(np.round(proba, 4))\n",
    "    if grid.size > 1500:\n",
    "        grid = np.linspace(0, 1, 1001)\n",
    "    best_t, best_c = 0.5, float(\"inf\")\n",
    "    y_true = np.asarray(y_true)\n",
    "    for t in grid:\n",
    "        y_pred = (proba >= t).astype(int)\n",
    "        FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "        c = C_FP * FP + C_FN * FN\n",
    "        if c < best_c:\n",
    "            best_t, best_c = float(t), float(c)\n",
    "    return best_t, best_c\n",
    "\n",
    "thr_f1, f1_est   = find_f1_max_threshold(y, oof_cal)\n",
    "thr_hr           = find_thr_for_recall(y, oof_cal, target=0.95)\n",
    "thr_hp           = find_thr_for_precision(y, oof_cal, target=0.98)\n",
    "thr_mc, cost_mc  = find_min_cost_threshold(y, oof_cal, C_FP=1.0, C_FN=5.0)\n",
    "\n",
    "thresholds_selected = {\n",
    "    \"f1_global\": float(thr_f1),\n",
    "    \"high_recall_global\": float(thr_hr),\n",
    "    \"high_precision_global\": float(thr_hp),\n",
    "    \"min_cost_global\": float(thr_mc),\n",
    "    \"min_cost_params\": {\"C_FP\": 1.0, \"C_FN\": 5.0}\n",
    "}\n",
    "\n",
    "# Print nicely\n",
    "for k in [\"f1_global\", \"high_recall_global\", \"high_precision_global\", \"min_cost_global\"]:\n",
    "    print(f\"{k}: {thresholds_selected[k]:.4f}\")\n",
    "\n",
    "# Optional: persist thresholds into the current artifacts JSON if available\n",
    "ARTIFACT_JSON = \"spam_model_v1_artifacts.json\"\n",
    "if os.path.exists(ARTIFACT_JSON):\n",
    "    with open(ARTIFACT_JSON, \"r\") as f:\n",
    "        art = json.load(f)\n",
    "    art.setdefault(\"thresholds\", {}).update(thresholds_selected)\n",
    "    with open(ARTIFACT_JSON, \"w\") as f:\n",
    "        json.dump(art, f, indent=2)\n",
    "    print(f\"Updated thresholds in {ARTIFACT_JSON}\")\n",
    "else:\n",
    "    print(\"[INFO] Artifact JSON not found; skipping write.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac99f1",
   "metadata": {},
   "source": [
    "## Step 6.6 — Final fit, test, and save artifacts (v1)\n",
    "\n",
    "**Purpose**\n",
    "Train the chosen pipeline on the training split, evaluate on the held-out test set, and persist everything needed for future inference and reproducible runs.\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "* (Re)creates a **stratified 80/20 split** only if `X_train/X_test` aren’t already in memory.\n",
    "* Builds the **best pipeline** selected in Step 6.2 (`BEST_PIPELINE_NAME`) via `build_pipeline_by_name(...)`.\n",
    "* **Fits** the pipeline on `X_train, y_train` and reports wall-clock **fit time**.\n",
    "* Scores the test set and reports **PR-AUC** and **ROC-AUC** on `y_test`.\n",
    "* Applies the previously selected **decision thresholds** (`thresholds_selected`) to compute **precision/recall/F1** and a **confusion matrix** at each operating point (F1-max, High-Recall, High-Precision, Min-Cost).\n",
    "* Recursively **extracts TF-IDF parameters** from the pipeline (word & char vectorizers) so the artifact is self-describing.\n",
    "* **Saves** two files:\n",
    "\n",
    "  * `spam_model_v1.joblib` — the fully fitted sklearn pipeline.\n",
    "  * `spam_model_v1_artifacts.json` — metadata: pipeline name, vectorizer params, meta-features, thresholds, test metrics, fit time, seed, and a version tag (`\"v1\"`).\n",
    "\n",
    "**Outputs saved**\n",
    "\n",
    "* `spam_model_v1.joblib`\n",
    "* `spam_model_v1_artifacts.json` containing:\n",
    "\n",
    "  * `version`, `timestamp_utc`, `random_state`\n",
    "  * `pipeline_name`, `calibrated` flag\n",
    "  * `vectorizers` (TF-IDF config discovered inside the pipeline)\n",
    "  * `meta_features` used\n",
    "  * `thresholds` (from Step 6.4)\n",
    "  * `metrics.test` (PR-AUC, ROC-AUC, and per-threshold PR/RC/F1 + confusion matrix)\n",
    "  * `fit_time_sec`\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* The artifact version is labeled **“v1”** to enable simple, explicit versioning if you train updated models later (e.g., `v2`, `v3`).\n",
    "* This step assumes `thresholds_selected` exists from Step 6.4; if you want to use different operating points, update that dict before saving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a965704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 6.5 — FINAL FIT, TEST, SAVE (v1) ===\n",
      "Fitted in 1.4s\n",
      "Test PR-AUC:  0.9870\n",
      "Test ROC-AUC: 0.9954\n",
      "Saved → spam_model_v1.joblib\n",
      "Saved → spam_model_v1_artifacts.json\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STEP 6.5 — FINAL FIT, TEST, SAVE (v1) ===\")\n",
    "# Train/test split (reuse if already existing)\n",
    "if not {\"X_train\",\"X_test\",\"y_train\",\"y_test\"} <= set(globals().keys()):\n",
    "    X_full = df_ready_model.drop(columns=[\"label_num\"])\n",
    "    y_full = df_ready_model[\"label_num\"].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_full, y_full, test_size=0.20, stratify=y_full, random_state=42\n",
    "    )\n",
    "    print(\"Created stratified 80/20 split.\")\n",
    "\n",
    "\n",
    "final_pipe = build_pipeline_by_name(BEST_PIPELINE_NAME)\n",
    "\n",
    "t0 = time.time()\n",
    "final_pipe.fit(X_train, y_train)\n",
    "fit_time = time.time() - t0\n",
    "print(f\"Fitted in {fit_time:.1f}s\")\n",
    "\n",
    "proba_test = final_pipe.predict_proba(X_test)[:, 1]\n",
    "pr_auc_test, roc_auc_test = average_precision_score(y_test, proba_test), roc_auc_score(y_test, proba_test)\n",
    "print(f\"Test PR-AUC:  {pr_auc_test:.4f}\")\n",
    "print(f\"Test ROC-AUC: {roc_auc_test:.4f}\")\n",
    "\n",
    "def eval_at_threshold(y_true, proba, thr):\n",
    "    pred = (proba >= thr).astype(int)\n",
    "    pr, rc, f1, _ = precision_recall_fscore_support(y_true, pred, average=\"binary\", zero_division=0)\n",
    "    cm = confusion_matrix(y_true, pred)\n",
    "    return {\"precision\": float(pr), \"recall\": float(rc), \"f1\": float(f1), \"cm\": cm.tolist()}\n",
    "\n",
    "thr_metrics_test = {name: eval_at_threshold(y_test, proba_test, thr)\n",
    "                    for name, thr in thresholds_selected.items() if not isinstance(thr, dict)}\n",
    "\n",
    "# --- Generic vectorizer extraction (walk the pipeline and collect TF-IDF params) ---\n",
    "def collect_tfidf_params(pipe: Pipeline):\n",
    "    params = {}\n",
    "    idx = 0\n",
    "    def walk(est):\n",
    "        nonlocal idx\n",
    "        if isinstance(est, TfidfVectorizer):\n",
    "            key = f\"tfidf_{idx}_{est.analyzer}\"\n",
    "            idx += 1\n",
    "            params[key] = {k: v for k, v in est.get_params().items()\n",
    "                           if k in [\"analyzer\",\"ngram_range\",\"min_df\",\"max_df\",\n",
    "                                    \"max_features\",\"strip_accents\",\"stop_words\",\"sublinear_tf\"]}\n",
    "        # Explore common containers\n",
    "        from sklearn.pipeline import Pipeline as SkPipeline, FeatureUnion\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        if isinstance(est, SkPipeline):\n",
    "            for _, step in est.steps:\n",
    "                walk(step)\n",
    "        elif isinstance(est, ColumnTransformer):\n",
    "            for _, trans, _ in est.transformers_:\n",
    "                walk(trans)\n",
    "        elif \"FeatureUnion\" in est.__class__.__name__:\n",
    "            for _, trans in est.transformer_list:\n",
    "                walk(trans)\n",
    "    walk(pipe)\n",
    "    return params\n",
    "\n",
    "ARTIFACT_VERSION = \"v1\"\n",
    "MODEL_PATH   = f\"spam_model_{ARTIFACT_VERSION}.joblib\"\n",
    "ARTIFACT_JSON= f\"spam_model_{ARTIFACT_VERSION}_artifacts.json\"\n",
    "\n",
    "joblib.dump(final_pipe, MODEL_PATH)\n",
    "\n",
    "artifact = {\n",
    "    \"version\": ARTIFACT_VERSION,\n",
    "    \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    \"random_state\": 42,\n",
    "    \"pipeline_name\": BEST_PIPELINE_NAME,\n",
    "    \"calibrated\": True,\n",
    "    \"vectorizers\": collect_tfidf_params(final_pipe),\n",
    "    \"meta_features\": all_meta_features,\n",
    "    \"thresholds\": thresholds_selected,\n",
    "    \"metrics\": {\"test\": {\"pr_auc\": pr_auc_test, \"roc_auc\": roc_auc_test, \"by_threshold\": thr_metrics_test}},\n",
    "    \"fit_time_sec\": fit_time\n",
    "}\n",
    "with open(ARTIFACT_JSON, \"w\") as f:\n",
    "    json.dump(artifact, f, indent=2)\n",
    "\n",
    "print(f\"Saved → {MODEL_PATH}\")\n",
    "print(f\"Saved → {ARTIFACT_JSON}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcebd7",
   "metadata": {},
   "source": [
    "## Step 6.7 — Robust inference helper (load, score, threshold)\n",
    "\n",
    "**Purpose**\n",
    "Provide a production-style helper to score *already preprocessed* data (same schema as `df_ready_model`) using the saved pipeline and thresholds—without re-running the whole notebook.\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "* **Loads artifacts** from disk:\n",
    "\n",
    "  * `spam_model_v1.joblib` — the fitted sklearn pipeline.\n",
    "  * `spam_model_v1_artifacts.json` — contains decision thresholds and metadata.\n",
    "* **Resolves the positive-class column** in `predict_proba` safely (reads `pipe.named_steps[\"clf\"].classes_` to find the index for label `1`).\n",
    "* **Scores a DataFrame** and returns probabilities `p_spam` and binary predictions `pred_spam` using:\n",
    "\n",
    "  * a **named threshold** from the artifact JSON (default: `\"high_recall_global\"`), or\n",
    "  * a **manual override** via `threshold_override`.\n",
    "* **Sanity checks**:\n",
    "\n",
    "  * Verifies files exist.\n",
    "  * Clips thresholds that fall outside `[0,1]`.\n",
    "  * Warns if the requested `threshold_key` is missing (falls back to `0.5`).\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "* Preprocessed `pd.DataFrame` with at least `text_clean` and any required meta-features.\n",
    "* Paths to the model and artifact JSON (defaults provided).\n",
    "* Optional `threshold_key` or `threshold_override`.\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "* The input DataFrame plus:\n",
    "\n",
    "  * `p_spam`: calibrated probability for the positive class.\n",
    "  * `pred_spam`: decision based on the selected threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15f429a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 6.7 — INFERENCE HELPER (robust) ===\n",
      "Scoring done. threshold_key='high_recall_global', threshold_used=0.6527, pos_idx=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>p_spam</th>\n",
       "      <th>pred_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>hpl / conoco - teco waha 03 / 23 / 01 purchase hpl / conoco - teco waha 03 / 23 / 01 purchase daren , conoco invoiced hpl at $ 5 . 87 for 03 / 23 at pgev / ...</td>\n",
       "      <td>0.156795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>holiday on - call data holiday on - call data pipeline contact phone fax pager black marlin blair lichentwalter [phone] ( h ) [phone] debbie thompson [phone...</td>\n",
       "      <td>0.166913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>gas day 2 / 08 / 01 gas day 2 / 08 / 01 we agree : teco tap nom = 40 . 000 ; actual 41 . 358 - - - - - - - - - - - - - - - - - - - - - - forwarded by meliss...</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>sarco lateral and crow o ' connor meters sarco lateral and crow o ' connor meters daren - have you had a chance to look at this ? - aimee - - - - - - - - - ...</td>\n",
       "      <td>0.038250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>natural gas nomination for 09 / 00 natural gas nomination for 09 / 00 enron methanol nominates the following natural gas requirements for the methanol plant...</td>\n",
       "      <td>0.075413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                           text_clean  \\\n",
       "3169  hpl / conoco - teco waha 03 / 23 / 01 purchase hpl / conoco - teco waha 03 / 23 / 01 purchase daren , conoco invoiced hpl at $ 5 . 87 for 03 / 23 at pgev / ...   \n",
       "3100  holiday on - call data holiday on - call data pipeline contact phone fax pager black marlin blair lichentwalter [phone] ( h ) [phone] debbie thompson [phone...   \n",
       "624   gas day 2 / 08 / 01 gas day 2 / 08 / 01 we agree : teco tap nom = 40 . 000 ; actual 41 . 358 - - - - - - - - - - - - - - - - - - - - - - forwarded by meliss...   \n",
       "4037  sarco lateral and crow o ' connor meters sarco lateral and crow o ' connor meters daren - have you had a chance to look at this ? - aimee - - - - - - - - - ...   \n",
       "969   natural gas nomination for 09 / 00 natural gas nomination for 09 / 00 enron methanol nominates the following natural gas requirements for the methanol plant...   \n",
       "\n",
       "        p_spam  pred_spam  \n",
       "3169  0.156795          0  \n",
       "3100  0.166913          0  \n",
       "624   0.055363          0  \n",
       "4037  0.038250          0  \n",
       "969   0.075413          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== STEP 6.7 — INFERENCE HELPER (robust) ===\")\n",
    "\n",
    "\n",
    "def load_model_and_thresholds(model_path=\"spam_model_v1.joblib\",\n",
    "                              artifact_json=\"spam_model_v1_artifacts.json\",\n",
    "                              threshold_key=\"high_recall_global\"):\n",
    "    assert os.path.exists(model_path), f\"Missing model: {model_path}\"\n",
    "    assert os.path.exists(artifact_json), f\"Missing artifact json: {artifact_json}\"\n",
    "    pipe = joblib.load(model_path)\n",
    "    with open(artifact_json, \"r\") as f:\n",
    "        art = json.load(f)\n",
    "\n",
    "    thr_dict = art.get(\"thresholds\", {})\n",
    "    thr = thr_dict.get(threshold_key, None)\n",
    "    if thr is None:\n",
    "        # Fallback + warning\n",
    "        print(f\"[WARN] threshold_key='{threshold_key}' not found in artifacts. Falling back to 0.5.\")\n",
    "        thr = 0.5\n",
    "    thr = float(thr)\n",
    "    # Basic sanity check\n",
    "    if not (0.0 <= thr <= 1.0):\n",
    "        print(f\"[WARN] Loaded threshold={thr} seems out of [0,1]. Clipping.\")\n",
    "        thr = min(max(thr, 0.0), 1.0)\n",
    "\n",
    "    return pipe, thr, art\n",
    "\n",
    "def get_positive_class_index(pipe):\n",
    "    \"\"\"Return the column index in predict_proba that corresponds to class label 1 (spam).\"\"\"\n",
    "    clf = pipe.named_steps.get(\"clf\", None)\n",
    "    assert clf is not None, \"Pipeline must have a 'clf' step.\"\n",
    "    classes = getattr(clf, \"classes_\", None)\n",
    "    assert classes is not None, \"Classifier has no attribute 'classes_'.\"\n",
    "    pos_idx_arr = np.where(classes == 1)[0]\n",
    "    assert len(pos_idx_arr) == 1, f\"Could not resolve positive class index in {classes}\"\n",
    "    return int(pos_idx_arr[0])\n",
    "\n",
    "def score_preprocessed_df(df_like: pd.DataFrame,\n",
    "                          model_path=\"spam_model_v1.joblib\",\n",
    "                          artifact_json=\"spam_model_v1_artifacts.json\",\n",
    "                          threshold_key=\"high_recall_global\",\n",
    "                          threshold_override: float | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Score a preprocessed DataFrame (same schema as df_ready_model: has 'text_clean' and meta-features).\n",
    "    - Loads model & thresholds from disk\n",
    "    - Resolves the positive-class column index robustly\n",
    "    - Allows overriding the threshold if needed\n",
    "    \"\"\"\n",
    "    pipe, thr_loaded, art = load_model_and_thresholds(model_path, artifact_json, threshold_key)\n",
    "    thr = float(threshold_override) if threshold_override is not None else thr_loaded\n",
    "\n",
    "    pos_idx = get_positive_class_index(pipe)\n",
    "\n",
    "    proba = pipe.predict_proba(df_like)[:, pos_idx]\n",
    "    pred  = (proba >= thr).astype(int)\n",
    "\n",
    "    out = df_like.copy()\n",
    "    out[\"p_spam\"]    = proba\n",
    "    out[\"pred_spam\"] = pred\n",
    "\n",
    "    print(f\"Scoring done. threshold_key='{threshold_key}', threshold_used={thr:.4f}, pos_idx={pos_idx}\")\n",
    "    return out\n",
    "\n",
    "# --- Demo on a small sample (already preprocessed schema) ---\n",
    "if \"df_ready_model\" in globals():\n",
    "    demo = df_ready_model.sample(n=min(5, len(df_ready_model)), random_state=42)\n",
    "    cols_to_show = [c for c in [\"subject\",\"text_clean\"] if c in demo.columns]\n",
    "    scored = score_preprocessed_df(demo,\n",
    "                                   model_path=\"spam_model_v1.joblib\",\n",
    "                                   artifact_json=\"spam_model_v1_artifacts.json\",\n",
    "                                   threshold_key=\"high_recall_global\")\n",
    "    display(scored[cols_to_show + [\"p_spam\",\"pred_spam\"]])\n",
    "else:\n",
    "    print(\"[INFO] df_ready_model not found in RAM; run warm start or preprocessing to demo scoring.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d99c3",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, we developed a robust, end-to-end pipeline for **SPAM email detection** and **content analysis** using a real-world dataset of 5,171 emails. The workflow included rigorous EDA, careful preprocessing (with PII masking and deduplication), feature engineering (TF-IDF + meta-features), and extensive model evaluation.\n",
    "\n",
    "**Key results and takeaways:**\n",
    "\n",
    "- **Model Performance:**  \n",
    "  The final calibrated Logistic Regression model, trained with stratified 80/20 splits and 5-fold cross-validation, achieved:\n",
    "  - **Hold-out PR-AUC ≈ 0.987**\n",
    "  - **Hold-out ROC-AUC ≈ 0.995**\n",
    "  These metrics indicate excellent discrimination between SPAM and HAM, with robust generalization on unseen data.\n",
    "\n",
    "- **Thresholding & Calibration:**  \n",
    "  Multiple operating points were derived from calibrated out-of-fold probabilities:\n",
    "  - **F1-optimal threshold (`f1_global`)**\n",
    "  - **High-recall threshold (`high_recall_global` ≈ 0.65)**\n",
    "  - **High-precision and min-cost thresholds**  \n",
    "  This enables flexible deployment depending on business risk tolerance (e.g., minimizing false negatives or false positives).\n",
    "\n",
    "- **Feature Insights:**  \n",
    "  Ablation studies confirmed that combining **word n-grams** with **meta-features** (formatting, digit/exclamation counts, subject flags, etc.) yields the best performance, while character n-grams add marginal gains.\n",
    "\n",
    "- **Topic Modeling:**  \n",
    "  On predicted SPAM, topic modeling (NMF, K ≈ 5) revealed distinct spam campaigns and semantic clusters, with good topic separation (cosine distance analysis). Artifacts and top-terms per topic were saved for interpretability.\n",
    "\n",
    "- **NER on HAM:**  \n",
    "  Named Entity Recognition (spaCy or rule-based fallback) extracted organizations from HAM emails, producing a ranked list of entities and coverage statistics. This enables downstream BI and organizational analysis.\n",
    "\n",
    "- **Reproducibility & Artifacts:**  \n",
    "  All key artifacts were saved:\n",
    "  - Full sklearn pipeline (`spam_model_v1.joblib`)\n",
    "  - Model metadata and thresholds (`spam_model_v1_artifacts.json`)\n",
    "  - Error slices (FP/FN), topic models, and NER outputs\n",
    "\n",
    "**Design choices**—such as PII masking, deduplication, subject weighting, and explicit anti-leakage checks—ensured ethical, generalizable, and production-ready results.\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**  \n",
    "This notebook demonstrates a complete, reproducible workflow for SPAM detection and content analysis, achieving state-of-the-art performance on the provided dataset and producing actionable insights for both security and"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
